{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3790,"status":"ok","timestamp":1639603950015,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"},"user_tz":-330},"id":"P0nF1-G86hoi","outputId":"e2bfca42-d99a-412d-91eb-2bdc9a670bf4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1639603950016,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"},"user_tz":-330},"id":"uw2a1dRV7V1u","outputId":"3e777e60-bce7-41ef-fc90-111a51405736"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}],"source":["%ls"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1637,"status":"ok","timestamp":1639603951646,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"},"user_tz":-330},"id":"qsBjBTl46z-t","outputId":"437772e8-15c5-4083-c984-3b69aee79e7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Bert_Lime\n"]}],"source":["%cd drive/MyDrive/Bert_Lime"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"4TPSm9D7La6G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639600355959,"user_tz":-330,"elapsed":12077,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}},"outputId":"f84492b7-1bab-49ad-eab1-e2691c303759"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (1.43.0)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (2.23.0)\n","Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (2.1.0)\n","Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (2.2.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (3.17.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (1.15.0)\n","Requirement already satisfied: google-api-core<3.0dev,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (2.3.1)\n","Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (1.35.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage) (57.4.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage) (1.53.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.2.8)\n","Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.7/dist-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage) (1.3.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.10)\n"]}],"source":["!pip install --upgrade google-cloud-storage"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"PD9GzXQmas5p","executionInfo":{"status":"ok","timestamp":1639603998289,"user_tz":-330,"elapsed":46009,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["%%capture\n","#if running on colab, install below 4\n","!git clone https://github.com/Jeevesh8/arg_mining\n","!git clone https://github.com/chridey/change-my-view-modes\n","!pip install transformers\n","!pip install seqeval datasets allennlp\n","!pip install flax\n","!pip install sentencepiece\n","#if connected to local runtime, run the next command too\n","# !pip install bs4 tensorflow torch "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tG0N7MIH6hFY"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6588,"status":"ok","timestamp":1639604004866,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"},"user_tz":-330},"id":"r3uQjOjgiVS8","outputId":"ee8aac15-666d-4a18-edc5-8ffe123e83b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: bertviz in /usr/local/lib/python3.7/dist-packages (1.2.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from bertviz) (0.1.96)\n","Requirement already satisfied: transformers>=2.0 in /usr/local/lib/python3.7/dist-packages (from bertviz) (4.12.5)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from bertviz) (2019.12.20)\n","Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from bertviz) (1.10.0+cu111)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from bertviz) (4.62.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bertviz) (2.23.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from bertviz) (1.20.24)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->bertviz) (3.10.0.2)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (0.10.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (21.3)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (0.0.46)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (3.3.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (0.1.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (4.8.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=2.0->bertviz) (3.0.6)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->bertviz) (0.10.0)\n","Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->bertviz) (0.5.0)\n","Requirement already satisfied: botocore<1.24.0,>=1.23.24 in /usr/local/lib/python3.7/dist-packages (from boto3->bertviz) (1.23.24)\n","Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.24->boto3->bertviz) (1.25.11)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.24->boto3->bertviz) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.24->boto3->bertviz) (1.15.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=2.0->bertviz) (3.6.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bertviz) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bertviz) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bertviz) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.0->bertviz) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.0->bertviz) (7.1.2)\n"]}],"source":["!pip install bertviz"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"uQcIKc2ydWrr","executionInfo":{"status":"ok","timestamp":1639604004866,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["#Run to ignore warnings\n","import warnings\n","import numpy as np\n","warnings.filterwarnings('ignore')\n","import pickle"]},{"cell_type":"markdown","metadata":{"id":"8pCBwYZjfkHw"},"source":["### Load Metric"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"73mi2SaldZCe","executionInfo":{"status":"ok","timestamp":1639604014458,"user_tz":-330,"elapsed":9022,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["%%capture\n","from datasets import load_metric\n","metric = load_metric('seqeval')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4925,"status":"ok","timestamp":1639591733720,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"},"user_tz":-330},"id":"9vFjBlnoLrk4","outputId":"014e7827-63fa-4736-9651-66750dbe7792"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.7)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.24)\n","Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.2.0)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n","Requirement already satisfied: yaspin>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.1.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.1)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.25.11)\n","Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n"]}],"source":["!pip install wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1250,"status":"ok","timestamp":1636889734222,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"},"user_tz":-330},"id":"ar7r57THMmB8","outputId":"352155ca-6b71-451b-cc65-9f52e234069f"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manunay\u001b[0m (use `wandb login --relogin` to force relogin)\n"]}],"source":["!wandb login"]},{"cell_type":"markdown","metadata":{"id":"wjf6BxMkfm3R"},"source":["### Define & Load Tokenizer, Model, Dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"LRllHC2Edwnt","executionInfo":{"status":"ok","timestamp":1639604014458,"user_tz":-330,"elapsed":10,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["import torch\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1639604014458,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"},"user_tz":-330},"id":"4nT7V8NadxY0","outputId":"ec9af2e3-fa0f-4885-8b57-f9efa19ceb2c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":9}],"source":["device"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"GLYfC4tSd2Of","executionInfo":{"status":"ok","timestamp":1639604014459,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["model_version = 'bert-base-cased'"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"FbpL1Fpkd4mX","executionInfo":{"status":"ok","timestamp":1639604030689,"user_tz":-330,"elapsed":16236,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["%%capture\n","from transformers import AutoTokenizer, AutoModel\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\",\n","                                          bos_token = \"[CLS]\",\n","                                          eos_token = \"[SEP]\")\n","transformer_model = AutoModel.from_pretrained(model_version,output_hidden_states=True, output_attentions = True)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"eG8c_yrDFV91","executionInfo":{"status":"ok","timestamp":1639604052477,"user_tz":-330,"elapsed":21804,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["transformer_model = transformer_model.to(device)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Ipk3NaqNd_hm","executionInfo":{"status":"ok","timestamp":1639604052478,"user_tz":-330,"elapsed":17,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["import torch.nn as nn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VOhEyp8UNJfj","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"0e4172a3-33f1-493a-b268-3c3590e65a1d"},"outputs":[{"data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["import wandb\n","wandb.init(project=\"bert_explain\", entity=\"anunay\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iPLPBmp2NQP4"},"outputs":[],"source":["wandb.config = {\n","  \"learning_rate\": 2e-5,\n","  \"epochs\": 35,\n","  \"batch_size\": 2,\n","  \"num_devices\": 1,\n","  \"max_len\": 4096,\n","  \"max_comps\": 128,\n","  \"omit_filenames\": True \n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":607,"status":"ok","timestamp":1636890922956,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"},"user_tz":-330},"id":"AHse8fVAN1gj","outputId":"eeebc1d1-02cc-49af-c35d-e3f39974c66a"},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["wandb.watch(transformer_model, log='all', log_freq=50)"]},{"cell_type":"markdown","metadata":{"id":"nTeM7L87eAHB"},"source":["#### To add extra token type embeddings..."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"g-v4kM6ReDNh","executionInfo":{"status":"ok","timestamp":1639604052479,"user_tz":-330,"elapsed":17,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["def resize_token_type_embeddings(transformer_model, new_size):\n","    old_embeddings = transformer_model.embeddings.token_type_embeddings.weight\n","    old_size, hidden_dim = old_embeddings.shape\n","    transformer_model.embeddings.token_type_embeddings = nn.Embedding(new_size, hidden_dim, device=transformer_model.device)\n","    with torch.no_grad():\n","        transformer_model.embeddings.token_type_embeddings.weight[:old_size] = old_embeddings\n","\n","#resize_token_type_embeddings(transformer_model, 2)\n","#transformer_model.config.type_vocab_size = 2"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1639604052480,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"},"user_tz":-330},"id":"Msv1H6Nx8VRg","outputId":"4f244526-9d6d-45b3-e5e7-fc7ea6f9d8a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'Argument Mining BTP'\n","/content/drive/MyDrive/Bert_Lime\n","\u001b[0m\u001b[01;34marg_mining\u001b[0m/                        Drinventor_linear_layer.pt\n","\u001b[01;34mchange-my-view-modes\u001b[0m/              Drinventor_tokenizer_pre.pkl\n","\u001b[01;34mcompiled_corpus\u001b[0m/                   Drinventor_transformer_layer.pt\n","compiled_corpus.zip                layer_wise_analysis.pkl\n","crf_layer.pkl                      linear_layer.pt\n","cross_entropy_layer.pt             \u001b[01;34mModel\u001b[0m/\n","data_dict.pkl                      \u001b[01;34mnaacl18-multitask_argument_mining\u001b[0m/\n","data_runner.pkl                    \u001b[01;34mtemp\u001b[0m/\n","Discourse_Markers.txt              tokenizer_pre.pkl\n","Drinventor_crf_layer.pkl           transformer_layer.pt\n","Drinventor_cross_entropy_layer.pt  \u001b[01;34mwandb\u001b[0m/\n"]}],"source":["%cd Argument\\ Mining\\ BTP\n","%ls"]},{"cell_type":"markdown","metadata":{"id":"Eci9p6GYeHzT"},"source":["#### Load in discourse markers(Provide ``Discourse_Markers.txt``)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"9xdP51-0eHio","executionInfo":{"status":"ok","timestamp":1639604052480,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["with open('./Discourse_Markers.txt') as f:\n","    discourse_markers = [dm.strip() for dm in f.readlines()]"]},{"cell_type":"markdown","metadata":{"id":"FF8q3OhSe3jS"},"source":["* Change the ``batch_size`` in ``arg_mining/datasets/cmv_modes/configs.py`` before running below cell, as needed. [By default: 8]\n","\n","* Can also change ``max_len`` in the same file to suit the maximum length of your model. All threads will be truncated at ``max_len`` length. "]},{"cell_type":"code","execution_count":17,"metadata":{"id":"CWKnwhtReE-l","executionInfo":{"status":"ok","timestamp":1639604053040,"user_tz":-330,"elapsed":568,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["%%capture\n","from arg_mining.datasets.cmv_modes import load_dataset, data_config"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1072,"status":"ok","timestamp":1639604054110,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"},"user_tz":-330},"id":"JVhNUYYweSms","outputId":"76253931-4513-4067-c14c-8f7c80f1a82e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Embedding(29011, 768)"]},"metadata":{},"execution_count":18}],"source":["tokenizer.add_tokens(data_config[\"special_tokens\"], special_tokens=True)\n","\n","transformer_model.resize_token_embeddings(len(tokenizer))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_bf1UAyx8W5h"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"s7ORwS93eV40"},"source":["### Function to get datasets\n","* Change split sizes, if needed."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"tWdSINdKeTLM","executionInfo":{"status":"ok","timestamp":1639604054111,"user_tz":-330,"elapsed":13,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["def get_datasets():\n","    train_dataset, valid_dataset, test_dataset = load_dataset(tokenizer=tokenizer,\n","                                                              train_sz=50,\n","                                                              test_sz=50,\n","                                                              mask_tokens=discourse_markers,)\n","    return train_dataset, valid_dataset, test_dataset"]},{"cell_type":"markdown","metadata":{"id":"n4JnHTedreZy"},"source":["### Wrap dataset in ``get_comment_wise_dataset`` if you want to get comment wise dataset"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"eV7epQwUr89V","executionInfo":{"status":"ok","timestamp":1639604054112,"user_tz":-330,"elapsed":12,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["from typing import List, Tuple"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"AJ-KjmBgb75K","executionInfo":{"status":"ok","timestamp":1639604054113,"user_tz":-330,"elapsed":12,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["def split_encoding(tokenized_thread: List[int], \n","                   split_on: List[int], \n","                   eos_token_id: int) -> List[List[int]]:\n","    \"\"\"Splits tokenized_thread into multiple lists at each occurance of \n","    a token_id specified in split_on or the eos_token_id.\n","    \n","    1. The eos_token_id is retained in the last splitted component.\n","    2. Each matched token_id from split_on is retained in the component that \n","       follows it.\n","    \"\"\"\n","    splitted = [[]]\n","    for elem in tokenized_thread:\n","        if elem in split_on:\n","            splitted.append([])\n","        splitted[-1].append(elem)\n","        if elem == eos_token_id:\n","            break\n","    return splitted\n","\n","def pad_batch(elems: List[List[int]], pad_token_id: int) -> List[List[int]]:\n","    \"\"\"Pads all lists in elems to the maximum list length of any list in \n","    elems. Pads with pad_token_id.\n","    \"\"\"\n","    max_len = max([len(elem) for elem in elems])\n","    return [elem+[pad_token_id]*(max_len-len(elem)) for elem in elems]\n","\n","def get_comment_wise_dataset(dataset,\n","                             max_len: int=512,\n","                             batch_size: int=8) -> Tuple[List[List[int]], \n","                                                         List[List[int]], \n","                                                         List[List[int]]]:\n","    \"\"\"\n","    Args:\n","        dataset:     A numpy iterator dataset for threads, as returned from \n","                     get_datasets() function above.\n","        max_len:     Maximum length at which to truncate any comment.\n","        batch_size:  Number of comments in a batch\n","    \n","    Returns:\n","        A tuple having batched & padded(to max. length in batch) tokenized threads, \n","        masked threads, and component type labels; where each element corresponds\n","        to a comment in some thread.\n","    \n","    NOTE:\n","        This function removes the extra num_devices dimension from the elements \n","        of dataset provided.\n","    \"\"\"\n","    user_token_indices = tokenizer.encode(\"[UNU]\"+\"\".join([f\"[USER{i}]\" for i in range(data_config[\"max_users\"])]))[1:-1]\n","    comment_wise_tokenized_threads = []\n","    comment_wise_masked_threads = []\n","    comment_wise_comp_type_labels = []\n","\n","    for (tokenized_threads, masked_threads, comp_type_labels, _ ) in dataset:\n","        tokenized_threads = np.squeeze(tokenized_threads, axis=0).tolist()\n","        masked_threads = np.squeeze(masked_threads, axis=0).tolist()\n","        comp_type_labels = np.squeeze(comp_type_labels, axis=0).tolist()\n","\n","        for tokenized_thread, masked_thread, comp_type_label in zip(tokenized_threads, masked_threads, comp_type_labels):\n","            splitted_encodings = split_encoding(tokenized_thread, user_token_indices, tokenizer.eos_token_id)\n","            for elem in splitted_encodings:\n","                comment_wise_tokenized_threads.append(elem)\n","                comment_wise_masked_threads.append(masked_thread[:len(elem)])\n","                comment_wise_comp_type_labels.append(comp_type_label[:len(elem)])\n","                masked_thread, comp_type_label = masked_thread[len(elem):], comp_type_label[len(elem):]\n","    i = 0\n","    cw_tokenized_threads, cw_masked_threads, cw_comp_type_labels = [], [], []\n","    while i<len(comment_wise_tokenized_threads):\n","         cw_tokenized_threads.append(comment_wise_tokenized_threads[i][:max_len])\n","         cw_masked_threads.append(comment_wise_masked_threads[i][:max_len])\n","         cw_comp_type_labels.append(comment_wise_comp_type_labels[i][:max_len])\n","         i += 1\n","         \n","         if i%batch_size==0:\n","             yield (pad_batch(cw_tokenized_threads, tokenizer.pad_token_id), \n","                    pad_batch(cw_masked_threads, tokenizer.pad_token_id),\n","                    pad_batch(cw_comp_type_labels, data_config[\"pad_for\"][\"comp_type_labels\"]))\n","            \n","             cw_tokenized_threads, cw_masked_threads, cw_comp_type_labels = [], [], []"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"y5wp_tZsaLen","executionInfo":{"status":"ok","timestamp":1639604054778,"user_tz":-330,"elapsed":676,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["from typing import Generator"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"9q6HebJIbr6z","executionInfo":{"status":"ok","timestamp":1639604054779,"user_tz":-330,"elapsed":12,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["import random"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1639604054780,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"},"user_tz":-330},"id":"MXe35VWsbuMN","outputId":"d76262d7-90e4-42e0-f829-7c0a57f8ff20"},"outputs":[{"output_type":"stream","name":"stdout","text":["None\n","[2, 1, 3]\n"]}],"source":["l = [1,2,3]\n","print(random.shuffle(l))\n","print(l)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"VPkXe9tmFEPw","executionInfo":{"status":"ok","timestamp":1639604054780,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["def get_masked_data_lists(dataset,\n","                          left: bool=True) -> Tuple[List[List[int]], List[List[int]]]:\n","    \"\"\"\n","    Args:\n","        dataset:    A python generator that yields tuples of np.array's\n","                    consisting of tokenized_threads, masked_threads and component\n","                    type labels\n","        left:       If true, left side of components are masked. Otherwise right\n","                    side is masked.\n","    Returns:\n","        A tuple of two lists consisting of samples from entire dataset:\n","            final_threads:  A list of lists of int. Where each internal list corresponds\n","                            to a thread masked on one side.\n","            final_labels:   A list of lists of int. Where each internal list corresponds\n","                            to a masked component type labels.\n","    NOTE:\n","        A left masked sample consists of a tokenized thread whose all tokens before\n","        the beginning of some argumentative component are [MASK] and the corresponding\n","        component type labels are \"other\".\n","    \"\"\"\n","    final_threads, final_labels = [], []\n","    if not left:\n","        for (tokenized_threads, _masked_threads, comp_type_labels) in dataset:\n","            for (tokenized_thread, comp_type_label) in zip(tokenized_threads, comp_type_labels):\n","                # tokenized_thread = tokenized_thread.tolist()\n","                # comp_type_label = comp_type_label.tolist()\n","                left_masked_thread = []\n","                comp_types_for_left_masked_thread = []\n","                for i, (_token, label) in enumerate(zip(tokenized_thread, comp_type_label)):\n","                    if (label == data_config[\"arg_components\"][\"B-C\"] or \n","                        label == data_config[\"arg_components\"][\"B-P\"]):\n","                        final_threads.append(left_masked_thread+tokenized_thread[i:])\n","                        final_labels.append(comp_types_for_left_masked_thread+comp_type_label[i:])\n","                    left_masked_thread.append(tokenizer.mask_token_id)\n","                    comp_types_for_left_masked_thread.append(0)\n","    else:\n","        for (tokenized_threads, _masked_threads, comp_type_labels) in dataset:\n","            for (tokenized_thread, comp_type_label) in zip(tokenized_threads, comp_type_labels):\n","                tokenized_thread = tokenized_thread[::-1]\n","                comp_type_label = comp_type_label[::-1]\n","                right_masked_thread = []\n","                comp_types_for_right_masked_thread = []\n","                flag = 0\n","                for i, (_token, label) in enumerate(zip(tokenized_thread, comp_type_label)):\n","                    if ((label == data_config[\"arg_components\"][\"I-C\"] or \n","                        label == data_config[\"arg_components\"][\"I-P\"])) and flag:\n","                        final_threads.append(right_masked_thread+tokenized_thread[i:])\n","                        final_labels.append(comp_types_for_right_masked_thread+comp_type_label[i:])\n","                        final_threads[-1] = final_threads[-1][::-1]\n","                        final_labels[-1] = final_labels[-1][::-1]\n","                    if(label != data_config[\"arg_components\"][\"I-C\"] and\n","                        label != data_config[\"arg_components\"][\"I-P\"]):\n","                        flag = 1\n","                    else:\n","                        flag = 0\n","                    right_masked_thread.append(tokenizer.mask_token_id)\n","                    comp_types_for_right_masked_thread.append(0)\n","#         print((final_threads, final_labels))\n","        \n","    return final_threads, final_labels\n","\n","def get_masked_dataset(dataset,\n","                       left:bool = True,\n","                       shuffle:bool = True,\n","                       batch_size: int = 10) -> Generator[Tuple[np.ndarray, np.ndarray], None, None]:\n","    \"\"\"\n","    Args:\n","        dataset:    Same as in get_masked_data_lists()\n","        left:       Same as in get_masked_data_lists()\n","        shuffle:    Whether to shuffle around the elements corresponding to masking\n","                    of various threads. If True, batch will consist of random left/right\n","                    masked samples from different tokenized_threads, rather than same one.\n","        batch_size: Number of elements to put in a batch. \n","    \n","    Yields:\n","        A batch consisting of a tuple of np.array's corresponding to left/right masked\n","        tokenized_threads, and comp_type_labels.\n","    \"\"\"\n","    masked_threads, labels_for_masked_threads = get_masked_data_lists(dataset, left)\n","    samples =[(elem1, elem2) for (elem1, elem2) in zip(masked_threads, labels_for_masked_threads)]\n","    if shuffle:\n","        random.shuffle(samples)\n","    \n","    batch_threads = []\n","    batch_labels = []\n","    lengths = []\n","    for sample in samples:\n","#         print(sample)\n","        batch_threads.append(sample[0])\n","        batch_labels.append(sample[1])\n","        lengths.append(len(sample[0]))\n","        if len(batch_threads)==batch_size:\n","            max_len = max(lengths)\n","            for thread, label in zip(batch_threads, batch_labels):\n","                thread += [tokenizer.pad_token_id]*(max_len-len(thread))\n","                label += [data_config[\"pad_for\"][\"comp_type_labels\"]]*(max_len-len(thread))\n","            yield np.array(batch_threads), np.array(batch_labels)\n","            batch_threads, batch_labels, lengths = [], [], []"]},{"cell_type":"markdown","metadata":{"id":"lMyK-OLvjCn2"},"source":["### Sample Run for dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"elapsed":758,"status":"ok","timestamp":1636889852006,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"},"user_tz":-330},"id":"1wEc18EPVcYb","outputId":"d7e772f3-5a25-4316-c6d9-7e921af98a07"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\ntrain_dataset, valid_dataset, test_dataset = get_datasets()\\nfor (tokenized_threads, masked_threads, comp_type_labels) in get_comment_wise_dataset(train_dataset):\\n    print(len(tokenized_threads[0]))\\n    print(tokenizer.batch_decode(tokenized_threads))\\n    print(tokenizer.batch_decode(masked_threads))\\n    print(comp_type_labels)\\n    break\\n'"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","train_dataset, valid_dataset, test_dataset = get_datasets()\n","for (tokenized_threads, masked_threads, comp_type_labels) in get_comment_wise_dataset(train_dataset):\n","    print(len(tokenized_threads[0]))\n","    print(tokenizer.batch_decode(tokenized_threads))\n","    print(tokenizer.batch_decode(masked_threads))\n","    print(comp_type_labels)\n","    break\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E0p2J_WQjg5P"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":26,"metadata":{"id":"H9U9WNW_j12E","executionInfo":{"status":"ok","timestamp":1639604060463,"user_tz":-330,"elapsed":5689,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["from allennlp.modules.conditional_random_field import ConditionalRandomField as crf"]},{"cell_type":"markdown","metadata":{"id":"o0vzECspfT9q"},"source":["### Define layers for a Linear-Chain-CRF"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"8Z0wI2FyfQN3","executionInfo":{"status":"ok","timestamp":1639604061205,"user_tz":-330,"elapsed":757,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["\n","from allennlp.modules.conditional_random_field import ConditionalRandomField as crf\n","\n","ac_dict = data_config[\"arg_components\"]\n","\n","allowed_transitions =([(ac_dict[\"B-C\"], ac_dict[\"I-C\"]), \n","                       (ac_dict[\"B-P\"], ac_dict[\"I-P\"])] + \n","                      [(ac_dict[\"I-C\"], ac_dict[ct]) \n","                        for ct in [\"I-C\", \"B-C\", \"B-P\", \"O\"]] +\n","                      [(ac_dict[\"I-P\"], ac_dict[ct]) \n","                        for ct in [\"I-P\", \"B-C\", \"B-P\", \"O\"]] +\n","                      [(ac_dict[\"O\"], ac_dict[ct]) \n","                        for ct in [\"O\", \"B-C\", \"B-P\"]])\n","                    \n","linear_layer = nn.Linear(transformer_model.config.hidden_size,\n","                         len(ac_dict)).to(device)\n","\n","crf_layer = crf(num_tags=len(ac_dict),\n","                constraints=allowed_transitions,\n","                include_start_end_transitions=False).to(device)\n","\n","cross_entropy_layer = nn.CrossEntropyLoss(weight=torch.log(torch.tensor([3.3102, 61.4809, 3.6832, 49.6827, 2.5639], \n","                                                                        device=device)), reduction='none')"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"O72cBftf9Kxp","executionInfo":{"status":"ok","timestamp":1639604061206,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["linear_path = \"linear_layer.pt\"\n","cross_path = \"cross_entropy_layer.pt\"\n","crf_path = \"crf_layer.pkl\"\n","tokenizer_path = \"tokenizer_pre.pkl\"\n","transformer_path = \"transformer_layer.pt\""]},{"cell_type":"code","execution_count":29,"metadata":{"id":"bgiozkHUA_xL","executionInfo":{"status":"ok","timestamp":1639604061207,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["import pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ePu8ImSZ9if-"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"ckFXZTW3fnZK"},"source":["### Loss and Prediction Function"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"yIQbsEzbfZO2","executionInfo":{"status":"ok","timestamp":1639604061207,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["def compute(batch: Tuple[torch.Tensor, torch.Tensor, torch.Tensor],\n","            preds: bool=False, cross_entropy: bool=True):\n","    \"\"\"\n","    Args:\n","        batch:  A tuple having tokenized thread of shape [batch_size, seq_len],\n","                component type labels of shape [batch_size, seq_len], and a global\n","                attention mask for Longformer, of the same shape.\n","        \n","        preds:  If True, returns a List(of batch_size size) of Tuples of form \n","                (tag_sequence, viterbi_score) where the tag_sequence is the \n","                viterbi-decoded sequence, for the corresponding sample in the batch.\n","        \n","        cross_entropy:  This argument will only be used if preds=False, i.e., if \n","                        loss is being calculated. If True, then cross entropy loss\n","                        will also be added to the output loss.\n","    \n","    Returns:\n","        Either the predicted sequences with their scores for each element in the batch\n","        (if preds is True), or the loss value summed over all elements of the batch\n","        (if preds is False).\n","    \"\"\"\n","    tokenized_threads, token_type_ids, comp_type_labels = batch\n","    \n","    pad_mask = torch.where(tokenized_threads!=tokenizer.pad_token_id, 1, 0)\n","    \n","    logits = linear_layer(transformer_model(input_ids=tokenized_threads,\n","                                            attention_mask=pad_mask,).last_hidden_state)\n","    # print(logits.shape)\n","    if preds:\n","        return crf_layer.viterbi_tags(logits, pad_mask)\n","    \n","    log_likelihood = crf_layer(logits, comp_type_labels, pad_mask)\n","    \n","    if cross_entropy:\n","        logits = logits.reshape(-1, logits.shape[-1])\n","        \n","        pad_mask, comp_type_labels = pad_mask.reshape(-1), comp_type_labels.reshape(-1)\n","        \n","        ce_loss = torch.sum(pad_mask*cross_entropy_layer(logits, comp_type_labels))\n","        \n","        return ce_loss - log_likelihood\n","\n","    return -log_likelihood"]},{"cell_type":"markdown","metadata":{"id":"HHENTQyCfrXA"},"source":["### Define optimizer"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"FJ1pZLSEftJ7","executionInfo":{"status":"ok","timestamp":1639604061208,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["from itertools import chain\n","\n","import torch.optim as optim\n","\n","optimizer = optim.Adam(params = chain(transformer_model.parameters(),\n","                                      linear_layer.parameters(),\n","                                      crf_layer.parameters()),\n","                       lr = 2e-5,)"]},{"cell_type":"markdown","metadata":{"id":"ORtGK-SEfvaM"},"source":["### Training And Evaluation Loops"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"axoEh9b4fvJI","executionInfo":{"status":"ok","timestamp":1639604061208,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["values_weight = [[] for i in range(5)]\n","values_bias = [[] for i in range(5)]\n","def train_left_right(dataset, left: bool=True):\n","    global values_weight, values_bias;\n","    accumulate_over = 4\n","    \n","    optimizer.zero_grad()\n","    \n","    for i, (tokenized_threads, comp_type_labels) in enumerate(get_comment_wise_dataset(dataset)):\n","        \n","        #Cast to PyTorch tensor\n","        tokenized_threads = torch.tensor(tokenized_threads, device=device)\n","        # masked_threads = torch.tensor(masked_threads, device=device)\n","        max_size = max([len(i1) for i1 in comp_type_labels])\n","        # print(max_size)\n","        new_comp = []\n","        for l in range(comp_type_labels.shape[0]):\n","          new_comp.append(list(comp_type_labels[l]) + [0]*(max_size - len(comp_type_labels[l])))\n","        comp_type_labels = np.array(new_comp)\n","        # print(type(comp_type_labels))\n","        comp_type_labels = torch.tensor(comp_type_labels, device=device, dtype=torch.int64)\n","        \n","        loss = compute((tokenized_threads,\n","                        torch.where(tokenized_threads==tokenizer.mask_token_id, 1, 0), \n","                        comp_type_labels,))/data_config[\"batch_size\"]\n","        \n","        print(\"Loss: \", loss)\n","\n","        loss.backward()\n","        \n","        if i%accumulate_over==accumulate_over-1:\n","            optimizer.step()\n","            optimizer.zero_grad()\n","    \n","    optimizer.step()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fOIbNiAqfyP-"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":33,"metadata":{"id":"ZAZ49q4ryuf8","executionInfo":{"status":"ok","timestamp":1639604061209,"user_tz":-330,"elapsed":10,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["def evaluate(dataset, metric):\n","    \n","    int_to_labels = {v:k for k, v in ac_dict.items()}\n","    print('ENTER')\n","    \n","    with torch.no_grad():\n","        for tokenized_threads, masked_threads, comp_type_labels in get_comment_wise_dataset(dataset):\n","            # print(comp_type_labels)\n","            #Cast to PyTorch tensor\n","            tokenized_threads = torch.tensor(tokenized_threads, device=device)\n","            masked_threads = torch.tensor(masked_threads, device=device)\n","            comp_type_labels = torch.tensor(comp_type_labels, device=device)\n","            # print(tokenized_threads)\n","            # print(comp_type_labels.shape)\n","            # print(comp_type_labels)\n","            # print(torch.where(tokenized_threads==tokenizer.mask_token_id, 1, 0))\n","            preds = compute((tokenized_threads,\n","                            torch.where(masked_threads==tokenizer.mask_token_id, 1, 0), \n","                            comp_type_labels,), preds=True)\n","            \n","            lengths = torch.sum(torch.where(tokenized_threads!=tokenizer.pad_token_id, 1, 0), \n","                                axis=-1)\n","            # print(preds.shape)\n","            # print(preds)\n","            preds = [ [int_to_labels[pred] for pred in pred[0][:lengths[i]]]\n","                    for i, pred in enumerate(preds)\n","                    ]\n","            \n","            refs = [ [int_to_labels[ref] for ref in labels[:lengths[i]]]\n","                    for i, labels in enumerate(comp_type_labels.cpu().tolist())\n","                ]\n","            \n","            metric.add_batch(predictions=preds, \n","                            references=refs,)\n","                            #tokenized_threads=tokenized_threads.cpu().tolist())\n","        \n","    print(metric.compute())"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"FPxxgAIxvY6t","executionInfo":{"status":"ok","timestamp":1639604061209,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["\n","def train(dataset):\n","    accumulate_over = 4\n","    \n","    optimizer.zero_grad()\n","\n","    for i, (tokenized_threads, masked_threads, comp_type_labels) in enumerate(get_comment_wise_dataset(dataset)):\n","        \n","        #Cast to PyTorch tensor\n","        tokenized_threads = torch.tensor(tokenized_threads, device=device)\n","        masked_threads = torch.tensor(masked_threads, device=device)\n","        comp_type_labels = torch.tensor(comp_type_labels, device=device, dtype=torch.long)\n","        \n","        loss = compute((tokenized_threads,\n","                        torch.where(masked_threads==tokenizer.mask_token_id, 1, 0), \n","                        comp_type_labels,))/data_config[\"batch_size\"]\n","        \n","        print(\"Loss: \", loss)\n","\n","        wandb.log({'train_loss': loss.item() })\n","        loss.backward()\n","        if i%accumulate_over==accumulate_over-1:\n","            optimizer.step()\n","            optimizer.zero_grad()\n","    \n","    optimizer.step()"]},{"cell_type":"markdown","metadata":{"id":"3iWBULiFf0pq"},"source":["### Final Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sBHfu8F0f0RS"},"outputs":[],"source":["\n","for name, param in transformer_model.named_parameters():\n","  # if(\"encoder.layer.11\" in name):  \n","  print(name, param.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1634506443589,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"},"user_tz":-330},"id":"3D0RtoasXguz","outputId":"c7870da9-b328-4a62-f3f7-efb8929a8de9"},"outputs":[{"name":"stdout","output_type":"stream","text":["weight torch.Size([5, 768])\n","bias torch.Size([5])\n"]}],"source":["for name, param in linear_layer.named_parameters():\n","  # if(\"encoder.layer.11\" in name):  \n","  print(name, param.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1634506443590,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"},"user_tz":-330},"id":"RoByUXx9wS-T","outputId":"05a74dc5-63c0-4f23-e35e-5ea9c062a194"},"outputs":[{"name":"stdout","output_type":"stream","text":["103\n"]}],"source":["print(tokenizer.mask_token_id)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xnn3q4hRVkMm"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3536281,"status":"ok","timestamp":1636900326596,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"},"user_tz":-330},"id":"ldxdH0UBf32g","outputId":"6e868259-2c9b-40bf-cb36-f926f914bc3d"},"outputs":[{"name":"stdout","output_type":"stream","text":["------------EPOCH 1---------------\n","Loss:  tensor(1034.2817, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(887.2109, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2408.0747, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1494.1326, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1873.7246, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2329.7798, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1234.6335, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(3179.7261, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2652.5676, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2226.3198, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2417.5398, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2614.9922, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1398.1238, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1732.7836, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1246.1193, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1757.1753, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2655.0583, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2734.3047, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1916.7559, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1675.9404, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2572.1584, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2494.8867, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2308.0068, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2179.9509, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2634.3701, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1550.4854, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1478.3818, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1042.5027, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1384.6604, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1624.3987, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1586.3341, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2077.4028, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1034.2471, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1831.4509, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.03333333333333333, 'recall': 0.03546099290780142, 'f1': 0.034364261168384876, 'number': 846}, 'P': {'precision': 0.12472160356347439, 'recall': 0.11851851851851852, 'f1': 0.12154096581660337, 'number': 945}, 'overall_precision': 0.07897664071190211, 'overall_recall': 0.07928531546621999, 'overall_f1': 0.07913067706882139, 'overall_accuracy': 0.5018966889898375}\n","------------EPOCH 2---------------\n","Loss:  tensor(968.9219, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(857.9913, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2286.5728, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1461.6511, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1762.2151, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2186.0859, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1148.7118, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2718.0061, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2378.1165, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2062.4478, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2296.3284, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2482.2563, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1333.9231, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1647.3479, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1208.6440, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1690.1873, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2522.1299, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2633.7410, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1851.6719, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1563.4808, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2399.0862, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2376.6287, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2167.1995, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2006.7133, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2305.3730, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1483.9427, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1386.0376, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(948.8872, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1286.7211, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1514.8149, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1483.1658, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2042.1090, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(944.3459, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1643.5364, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.052873563218390804, 'recall': 0.054373522458628844, 'f1': 0.05361305361305361, 'number': 846}, 'P': {'precision': 0.12755598831548198, 'recall': 0.13862433862433862, 'f1': 0.1328600405679513, 'number': 945}, 'overall_precision': 0.09330521876647338, 'overall_recall': 0.09882747068676717, 'overall_f1': 0.09598698481561822, 'overall_accuracy': 0.511801620381211}\n","------------EPOCH 3---------------\n","Loss:  tensor(902.6952, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(763.0808, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2106.1099, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1349.6646, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1671.1082, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2118.5154, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1141.0115, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2781.1484, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2182.1895, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1946.2925, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2173.5112, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2307.5693, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1322.6855, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1541.2562, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1190.5165, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1617.0254, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2423.7959, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2581.3005, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1725.0410, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1468.8004, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2254.8726, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2244.1104, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2024.0732, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1864.6919, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2016.8716, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1454.0052, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1321.7518, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(889.3168, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1212.1689, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1369.4382, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1393.4712, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2028.4172, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(864.2218, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1527.6027, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.075, 'recall': 0.04964539007092199, 'f1': 0.05974395448079659, 'number': 846}, 'P': {'precision': 0.15167682926829268, 'recall': 0.2105820105820106, 'f1': 0.17634027470093042, 'number': 945}, 'overall_precision': 0.12873931623931623, 'overall_recall': 0.13456169737576773, 'overall_f1': 0.13158613158613158, 'overall_accuracy': 0.5125509296117642}\n","------------EPOCH 4---------------\n","Loss:  tensor(856.4781, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(702.6107, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1995.2826, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1315.3271, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1645.5659, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2060.9097, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1121.5310, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2313.4756, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2034.9792, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1948.2251, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2137.7363, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2244.8516, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1295.7402, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1483.6107, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1195.1089, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1501.4110, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2252.9626, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2456.1716, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1658.7050, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1344.3755, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2033.4590, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2024.3062, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1849.8635, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1727.7319, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1750.9833, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1425.5104, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1237.9198, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(795.8588, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1242.6243, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1388.9778, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1381.1552, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2141.1377, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(766.3726, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1362.6625, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.1643059490084986, 'recall': 0.20567375886524822, 'f1': 0.18267716535433073, 'number': 846}, 'P': {'precision': 0.1394335511982571, 'recall': 0.13544973544973546, 'f1': 0.13741277509393454, 'number': 945}, 'overall_precision': 0.15275670207384925, 'overall_recall': 0.16862088218872137, 'overall_f1': 0.16029723991507427, 'overall_accuracy': 0.5145881140823304}\n","------------EPOCH 5---------------\n","Loss:  tensor(792.1792, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(600.2024, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1763.9933, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1175.8577, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1401.2822, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1838.4973, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1022.8214, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2033.2559, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1795.2982, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1732.5717, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1936.3198, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2033.2053, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1225.0028, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1359.9868, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1082.4403, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1332.8799, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2180.7915, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2283.6030, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1625.0312, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1196.3491, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1852.0037, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1799.4949, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1753.0726, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1634.7673, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1454.7405, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1281.6573, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1121.2640, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(692.2806, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1169.7598, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1193.1536, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1280.9836, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1841.8590, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(723.9427, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1265.2865, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.17759336099585063, 'recall': 0.25295508274231676, 'f1': 0.20867869332033154, 'number': 846}, 'P': {'precision': 0.20659062103929024, 'recall': 0.1724867724867725, 'f1': 0.18800461361014995, 'number': 945}, 'overall_precision': 0.18906720160481444, 'overall_recall': 0.21049692908989392, 'overall_f1': 0.19920739762219286, 'overall_accuracy': 0.49283473048283616}\n","------------EPOCH 6---------------\n","Loss:  tensor(770.8324, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(563.1292, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1693.7434, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1063.8386, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1213.3994, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1771.3408, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(981.7946, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2180.9431, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1560.3735, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1499.4041, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1707.7012, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1773.9995, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1290.7294, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1358.6089, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1156.2947, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1331.0586, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2097.9324, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2249.1152, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1561.5305, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1132.2747, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1766.3190, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1620.5642, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1778.5608, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1640.3513, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1307.4197, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1235.9277, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1072.2773, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(657.4166, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1006.2546, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1016.0493, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1160.5474, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1498.6647, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(666.4813, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1173.4758, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.14023732470334413, 'recall': 0.3073286052009456, 'f1': 0.19259259259259257, 'number': 846}, 'P': {'precision': 0.13861386138613863, 'recall': 0.014814814814814815, 'f1': 0.02676864244741874, 'number': 945}, 'overall_precision': 0.140153452685422, 'overall_recall': 0.15298715801228363, 'overall_f1': 0.14628937533368927, 'overall_accuracy': 0.40458015267175573}\n","------------EPOCH 7---------------\n","Loss:  tensor(694.0060, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(487.4685, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1508.8354, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(961.4191, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1033.5559, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1634.7029, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(924.5298, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1983.6615, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1521.9988, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1325.2356, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1635.1189, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1771.3829, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1004.9692, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1099.7390, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(894.0653, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1126.3313, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1941.8472, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1983.8553, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1417.6782, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(999.3306, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1730.1456, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1523.8062, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1740.8235, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1601.0366, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1180.9213, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1153.6873, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1001.2351, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(592.5000, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(995.2117, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(848.1367, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1123.6292, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1450.4900, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(650.5771, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1197.3738, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.19532710280373833, 'recall': 0.2470449172576832, 'f1': 0.21816283924843427, 'number': 846}, 'P': {'precision': 0.16940948693126814, 'recall': 0.18518518518518517, 'f1': 0.1769464105156724, 'number': 945}, 'overall_precision': 0.1825962910128388, 'overall_recall': 0.21440536013400335, 'overall_f1': 0.19722650231124808, 'overall_accuracy': 0.5145881140823304}\n","------------EPOCH 8---------------\n","Loss:  tensor(665.4543, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(464.9718, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1423.0140, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(888.1648, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(991.8141, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1574.6536, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(954.5989, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2084.4204, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1305.9569, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1210.9905, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1522.2317, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1617.3309, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(963.0322, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1053.6481, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(891.8678, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1065.5632, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1633.8092, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1790.5122, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1365.6162, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(976.6995, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1449.5332, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1281.1198, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1426.1498, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1296.7650, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1054.9001, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1208.3689, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1036.6429, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(621.6572, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(893.9771, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(787.1169, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1121.6890, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1320.7494, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(732.3335, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1242.4633, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.17873303167420815, 'recall': 0.0933806146572104, 'f1': 0.12267080745341614, 'number': 846}, 'P': {'precision': 0.19491525423728814, 'recall': 0.3164021164021164, 'f1': 0.24122630092779349, 'number': 945}, 'overall_precision': 0.19129554655870445, 'overall_recall': 0.21105527638190955, 'overall_f1': 0.2006902044066897, 'overall_accuracy': 0.5051515009600525}\n","------------EPOCH 9---------------\n","Loss:  tensor(890.2305, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(714.2788, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1697.4736, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1126.0205, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1124.9062, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1920.1434, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1173.3591, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2138.6787, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1156.1115, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1064.7874, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1479.3336, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1558.6851, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(988.5905, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(972.4038, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(846.6288, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1050.2939, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1806.3889, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2153.0715, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1308.1411, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1113.1729, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1644.1082, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1474.0951, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1470.3062, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1482.5270, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1280.5852, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1177.6704, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1038.0217, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(622.9224, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(925.8060, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(942.3446, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1140.3826, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1505.7649, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(642.0956, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1162.0470, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.18009478672985782, 'recall': 0.1347517730496454, 'f1': 0.15415821501014199, 'number': 846}, 'P': {'precision': 0.2018140589569161, 'recall': 0.28253968253968254, 'f1': 0.23544973544973546, 'number': 945}, 'overall_precision': 0.19478527607361965, 'overall_recall': 0.21273031825795644, 'overall_f1': 0.20336269015212172, 'overall_accuracy': 0.5249379478293448}\n","------------EPOCH 10---------------\n","Loss:  tensor(617.2954, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(458.9514, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1346.8655, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(869.0881, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(979.7639, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1497.1035, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(903.5284, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1649.4517, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1513.2523, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1534.4412, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1904.5979, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2034.0042, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(997.8990, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1371.8862, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(936.4850, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1265.1309, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2180.4602, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2323.5210, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2062.7920, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1281.7129, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1626.0659, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1672.2849, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1586.7711, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1508.6642, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1302.3158, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1175.8184, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(952.7466, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(593.1160, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(922.0900, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1080.4438, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1082.7690, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1494.0791, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(843.7463, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1677.9912, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.06716417910447761, 'recall': 0.10638297872340426, 'f1': 0.08234217749313814, 'number': 846}, 'P': {'precision': 0.0234375, 'recall': 0.012698412698412698, 'f1': 0.016472203157172276, 'number': 945}, 'overall_precision': 0.0550755939524838, 'overall_recall': 0.05695142378559464, 'overall_f1': 0.05599780400768597, 'overall_accuracy': 0.4078115487285159}\n","------------EPOCH 11---------------\n","Loss:  tensor(739.5749, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(473.2113, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1979.2878, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1041.4548, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1136.0828, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1596.4124, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(853.5842, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1865.2571, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1052.9474, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1111.4437, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1435.3887, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1604.4739, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(903.8722, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(995.1722, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(809.3957, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1082.9922, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1776.3650, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1947.5488, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1730.2893, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1051.9089, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1441.8992, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1581.5552, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1431.9352, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1428.1998, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(960.1696, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1208.9294, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(975.7176, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(537.7985, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(865.1654, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(848.9406, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1011.3781, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1683.1335, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(486.8295, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(933.1408, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.16688396349413298, 'recall': 0.15130023640661938, 'f1': 0.1587104773713577, 'number': 846}, 'P': {'precision': 0.16865776528461, 'recall': 0.25396825396825395, 'f1': 0.20270270270270274, 'number': 945}, 'overall_precision': 0.1680365296803653, 'overall_recall': 0.2054718034617532, 'overall_f1': 0.18487817131374026, 'overall_accuracy': 0.5315646513370487}\n","------------EPOCH 12---------------\n","Loss:  tensor(531.0495, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(342.1279, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1175.8546, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(720.8708, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(826.4774, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1174.3541, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(781.5929, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1363.0100, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(738.3765, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(821.2899, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1092.3655, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1210.7922, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(798.3335, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(805.8817, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(723.5410, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(873.2421, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1389.2219, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1357.3291, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1131.4480, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(610.7412, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(983.8167, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(898.2799, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1084.0436, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(951.4506, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(631.3905, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(853.9733, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(717.7678, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(420.6808, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(581.9737, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(503.6500, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(735.6882, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1017.7328, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(331.8117, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(671.2969, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.11989459815546773, 'recall': 0.10756501182033097, 'f1': 0.1133956386292835, 'number': 846}, 'P': {'precision': 0.12663185378590078, 'recall': 0.2052910052910053, 'f1': 0.15664109810254337, 'number': 945}, 'overall_precision': 0.12439982540375381, 'overall_recall': 0.15912897822445563, 'overall_f1': 0.13963743263106324, 'overall_accuracy': 0.5164379712452583}\n","------------EPOCH 13---------------\n","Loss:  tensor(455.0833, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(280.5200, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1044.4595, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(668.3297, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(635.6503, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(944.9019, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(611.1277, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1125.3278, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(550.3311, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(580.8803, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(833.0836, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1005.7355, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(604.3679, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(651.4436, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(648.1479, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(642.3459, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1167.2676, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1185.1718, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1048.8883, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(425.1680, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(730.9388, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(761.0542, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(844.5880, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(756.6803, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(462.0784, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(754.4518, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(650.9713, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(359.6375, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(472.5109, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(356.0955, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(552.8668, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(776.8394, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(236.0304, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(457.1642, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.11348684210526316, 'recall': 0.08156028368794327, 'f1': 0.09491059147180193, 'number': 846}, 'P': {'precision': 0.10125, 'recall': 0.17142857142857143, 'f1': 0.12730844793713164, 'number': 945}, 'overall_precision': 0.10461956521739131, 'overall_recall': 0.12897822445561138, 'overall_f1': 0.11552888222055514, 'overall_accuracy': 0.513323654755772}\n","------------EPOCH 14---------------\n","Loss:  tensor(407.5328, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(253.2503, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(825.7555, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(591.7777, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(530.4594, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(797.2407, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(561.5739, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(961.1365, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(392.7671, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(523.4009, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(771.8602, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(985.8988, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(498.3729, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(556.3760, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(655.8947, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(595.7938, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(921.8486, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(883.6381, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(667.1824, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(256.6177, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(577.5930, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(447.3540, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(497.6617, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(495.1412, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(331.0530, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(568.6036, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(518.0746, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(252.1907, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(453.5273, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(278.1021, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(523.5746, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(825.1887, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(220.2049, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(375.7869, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.13659793814432988, 'recall': 0.12529550827423167, 'f1': 0.13070283600493215, 'number': 846}, 'P': {'precision': 0.15276804484933426, 'recall': 0.2306878306878307, 'f1': 0.18381112984822934, 'number': 945}, 'overall_precision': 0.14707217430776215, 'overall_recall': 0.18090452261306533, 'overall_f1': 0.16224336504757136, 'overall_accuracy': 0.5328291106636069}\n","------------EPOCH 15---------------\n","Loss:  tensor(320.3546, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(187.9349, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(608.2482, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(479.1128, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(375.6996, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(549.5289, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(387.4604, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(783.3531, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(320.7244, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(369.0287, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(519.2501, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(706.6390, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(570.4863, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(699.7095, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(617.3853, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(681.5818, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1561.5393, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1366.9818, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1011.9413, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(514.2350, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(669.3461, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(491.3676, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(584.4525, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(602.7704, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(440.2723, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(651.5698, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(515.9517, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(313.2345, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(635.0735, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(699.8392, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(704.4728, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1120.3433, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(350.8289, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(589.9987, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.1388888888888889, 'recall': 0.24822695035460993, 'f1': 0.178117048346056, 'number': 846}, 'P': {'precision': 0.1525940996948118, 'recall': 0.15873015873015872, 'f1': 0.15560165975103735, 'number': 945}, 'overall_precision': 0.14428857715430862, 'overall_recall': 0.20100502512562815, 'overall_f1': 0.1679888007466169, 'overall_accuracy': 0.49758816091415725}\n","------------EPOCH 16---------------\n","Loss:  tensor(457.5408, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(207.9997, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(976.5482, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(494.8260, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(476.5360, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(928.4180, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(546.6483, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1347.5190, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(572.2516, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(569.8369, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(802.2679, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(968.7944, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(630.1514, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(670.8303, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(853.2615, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(765.5901, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1643.8147, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1480.4709, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1212.8975, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(588.2769, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(819.6448, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(551.2357, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(927.9017, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1007.7889, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(519.6440, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(905.4039, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(792.3658, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(423.0657, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(697.4993, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(676.8907, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(784.5575, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1143.1975, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(319.8696, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(632.6785, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.13333333333333333, 'recall': 0.30260047281323876, 'f1': 0.18510484454085321, 'number': 846}, 'P': {'precision': 0.13793103448275862, 'recall': 0.008465608465608466, 'f1': 0.015952143569292126, 'number': 945}, 'overall_precision': 0.13346814964610718, 'overall_recall': 0.1474036850921273, 'overall_f1': 0.14009020960466964, 'overall_accuracy': 0.41153467896782653}\n","------------EPOCH 17---------------\n","Loss:  tensor(736.6013, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(412.0851, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1212.2908, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1072.5289, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(769.3406, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1167.5630, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(650.8020, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1301.2228, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(447.9053, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(474.5947, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(717.3840, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(931.1909, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(523.7271, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(723.2632, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(612.3733, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(706.0981, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1974.6016, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1981.0974, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1854.0359, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(770.2767, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1308.7307, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1247.9921, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1552.9536, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1479.9404, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(766.8406, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(982.5760, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(878.6716, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(506.9705, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(615.6160, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(575.2399, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(793.3629, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(982.3461, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(495.5974, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(852.0799, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.0745874587458746, 'recall': 0.13356973995271867, 'f1': 0.09572215163066497, 'number': 846}, 'P': {'precision': 0.014625228519195612, 'recall': 0.008465608465608466, 'f1': 0.010723860589812333, 'number': 945}, 'overall_precision': 0.05868089233753637, 'overall_recall': 0.06756002233389168, 'overall_f1': 0.06280820140150531, 'overall_accuracy': 0.43895471362337846}\n","------------EPOCH 18---------------\n","Loss:  tensor(566.7390, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(440.3293, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1335.7572, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(814.4702, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1002.5053, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1232.9653, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(706.1365, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1520.8625, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1155.0337, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(956.7451, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1306.9771, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1374.3997, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(928.0120, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(829.3957, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(741.6224, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(974.8671, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1326.4736, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1463.4586, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(865.7402, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(636.1307, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(898.6274, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(913.8532, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(917.8700, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(896.8239, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(670.8550, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(778.2303, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(666.3664, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(389.0220, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(598.2877, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(510.9106, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(644.6636, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(1013.5989, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(335.3743, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(565.6727, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.16825396825396827, 'recall': 0.1879432624113475, 'f1': 0.17755443886097153, 'number': 846}, 'P': {'precision': 0.17830045523520485, 'recall': 0.24867724867724866, 'f1': 0.207688908528502, 'number': 945}, 'overall_precision': 0.17410517012814847, 'overall_recall': 0.2199888330541597, 'overall_f1': 0.1943759250123335, 'overall_accuracy': 0.5344448086919871}\n","------------EPOCH 19---------------\n","Loss:  tensor(394.2739, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(291.6390, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(770.1973, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(563.1384, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(483.3463, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(673.8526, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(489.0306, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(642.3613, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(332.4214, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(390.7281, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(541.3615, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(598.7825, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(331.0203, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(474.9986, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(448.3304, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(449.5758, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(845.4442, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(761.1750, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(586.0433, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(180.0533, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(383.9307, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(263.1852, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(482.3301, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(407.2843, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(231.5902, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(457.2029, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(382.1575, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(218.2198, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(345.1023, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(240.1463, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(417.5718, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(634.0554, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(168.1435, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(314.7874, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.11944869831546708, 'recall': 0.18439716312056736, 'f1': 0.14498141263940523, 'number': 846}, 'P': {'precision': 0.07424593967517401, 'recall': 0.06772486772486773, 'f1': 0.07083563918096292, 'number': 945}, 'overall_precision': 0.1014760147601476, 'overall_recall': 0.12283640424343942, 'overall_f1': 0.1111391765597373, 'overall_accuracy': 0.5025289186531167}\n","------------EPOCH 20---------------\n","Loss:  tensor(293.9266, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(175.6990, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(523.3608, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(441.0838, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(298.7820, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(359.5302, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(263.8289, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(373.3980, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(295.6674, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(347.1104, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(468.1454, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(473.9221, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(370.9569, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(532.7721, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(545.2012, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(492.0163, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(559.6433, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(535.3319, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(391.9318, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(106.5260, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(254.1379, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(161.1396, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(234.9058, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(219.1839, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(136.0886, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(422.7261, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(381.6921, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(148.4344, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(332.0521, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(131.4856, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(405.4856, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(602.4991, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(161.4575, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(358.3766, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.1583629893238434, 'recall': 0.10520094562647754, 'f1': 0.12642045454545456, 'number': 846}, 'P': {'precision': 0.1432983323038913, 'recall': 0.2455026455026455, 'f1': 0.18096723868954762, 'number': 945}, 'overall_precision': 0.14718019257221457, 'overall_recall': 0.17922948073701842, 'overall_f1': 0.16163141993957703, 'overall_accuracy': 0.5374654615276542}\n","------------EPOCH 21---------------\n","Loss:  tensor(191.4437, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(166.2971, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(454.9460, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(397.3519, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(192.5516, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(247.8377, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(185.2995, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(240.8043, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(130.7119, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(123.3917, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(181.5458, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(220.3091, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(167.6304, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(282.2731, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(271.8782, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(247.8953, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(412.7828, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(359.1325, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(282.9802, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(74.4505, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(190.7943, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(116.0206, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(148.7681, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(127.1108, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(61.1978, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(243.1870, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(172.9083, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(86.9831, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(129.6118, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(69.4533, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(193.5174, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(196.4304, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(103.0624, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(150.8650, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.1450381679389313, 'recall': 0.20212765957446807, 'f1': 0.1688888888888889, 'number': 846}, 'P': {'precision': 0.12628624883068287, 'recall': 0.14285714285714285, 'f1': 0.1340615690168818, 'number': 945}, 'overall_precision': 0.13612099644128114, 'overall_recall': 0.1708542713567839, 'overall_f1': 0.1515226541223075, 'overall_accuracy': 0.528497166674472}\n","------------EPOCH 22---------------\n","Loss:  tensor(146.7279, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(88.4988, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(266.0522, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(286.7199, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(133.0557, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(153.2581, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(109.4309, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(163.2323, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(96.9562, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(82.8555, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(122.3325, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(153.5192, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(121.6004, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(191.5359, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(199.2986, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(165.3304, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(280.8194, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(206.0842, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(195.7070, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(47.5177, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(85.3436, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(49.7634, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(94.2175, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(65.5262, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(37.8364, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(195.5179, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(138.3414, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(44.5046, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(77.4842, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(45.4456, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(165.0742, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(166.5028, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(68.4037, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(109.3525, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.15, 'recall': 0.13120567375886524, 'f1': 0.1399747793190416, 'number': 846}, 'P': {'precision': 0.1317326411421155, 'recall': 0.21481481481481482, 'f1': 0.16331456154465004, 'number': 945}, 'overall_precision': 0.13765892152564665, 'overall_recall': 0.175321049692909, 'overall_f1': 0.15422396856581533, 'overall_accuracy': 0.5387299208542126}\n","------------EPOCH 23---------------\n","Loss:  tensor(79.9491, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(60.4088, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(183.6269, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(166.4797, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(75.0774, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(100.0695, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(74.3033, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(88.3508, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(67.4315, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(54.8589, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(73.9457, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(110.0858, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(90.6483, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(143.3917, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(166.6702, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(117.2242, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(216.6206, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(142.4846, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(136.3210, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(31.8484, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(51.0127, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(29.6501, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(61.8404, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(39.3925, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(23.7232, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(158.3710, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(83.0403, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(30.8441, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(43.2263, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(34.1111, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(94.2630, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(83.6858, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(48.0204, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(57.9863, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.13245033112582782, 'recall': 0.16548463356973994, 'f1': 0.14713610089332632, 'number': 846}, 'P': {'precision': 0.13348765432098766, 'recall': 0.18306878306878308, 'f1': 0.15439535921463635, 'number': 945}, 'overall_precision': 0.13302167445813853, 'overall_recall': 0.17476270240089337, 'overall_f1': 0.15106177606177604, 'overall_accuracy': 0.5392450709502178}\n","------------EPOCH 24---------------\n","Loss:  tensor(51.7691, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(49.5748, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(136.1698, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(130.4058, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(58.0760, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(72.9678, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(55.6452, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(64.3346, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(59.9794, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(38.3445, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(45.2197, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(82.1407, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(67.1618, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(92.3950, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(119.6234, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(95.3926, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(166.5247, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(97.8927, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(98.5142, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(25.7120, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(37.4853, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(20.8301, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(47.6659, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(29.8722, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(16.6236, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(135.4195, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(58.6380, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(22.6589, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(25.1448, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(30.8756, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(78.7253, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(54.4156, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(36.1769, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(44.2526, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.15763546798029557, 'recall': 0.15130023640661938, 'f1': 0.15440289505428226, 'number': 846}, 'P': {'precision': 0.12862796833773088, 'recall': 0.20634920634920634, 'f1': 0.15847216578626575, 'number': 945}, 'overall_precision': 0.13874570446735396, 'overall_recall': 0.18034617532104968, 'overall_f1': 0.15683418305413935, 'overall_accuracy': 0.539221655036763}\n","------------EPOCH 25---------------\n","Loss:  tensor(31.4155, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(29.9244, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(107.7397, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(97.6133, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(41.3024, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(48.7869, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(42.4230, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(47.4102, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(45.5577, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(27.2069, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(27.8184, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(52.5795, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(48.3922, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(72.7637, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(88.0973, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(59.3308, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(133.1644, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(70.9211, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(81.7365, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(20.4361, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(19.7474, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(14.3980, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(37.2160, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(20.9082, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(12.3571, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(122.5159, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(42.0038, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(17.6776, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(17.8982, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(22.4932, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(59.6624, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(39.0261, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(28.9851, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(33.2354, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.15375722543352602, 'recall': 0.15721040189125296, 'f1': 0.1554646405610754, 'number': 846}, 'P': {'precision': 0.12692050768203073, 'recall': 0.20105820105820105, 'f1': 0.1556101556101556, 'number': 945}, 'overall_precision': 0.1367485182049111, 'overall_recall': 0.18034617532104968, 'overall_f1': 0.15555020467132194, 'overall_accuracy': 0.5439282536411746}\n","------------EPOCH 26---------------\n","Loss:  tensor(21.3510, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(19.9544, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(83.4709, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(76.2623, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(31.2100, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(37.6017, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(33.1416, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(37.6597, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(36.7135, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(18.7320, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(19.4364, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(40.2219, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(35.5527, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(51.2192, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(70.0329, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(45.1977, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(95.0518, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(48.4443, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(67.1918, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(17.0805, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(14.4645, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(11.8343, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(29.1086, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(14.1007, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(10.3923, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(114.2010, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(31.7958, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(14.7008, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(14.2290, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(16.0433, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(40.9316, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(28.4732, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(23.7949, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(25.5818, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.1487513572204126, 'recall': 0.16193853427895982, 'f1': 0.15506508205998867, 'number': 846}, 'P': {'precision': 0.1211708645336964, 'recall': 0.18835978835978837, 'f1': 0.14747307373653687, 'number': 945}, 'overall_precision': 0.13179916317991633, 'overall_recall': 0.17587939698492464, 'overall_f1': 0.1506816551064339, 'overall_accuracy': 0.5441858286891772}\n","------------EPOCH 27---------------\n","Loss:  tensor(15.7255, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(15.1833, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(59.7151, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(61.3881, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(22.6024, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(30.1741, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(26.2846, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(31.5183, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(28.3572, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(12.6868, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(14.5749, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(32.2118, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(28.4117, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(38.1085, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(57.6535, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(34.9365, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(73.8334, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(33.3528, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(52.0753, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(15.3127, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(10.5567, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(9.3769, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(22.3536, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(10.1167, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(8.4013, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(120.7745, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(24.3545, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(12.5556, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(10.7207, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(11.7348, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(32.4551, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(21.9204, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(19.6546, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(18.8720, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.145933014354067, 'recall': 0.14420803782505912, 'f1': 0.1450653983353151, 'number': 846}, 'P': {'precision': 0.11927788523533205, 'recall': 0.19576719576719576, 'f1': 0.14823717948717946, 'number': 945}, 'overall_precision': 0.12861332216170926, 'overall_recall': 0.17141261864879956, 'overall_f1': 0.14696026807084728, 'overall_accuracy': 0.5365756568163724}\n","------------EPOCH 28---------------\n","Loss:  tensor(11.4454, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(11.7170, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(54.5274, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(49.8011, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(15.4055, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(24.3078, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(20.9895, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(26.5689, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(20.4463, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(9.6639, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(11.4983, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(27.2405, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(22.4767, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(28.3621, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(48.6153, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(26.3991, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(58.1521, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(25.5958, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(47.5916, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(13.9068, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(8.4738, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(7.7708, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(16.9268, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(8.1871, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(7.2025, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(133.8683, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(17.8259, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(10.8540, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(8.3338, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(9.6555, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(26.8024, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(17.4176, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(16.6413, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(14.0163, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.14350282485875707, 'recall': 0.15011820330969267, 'f1': 0.146735990756788, 'number': 846}, 'P': {'precision': 0.1267605633802817, 'recall': 0.2, 'f1': 0.15517241379310345, 'number': 945}, 'overall_precision': 0.132996632996633, 'overall_recall': 0.17643774427694026, 'overall_f1': 0.15166786657067435, 'overall_accuracy': 0.5381211071043881}\n","------------EPOCH 29---------------\n","Loss:  tensor(8.6701, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(8.8340, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(55.6713, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(41.1850, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(11.5128, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(20.1275, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(16.7258, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(22.0336, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(16.0275, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(7.5874, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(9.2194, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(23.0609, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(18.8940, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(22.1340, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(39.5089, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(20.7069, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(45.6726, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(20.0863, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(40.0826, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(13.3646, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(7.0198, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(6.6287, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(12.2484, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(6.8457, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(6.2360, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(91.3002, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(13.4786, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(9.2626, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(6.8902, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(7.8940, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(21.4621, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(14.0657, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(14.3799, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(11.1597, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.1404303510758777, 'recall': 0.14657210401891252, 'f1': 0.14343551185656447, 'number': 846}, 'P': {'precision': 0.12042581503659348, 'recall': 0.19153439153439153, 'f1': 0.14787581699346405, 'number': 945}, 'overall_precision': 0.12782900251466892, 'overall_recall': 0.1702959240647683, 'overall_f1': 0.1460378261910462, 'overall_accuracy': 0.5389640799887604}\n","------------EPOCH 30---------------\n","Loss:  tensor(7.2940, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(7.4444, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(34.8651, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(34.5578, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(9.4096, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(17.4518, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(13.4262, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(18.5094, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(11.5979, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(6.4759, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(7.9474, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(20.1378, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(16.0987, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(17.1091, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(31.6538, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(17.1517, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(36.2987, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(16.1563, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(33.4726, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(12.5318, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(6.0746, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.7599, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(9.9092, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.8853, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.5389, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(79.1470, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(9.7794, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(7.8575, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.6214, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(6.7526, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(19.1186, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(11.9286, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(12.4917, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(9.2503, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.14602803738317757, 'recall': 0.14775413711583923, 'f1': 0.14688601645123386, 'number': 846}, 'P': {'precision': 0.12119248217757615, 'recall': 0.19788359788359788, 'f1': 0.15032154340836013, 'number': 945}, 'overall_precision': 0.13005418924551895, 'overall_recall': 0.17420435510887772, 'overall_f1': 0.14892601431980904, 'overall_accuracy': 0.5395260619116752}\n","------------EPOCH 31---------------\n","Loss:  tensor(5.8543, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.9138, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(43.2682, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(29.5838, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(7.9717, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(15.2149, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(10.9121, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(15.7791, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(8.5844, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.3993, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(6.6594, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(16.6762, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(14.1276, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(13.8137, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(25.3821, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(14.3176, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(38.4775, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(13.4497, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(29.0218, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(12.2593, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.2057, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.0229, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(7.8242, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.1210, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.8417, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(74.5626, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(7.7760, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(6.7947, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.7857, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.8314, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(16.8534, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(9.9867, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(11.0472, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(7.8581, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.14414414414414414, 'recall': 0.15130023640661938, 'f1': 0.14763552479815456, 'number': 846}, 'P': {'precision': 0.12107023411371237, 'recall': 0.19153439153439153, 'f1': 0.14836065573770493, 'number': 945}, 'overall_precision': 0.1296684851028116, 'overall_recall': 0.17252931323283083, 'overall_f1': 0.14805941542884524, 'overall_accuracy': 0.5399709642673161}\n","------------EPOCH 32---------------\n","Loss:  tensor(5.1383, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.0932, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(37.4915, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(25.5069, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(6.8956, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(13.7092, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(9.0408, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(13.6904, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(6.8647, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.7980, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.8794, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(14.5419, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(12.5211, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(11.4739, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(20.9546, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(12.5885, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(27.7411, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(11.4735, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(24.1027, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(11.7869, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.6639, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.5365, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(6.4929, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.6056, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.3945, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(73.1047, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(6.3622, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.9000, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.1880, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.0931, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(15.1702, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(8.6116, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(9.8142, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(6.8140, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.14367816091954022, 'recall': 0.14775413711583923, 'f1': 0.14568764568764567, 'number': 846}, 'P': {'precision': 0.1182934712346477, 'recall': 0.19365079365079366, 'f1': 0.14686998394863562, 'number': 945}, 'overall_precision': 0.12743069921390154, 'overall_recall': 0.17197096594081518, 'overall_f1': 0.14638783269961977, 'overall_accuracy': 0.5369268955181942}\n","------------EPOCH 33---------------\n","Loss:  tensor(4.3801, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.3040, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(23.9400, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(22.1458, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(6.0891, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(12.2816, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(7.5948, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(11.9043, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.6214, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.1897, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.1904, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(12.9892, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(11.2305, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(9.6802, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(17.6445, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(11.0200, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(21.2716, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(9.8713, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(20.2943, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(11.5033, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.1671, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.0441, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.5007, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.1191, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(3.9774, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(69.3755, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.4830, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.2799, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(3.7016, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.5107, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(13.8325, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(7.5044, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(8.7370, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(6.0253, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.14941176470588236, 'recall': 0.15011820330969267, 'f1': 0.1497641509433962, 'number': 846}, 'P': {'precision': 0.11662371134020619, 'recall': 0.19153439153439153, 'f1': 0.144973968762515, 'number': 945}, 'overall_precision': 0.12822647793505412, 'overall_recall': 0.17197096594081518, 'overall_f1': 0.1469115191986644, 'overall_accuracy': 0.5377698684025664}\n","------------EPOCH 34---------------\n","Loss:  tensor(3.9167, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(3.7994, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(24.2338, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(19.1721, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.4171, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(11.0954, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(6.5241, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(10.4880, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.8771, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(3.7858, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.6626, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(10.6587, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(10.0651, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(8.2466, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(15.0661, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(9.8928, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(14.6938, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(8.3622, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(16.3183, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(11.1105, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(3.8129, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(3.6982, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.7728, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(3.7486, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(3.6600, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(69.0915, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.7260, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.7692, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(3.3203, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.0020, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(12.6752, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(6.6171, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(7.7660, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.3554, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.14578587699316628, 'recall': 0.15130023640661938, 'f1': 0.14849187935034805, 'number': 846}, 'P': {'precision': 0.11578947368421053, 'recall': 0.18624338624338624, 'f1': 0.14279918864097363, 'number': 945}, 'overall_precision': 0.1267723102585488, 'overall_recall': 0.16973757677275264, 'overall_f1': 0.14514203867271425, 'overall_accuracy': 0.5368098159509203}\n","------------EPOCH 35---------------\n","Loss:  tensor(3.5196, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(3.3439, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(16.9281, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(16.7667, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.8663, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(10.0725, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.6500, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(9.3228, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.3619, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(3.4352, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.2147, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(6.2793, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(9.1305, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(7.2964, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(13.3257, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(8.9755, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(10.0984, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(7.3965, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(13.8033, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(10.9044, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(3.4851, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(3.3701, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.2018, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(3.4292, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(3.3516, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(69.9410, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.2047, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(3.8578, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(2.9817, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(3.5994, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(11.5968, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(5.8675, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(6.8689, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss:  tensor(4.8055, device='cuda:0', grad_fn=<DivBackward0>)\n","ENTER\n","{'C': {'precision': 0.14512471655328799, 'recall': 0.15130023640661938, 'f1': 0.14814814814814817, 'number': 846}, 'P': {'precision': 0.11147540983606558, 'recall': 0.17989417989417988, 'f1': 0.13765182186234817, 'number': 945}, 'overall_precision': 0.12380556709597008, 'overall_recall': 0.16638749302065886, 'overall_f1': 0.1419723677941877, 'overall_accuracy': 0.5372781342200159}\n"]}],"source":["n_epochs = 35\n","for epoch in range(n_epochs):\n","    print(f\"------------EPOCH {epoch+1}---------------\")\n","    train_dataset, _, test_dataset = get_datasets()\n","    train(train_dataset)\n","    evaluate(test_dataset, metric)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ULmWq0MTBo56"},"outputs":[],"source":["# linear_path = \"Roberta_linear_layer.pt\"\n","# cross_path = \"Roberta_cross_entropy_layer.pt\"\n","# crf_path = \"Roberta_crf_layer.pkl\"\n","# tokenizer_path = \"Roberta_tokenizer_pre.pkl\"\n","# transformer_path = \"Roberta_transformer_layer.pt\"\n","# torch.save(linear_layer.state_dict(), linear_path)\n","# torch.save(cross_entropy_layer.state_dict(), cross_path)\n","# torch.save(transformer_model.state_dict(), transformer_path)\n","# with open(crf_path, \"wb\") as f:\n","#   pickle.dump(crf_layer, f)\n","# with open(tokenizer_path, \"wb\") as f:\n","#   pickle.dump(tokenizer, f)"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"SGM5WyeaIX9B","executionInfo":{"status":"ok","timestamp":1639604061209,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["linear_path = \"Model/linear_layer.pt\"\n","cross_path = \"Model/cross_entropy_layer.pt\"\n","crf_path = \"Model/crf_layer.pkl\"\n","tokenizer_path = \"Model/tokenizer_pre.pkl\"\n","transformer_path = \"Model/transformer_layer.pt\""]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":546,"status":"ok","timestamp":1639604061746,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"},"user_tz":-330},"id":"TjqLx0fJIFLs","outputId":"432fc63a-85d2-4f80-e179-411c0876569c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34marg_mining\u001b[0m/                        Drinventor_linear_layer.pt\n","\u001b[01;34mchange-my-view-modes\u001b[0m/              Drinventor_tokenizer_pre.pkl\n","\u001b[01;34mcompiled_corpus\u001b[0m/                   Drinventor_transformer_layer.pt\n","compiled_corpus.zip                layer_wise_analysis.pkl\n","crf_layer.pkl                      linear_layer.pt\n","cross_entropy_layer.pt             \u001b[01;34mModel\u001b[0m/\n","data_dict.pkl                      \u001b[01;34mnaacl18-multitask_argument_mining\u001b[0m/\n","data_runner.pkl                    \u001b[01;34mtemp\u001b[0m/\n","Discourse_Markers.txt              tokenizer_pre.pkl\n","Drinventor_crf_layer.pkl           transformer_layer.pt\n","Drinventor_cross_entropy_layer.pt  \u001b[01;34mwandb\u001b[0m/\n"]}],"source":["%ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"frg1F99gU5gV"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":37,"metadata":{"id":"eUeHZ3kq6fWR","executionInfo":{"status":"ok","timestamp":1639604063862,"user_tz":-330,"elapsed":2119,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["linear_layer.load_state_dict(torch.load(linear_path, map_location=device))\n","cross_entropy_layer.load_state_dict(torch.load(cross_path, map_location=device))\n","transformer_model.load_state_dict(torch.load(transformer_path , map_location=device))\n","with open(crf_path, \"rb\") as f:\n","  crf_layer = pickle.load(f)\n","with open(tokenizer_path, \"rb\") as f:\n","  tokenizer = pickle.load(f)"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"qZ9R7sgdFfYS","executionInfo":{"status":"ok","timestamp":1639604063864,"user_tz":-330,"elapsed":14,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["from itertools import chain\n","\n","import torch.optim as optim\n","\n","optimizer = optim.Adam(params = chain(transformer_model.parameters(),\n","                                      linear_layer.parameters(),\n","                                      crf_layer.parameters()),\n","                       lr = 2e-5,)"]},{"cell_type":"code","source":["graph_attention = []\n","for i in range(12):\n","  graph_attention.append(dict())\n","mapping_ind = {}"],"metadata":{"id":"IsnqEl6azhvw","executionInfo":{"status":"ok","timestamp":1639604063864,"user_tz":-330,"elapsed":13,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["cnt = 0\n","threshold = 0.01"],"metadata":{"id":"mUQOr2ya0Lmc","executionInfo":{"status":"ok","timestamp":1639604063865,"user_tz":-330,"elapsed":12,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","execution_count":41,"metadata":{"id":"7DWh8MI0dktr","executionInfo":{"status":"ok","timestamp":1639604063866,"user_tz":-330,"elapsed":12,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["\n","def attention_graph(dataset):\n","    accumulate_over = 4\n","    global cnt;\n","    optimizer.zero_grad()\n","\n","    for i, (tokenized_threads, masked_threads, comp_type_labels) in enumerate(get_comment_wise_dataset(dataset)):\n","        \n","        #Cast to PyTorch tensor\n","        tokenized_threads = torch.tensor(tokenized_threads, device=device)\n","        masked_threads = torch.tensor(masked_threads, device=device)\n","        comp_type_labels = torch.tensor(comp_type_labels, device=device, dtype=torch.long)\n","        \n","        pad_mask = torch.where(tokenized_threads!=tokenizer.pad_token_id, 1, 0)\n","    \n","        attention = transformer_model(input_ids=tokenized_threads,\n","                                            attention_mask=pad_mask,)[-1][0]\n","        maximum_attention = np.max(attention.cpu().detach().numpy())\n","        for j, tokenized_thread in enumerate(tokenized_threads):\n","          tokens = tokenizer.convert_ids_to_tokens(tokenized_thread) \n","          for tok in tokens:\n","            if(tok not in mapping_ind):\n","              mapping_ind[tok] = cnt;\n","              cnt += 1\n","          for lay in range(12):\n","            weights = attention[j, lay, :, :]\n","            for ind_1 in range(len(tokens)):\n","              for ind_2 in range(len(tokens)):\n","                if(tokens[ind_1] in [\"[NEWLINE]\", '[PAD]'] or tokens[ind_2] in [\"[NEWLINE]\", '[PAD]']):\n","                  continue\n","                \n","                node_1 = mapping_ind[tokens[ind_1]]\n","                node_2 = mapping_ind[tokens[ind_2]]\n","                weight = weights[ind_1, ind_2]\n","                if(weight < threshold*maximum_attention):\n","                  continue\n","                if(node_1 not in graph_attention[lay]):\n","                  graph_attention[lay][node_1] = {}\n","                if(node_2  not in graph_attention[lay][node_1]):\n","                  graph_attention[lay][node_1][node_2] = weight\n","                else:\n","                  graph_attention[lay][node_1][node_2] += weight\n","        print(cnt, cnt**2)              \n"]},{"cell_type":"code","source":["train_dataset, _, test_dataset = get_datasets()\n","attention_graph(train_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AmMgIyVt1l_A","outputId":"5d3b7ef6-1255-4de4-8fe5-9a68da460292"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["265 70225\n","347 120409\n","784 614656\n","877 769129\n","997 994009\n","1260 1587600\n","1350 1822500\n","1619 2621161\n","1836 3370896\n","1979 3916441\n","2110 4452100\n","2161 4669921\n","2293 5257849\n","2393 5726449\n","2444 5973136\n"]}]},{"cell_type":"code","source":["graph_path = \"attention_graph.pkl\"\n","with open(graph_path, \"wb\") as f:\n","  pickle.dump(graph_attention, f)"],"metadata":{"id":"lnpt3Ki69eHE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["k = 0\n","for i in graph_attention[0]:\n","  k += len(graph_attention[0][i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"36YR9HHS6SIP","executionInfo":{"status":"ok","timestamp":1639602313343,"user_tz":-330,"elapsed":599,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}},"outputId":"f5191ca2-3799-4053-e802-e2d36f219eb6"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["91\n","91\n","91\n","91\n","1383\n","113\n","6686\n","2091\n","1684\n","2523\n","14973\n","1243\n","171\n","4785\n","16063\n","1316\n","1351\n","548\n","8282\n","7723\n","620\n","548\n","10465\n","548\n","13969\n","548\n","548\n","548\n","561\n","548\n","1048\n","2301\n","6924\n","1644\n","1096\n","626\n","1371\n","13796\n","871\n","880\n","548\n","20045\n","548\n","548\n","1194\n","1242\n","1096\n","1048\n","1048\n","3416\n","6967\n","548\n","1548\n","1048\n","548\n","899\n","3170\n","1463\n","548\n","548\n","548\n","548\n","548\n","1048\n","10368\n","548\n","548\n","548\n","1542\n","1048\n","665\n","1133\n","548\n","548\n","3136\n","5532\n","777\n","1378\n","655\n","2963\n","871\n","10622\n","1093\n","1839\n","2663\n","3226\n","1478\n","548\n","693\n","1670\n","2551\n","1526\n","548\n","1169\n","2578\n","1243\n","1096\n","548\n","548\n","2227\n","655\n","655\n","548\n","990\n","795\n","41\n","255\n","1752\n","148\n","148\n","41\n","41\n","541\n","41\n","41\n","41\n","41\n","41\n","41\n","887\n","539\n","41\n","1648\n","1041\n","41\n","144\n","2520\n","107\n","107\n","336\n","107\n","107\n","107\n","107\n","277\n","1296\n","832\n","723\n","4000\n","454\n","454\n","434\n","607\n","351\n","1811\n","1946\n","2262\n","107\n","107\n","454\n","107\n","107\n","107\n","107\n","332\n","1430\n","107\n","229\n","107\n","107\n","430\n","107\n","1107\n","257\n","2163\n","107\n","107\n","836\n","769\n","122\n","445\n","567\n","244\n","244\n","154\n","490\n","1517\n","122\n","707\n","347\n","347\n","538\n","538\n","538\n","592\n","122\n","563\n","563\n","848\n","122\n","554\n","1623\n","122\n","725\n","347\n","847\n","122\n","122\n","244\n","122\n","1122\n","122\n","122\n","122\n","122\n","122\n","122\n","328\n","725\n","310\n","1372\n","225\n","578\n","78\n","78\n","168\n","181\n","78\n","225\n","225\n","225\n","225\n","1467\n","225\n","548\n","225\n","225\n","225\n","225\n","519\n","309\n","147\n","147\n","147\n","147\n","147\n","147\n","470\n","2217\n","647\n","470\n","793\n","147\n","147\n","147\n","719\n","147\n","147\n","147\n","147\n","647\n","147\n","147\n","147\n","250\n","147\n","147\n","147\n","147\n","647\n","147\n","250\n","317\n","8856\n","32\n","559\n","355\n","635\n","1482\n","32\n","77\n","32\n","577\n","90\n","2236\n","90\n","180\n","180\n","90\n","90\n","662\n","193\n","90\n","90\n","180\n","413\n","90\n","175\n","90\n","90\n","90\n","90\n","413\n","135\n","135\n","90\n","90\n","90\n","90\n","45\n","45\n","45\n","45\n","45\n","368\n","45\n","45\n","45\n","45\n","68\n","13\n","13\n","13\n","188\n","103\n","1771\n","103\n","103\n","103\n","103\n","103\n","103\n","103\n","103\n","103\n","103\n","103\n","2233\n","103\n","206\n","188\n","103\n","103\n","103\n","103\n","103\n","103\n","103\n","103\n","603\n","103\n","1103\n","103\n","103\n","103\n","85\n","1552\n","85\n","85\n","85\n","85\n","170\n","85\n","85\n","670\n","85\n","170\n","908\n","85\n","803\n","157\n","157\n","157\n","803\n","85\n","85\n","85\n","85\n","85\n","85\n","85\n","85\n","500\n","500\n","500\n","1823\n","500\n","500\n","1646\n","500\n","500\n","500\n","500\n","1792\n","500\n","500\n","1823\n","2500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","1000\n","1000\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","823\n","500\n","500\n","500\n","500\n","500\n","1000\n","500\n","1792\n","500\n","1000\n","500\n","1000\n","500\n","500\n","823\n","500\n","500\n","500\n","1323\n","500\n","500\n","500\n","500\n","1000\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","823\n","500\n","1000\n","500\n","500\n","500\n","1000\n","500\n","500\n","500\n","500\n","500\n","500\n","823\n","500\n","500\n","500\n","500\n","823\n","1000\n","1000\n","500\n","500\n","500\n","500\n","500\n","500\n","572\n","500\n","1000\n","500\n","500\n","500\n","500\n","1000\n","1000\n","500\n","1000\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","823\n","500\n","500\n","1500\n","500\n","500\n","500\n","500\n","572\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","2000\n","500\n","500\n","4000\n","500\n","500\n","500\n","1500\n","500\n","500\n","500\n","500\n","1500\n","1000\n","1500\n","500\n","500\n","500\n","500\n","500\n","500\n","500\n","572\n","644\n","572\n","572\n","572\n","572\n","895\n","572\n","572\n","500\n","500\n","72\n","72\n","72\n","72\n","72\n","72\n","72\n","72\n","72\n","718\n","72\n","72\n","72\n","23\n","23\n","346\n","346\n","669\n","346\n","323\n","323\n","323\n","323\n","969\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","646\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","969\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","646\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","646\n","323\n","323\n","323\n","323\n","323\n","323\n","646\n","323\n","323\n","323\n","323\n","646\n","323\n","323\n","323\n","323\n","323\n","646\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n","323\n"]}]},{"cell_type":"code","execution_count":38,"metadata":{"id":"vmtRk9EgptD9","executionInfo":{"status":"ok","timestamp":1639600637835,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"outputs":[],"source":["from bertviz import model_view\n"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"6-iFipFGHztw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639602408097,"user_tz":-330,"elapsed":348,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}},"outputId":"49201ec8-e541-4c2a-83e0-9476c7c4ea0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.99528\n","4.3162334e-08\n"]}],"source":["tokenized_threads = tokenizer.encode(\"I point out that many Christians follow the bible which has numerous examples of sexism, but in application, there are numerous branches of Christianity that are no more sexist than secular groups. For example, Congregationalists and Universaliists.\", return_tensors='pt')\n","d_tokenized_threads = tokenized_threads.to(device)\n","# print(tokenized_threads)3,60,000/yr\n","pad_mask = torch.where(tokenized_threads!=tokenizer.pad_token_id, 1, 0).to(device)\n","# print(pad_mask)\n","output = transformer_model(input_ids=d_tokenized_threads,\n","                                        attention_mask=pad_mask,)[-1]\n","print(np.max(output[0].cpu().detach().numpy()))\n","print(np.min(output[0].cpu().detach().numpy()))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1P_CAnwcMYRMOr9BaXz_MSvCjqXDaJOrr"},"executionInfo":{"elapsed":37929,"status":"ok","timestamp":1639592151409,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"},"user_tz":-330},"id":"8dIK3SprkFXq","outputId":"7ce13b60-a007-4f67-a240-dca2b83cceff"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["tokenized_threads = tokenizer.encode(\"I point out that many Christians follow the bible which has numerous examples of sexism, but in application, there are numerous branches of Christianity that are no more sexist than secular groups. For example, Congregationalists and Universaliists.\", return_tensors='pt')\n","d_tokenized_threads = tokenized_threads.to(device)\n","# print(tokenized_threads)3,60,000/yr\n","pad_mask = torch.where(tokenized_threads!=tokenizer.pad_token_id, 1, 0).to(device)\n","# print(pad_mask)\n","output = transformer_model(input_ids=d_tokenized_threads,\n","                                        attention_mask=pad_mask,)\n","# output = transformer_model(tokenized_threads)\n","attention = output[-1]\n","print(len(attention), attention[0].shape)\n","tokens = tokenizer.convert_ids_to_tokens(tokenized_threads[0]) \n","print(len(tokens), attention[0].shape)\n","print(attentio)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xa7VzZzcTkx1"},"outputs":[],"source":["model_view(attention, tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AuKW_facyjhm"},"outputs":[],"source":["tokenized_threads = tokenizer.encode(\"For example, Congregationalists and Universaliists. I point out that many Christians follow the bible which has numerous examples of sexism, but in application, there are numerous branches of Christianity that are no more sexist than secular groups. \", return_tensors='pt')\n","d_tokenized_threads = tokenized_threads.to(device)\n","# print(tokenized_threads)3,60,000/yr\n","pad_mask = torch.where(tokenized_threads!=tokenizer.pad_token_id, 1, 0).to(device)\n","# print(pad_mask)\n","output = transformer_model(input_ids=d_tokenized_threads,\n","                                        attention_mask=pad_mask,)\n","# output = transformer_model(tokenized_threads)\n","attention = output[-1]\n","print(len(attention), attention[0].shape)\n","tokens = tokenizer.convert_ids_to_tokens(tokenized_threads[0]) \n","print(len(tokens), attention[0].shape)\n","model_view(attention, tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H091ceNa1AiX"},"outputs":[],"source":["class wrapper():\n","  model = -1\n","  tokenizer = -1\n","\n","  def __init__(model, tokenizer):\n","    self.model = model\n","    self.tokenizer = tokenizer\n","\n","  def predict_proba(text_sample):\n","    batch = preprocess(text_sample)\n","    tokenized_threads, token_type_ids = batch\n","    \n","    pad_mask = torch.where(tokenized_threads!=tokenizer.pad_token_id, 1, 0)\n","    \n","    logits = linear_layer(transformer_model(input_ids=tokenized_threads,\n","                                            attention_mask=pad_mask,).last_hidden_state)\n","    \n","    \n","    return logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rjVahmh50mdy"},"outputs":[],"source":["import seaborn as sns\n","%matplotlib inline\n","from collections import OrderedDict\n","from lime.lime_text import LimeTextExplainer\n","\n","explainer = LimeTextExplainer(class_names=class_names)\n","explanation = explainer.explain_instance(text_sample, pipeline.predict_proba, num_features=10)\n","\n","weights = OrderedDict(explanation.as_list())\n","lime_weights = pd.DataFrame({'words': list(weights.keys()), 'weights': list(weights.values())})\n","\n","sns.barplot(x=\"words\", y=\"weights\", data=lime_weights);\n","plt.xticks(rotation=45)\n","plt.title('Sample {} features weights given by LIME'.format(idx));"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Attention_effect_Bert_am.ipynb","provenance":[{"file_id":"1ytu6iYnEDXs0Zl8jscOrk85hXz3Z2z4Y","timestamp":1639591237887},{"file_id":"1KkaQKMEEtV-2nYayGOluwqfJSAOOUcbK","timestamp":1634506046345},{"file_id":"1yMX2KQlHgXlS1GdULU6IPruM6RjzIxYl","timestamp":1632580585679},{"file_id":"1z8g91dHSsWg_JYWvHGN1W8IcnWLKLnd_","timestamp":1632576779567},{"file_id":"https://github.com/Jeevesh8/arg_mining/blob/main/experiments/BERT_am.ipynb","timestamp":1631093920625}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}