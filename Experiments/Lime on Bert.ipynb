{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lime on Bert.ipynb","provenance":[{"file_id":"https://github.com/Jeevesh8/arg_mining/blob/main/experiments/BERT_am.ipynb","timestamp":1630833061125}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"PD9GzXQmas5p","executionInfo":{"status":"ok","timestamp":1631085596402,"user_tz":-330,"elapsed":19789,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"source":["%%capture\n","#if running on colab, install below 4\n","!git clone https://github.com/Jeevesh8/arg_mining\n","!pip install transformers\n","!pip install seqeval datasets allennlp\n","!pip install flax\n","!pip install sentencepiece\n","#if connected to local runtime, run the next command too\n","#pip install bs4 tensorflow torch "],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"uQcIKc2ydWrr","executionInfo":{"status":"ok","timestamp":1631085992263,"user_tz":-330,"elapsed":485,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"source":["#Run to ignore warnings\n","import warnings\n","import numpy as np\n","warnings.filterwarnings('ignore')"],"execution_count":66,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8pCBwYZjfkHw"},"source":["### Load Metric"]},{"cell_type":"code","metadata":{"id":"73mi2SaldZCe","executionInfo":{"status":"ok","timestamp":1631085597217,"user_tz":-330,"elapsed":820,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"source":["%%capture\n","from datasets import load_metric\n","metric = load_metric('seqeval')"],"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wjf6BxMkfm3R"},"source":["### Define & Load Tokenizer, Model, Dataset"]},{"cell_type":"code","metadata":{"id":"LRllHC2Edwnt","executionInfo":{"status":"ok","timestamp":1631085597218,"user_tz":-330,"elapsed":19,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"source":["import torch\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"4nT7V8NadxY0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631085597219,"user_tz":-330,"elapsed":19,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}},"outputId":"107cad7b-fe44-494e-86fc-452af7ec1b38"},"source":["device"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"GLYfC4tSd2Of","executionInfo":{"status":"ok","timestamp":1631085597220,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"source":["model_version = 'bert-base-uncased'"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"FbpL1Fpkd4mX","executionInfo":{"status":"ok","timestamp":1631085607816,"user_tz":-330,"elapsed":10604,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"source":["%%capture\n","from transformers import AutoTokenizer, AutoModel\n","tokenizer = AutoTokenizer.from_pretrained(model_version)\n","transformer_model = AutoModel.from_pretrained(model_version).to(device)"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ipk3NaqNd_hm","executionInfo":{"status":"ok","timestamp":1631085607817,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"source":["import torch.nn as nn"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nTeM7L87eAHB"},"source":["#### To add extra token type embeddings..."]},{"cell_type":"code","metadata":{"id":"g-v4kM6ReDNh","executionInfo":{"status":"ok","timestamp":1631085607818,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"source":["def resize_token_type_embeddings(transformer_model, new_size):\n","    old_embeddings = transformer_model.embeddings.token_type_embeddings.weight\n","    old_size, hidden_dim = old_embeddings.shape\n","    transformer_model.embeddings.token_type_embeddings = nn.Embedding(new_size, hidden_dim, device=transformer_model.device)\n","    with torch.no_grad():\n","        transformer_model.embeddings.token_type_embeddings.weight[:old_size] = old_embeddings\n","\n","#resize_token_type_embeddings(transformer_model, 2)\n","#transformer_model.config.type_vocab_size = 2"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Eci9p6GYeHzT"},"source":["#### Load in discourse markers(Provide ``Discourse_Markers.txt``)"]},{"cell_type":"code","metadata":{"id":"9xdP51-0eHio","executionInfo":{"status":"ok","timestamp":1631085607818,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"source":["with open('./Discourse_Markers.txt') as f:\n","    discourse_markers = [dm.strip() for dm in f.readlines()]"],"execution_count":45,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FF8q3OhSe3jS"},"source":["* Change the ``batch_size`` in ``arg_mining/datasets/cmv_modes/configs.py`` before running below cell, as needed. [By default: 8]"]},{"cell_type":"code","metadata":{"id":"CWKnwhtReE-l","executionInfo":{"status":"ok","timestamp":1631085607819,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"source":["%%capture\n","from arg_mining.datasets.cmv_modes import load_dataset, data_config"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"JVhNUYYweSms","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631085608607,"user_tz":-330,"elapsed":796,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}},"outputId":"6ad77570-3cae-41e4-f28b-59fc40b59ea3"},"source":["tokenizer.add_tokens(data_config[\"special_tokens\"])\n","\n","transformer_model.resize_token_embeddings(len(tokenizer))"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Embedding(30537, 768)"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","metadata":{"id":"s7ORwS93eV40"},"source":["### Function to get datasets\n","* Change split sizes, if needed."]},{"cell_type":"code","metadata":{"id":"tWdSINdKeTLM","executionInfo":{"status":"ok","timestamp":1631085796047,"user_tz":-330,"elapsed":501,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"source":["def get_datasets():\n","    tokenizer.bos_token_id = [\"0\"] *50\n","    tokenizer.eos_token_id = [\"0\"]*50\n","    train_dataset, valid_dataset, test_dataset = load_dataset(tokenizer=tokenizer,\n","                                                              train_sz=50,\n","                                                              test_sz=50,\n","                                                              mask_tokens=discourse_markers,)\n","    print(train_dataset)\n","    return train_dataset, valid_dataset, test_dataset"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1wEc18EPVcYb","executionInfo":{"status":"ok","timestamp":1631085873553,"user_tz":-330,"elapsed":28772,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}},"outputId":"d345a936-6cd2-4605-881f-2b4bdb2f7adb"},"source":["x,y,z = get_datasets()\n","# print(x.next())"],"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["<tensorflow.python.data.ops.dataset_ops._NumpyIterator object at 0x7fb5fc4c7590>\n"]}]},{"cell_type":"markdown","metadata":{"id":"o0vzECspfT9q"},"source":["### Define layers for a Linear-Chain-CRF"]},{"cell_type":"code","metadata":{"id":"8Z0wI2FyfQN3","executionInfo":{"status":"ok","timestamp":1631085873553,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"source":["from allennlp.modules.conditional_random_field import ConditionalRandomField as crf\n","\n","ac_dict = data_config[\"arg_components\"]\n","\n","allowed_transitions =([(ac_dict[\"B-C\"], ac_dict[\"I-C\"]), \n","                       (ac_dict[\"B-P\"], ac_dict[\"I-P\"])] + \n","                      [(ac_dict[\"I-C\"], ac_dict[ct]) \n","                        for ct in [\"I-C\", \"B-C\", \"B-P\", \"O\"]] +\n","                      [(ac_dict[\"I-P\"], ac_dict[ct]) \n","                        for ct in [\"I-P\", \"B-C\", \"B-P\", \"O\"]] +\n","                      [(ac_dict[\"O\"], ac_dict[ct]) \n","                        for ct in [\"O\", \"B-C\", \"B-P\"]])\n","                    \n","linear_layer = nn.Linear(transformer_model.config.hidden_size,\n","                         len(ac_dict)).to(device)\n","\n","crf_layer = crf(num_tags=len(ac_dict),\n","                constraints=allowed_transitions,\n","                include_start_end_transitions=False).to(device)\n","\n","cross_entropy_layer = nn.CrossEntropyLoss(weight=torch.log(torch.tensor([3.3102, 61.4809, 3.6832, 49.6827, 2.5639], \n","                                                                        device=device)), reduction='none')"],"execution_count":58,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ckFXZTW3fnZK"},"source":["### Loss and Prediction Function"]},{"cell_type":"code","metadata":{"id":"4bKvGQjffYL4","executionInfo":{"status":"ok","timestamp":1631085873554,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"source":["from typing import Tuple"],"execution_count":59,"outputs":[]},{"cell_type":"code","metadata":{"id":"yIQbsEzbfZO2","executionInfo":{"status":"ok","timestamp":1631085873554,"user_tz":-330,"elapsed":6,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"source":["def compute(batch: Tuple[torch.Tensor, torch.Tensor, torch.Tensor],\n","            preds: bool=False, cross_entropy: bool=True):\n","    \"\"\"\n","    Args:\n","        batch:  A tuple having tokenized thread of shape [batch_size, seq_len],\n","                component type labels of shape [batch_size, seq_len], and a global\n","                attention mask for Longformer, of the same shape.\n","        \n","        preds:  If True, returns a List(of batch_size size) of Tuples of form \n","                (tag_sequence, viterbi_score) where the tag_sequence is the \n","                viterbi-decoded sequence, for the corresponding sample in the batch.\n","        \n","        cross_entropy:  This argument will only be used if preds=False, i.e., if \n","                        loss is being calculated. If True, then cross entropy loss\n","                        will also be added to the output loss.\n","    \n","    Returns:\n","        Either the predicted sequences with their scores for each element in the batch\n","        (if preds is True), or the loss value summed over all elements of the batch\n","        (if preds is False).\n","    \"\"\"\n","    tokenized_threads, token_type_ids, comp_type_labels = batch\n","    \n","    pad_mask = torch.where(tokenized_threads!=tokenizer.pad_token_id, 1, 0)\n","    \n","    logits = linear_layer(transformer_model(input_ids=tokenized_threads,\n","                                            attention_mask=pad_mask,).last_hidden_state)\n","    \n","    if preds:\n","        return crf_layer.viterbi_tags(logits, pad_mask)\n","    \n","    log_likelihood = crf_layer(logits, comp_type_labels, pad_mask)\n","    \n","    if cross_entropy:\n","        logits = logits.reshape(-1, logits.shape[-1])\n","        \n","        pad_mask, comp_type_labels = pad_mask.reshape(-1), comp_type_labels.reshape(-1)\n","        \n","        ce_loss = torch.sum(pad_mask*cross_entropy_layer(logits, comp_type_labels))\n","        \n","        return ce_loss - log_likelihood\n","\n","    return -log_likelihood"],"execution_count":60,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HHENTQyCfrXA"},"source":["### Define optimizer"]},{"cell_type":"code","metadata":{"id":"FJ1pZLSEftJ7","executionInfo":{"status":"ok","timestamp":1631085874339,"user_tz":-330,"elapsed":790,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"source":["from itertools import chain\n","\n","import torch.optim as optim\n","\n","optimizer = optim.Adam(params = chain(transformer_model.parameters(),\n","                                      linear_layer.parameters(),\n","                                      crf_layer.parameters()),\n","                       lr = 2e-5,)"],"execution_count":61,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ORtGK-SEfvaM"},"source":["### Training And Evaluation Loops"]},{"cell_type":"code","metadata":{"id":"axoEh9b4fvJI","executionInfo":{"status":"ok","timestamp":1631085874340,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"source":["def train(dataset):\n","    accumulate_over = 4\n","    \n","    optimizer.zero_grad()\n","\n","    for i, (tokenized_threads, masked_threads, comp_type_labels, _ ) in enumerate(dataset):\n","        \n","        #Remove Device Axis and cast to PyTorch tensor\n","        tokenized_threads = torch.tensor(np.squeeze(tokenized_threads, axis=0), \n","                                         device=device)\n","        masked_threads = torch.tensor(np.squeeze(masked_threads, axis=0), \n","                                      device=device)\n","        comp_type_labels = torch.tensor(np.squeeze(comp_type_labels, axis=0), \n","                                        device=device, dtype=torch.long)\n","        \n","        loss = compute((tokenized_threads,\n","                        torch.where(masked_threads==tokenizer.mask_token_id, 1, 0), \n","                        comp_type_labels,))/data_config[\"batch_size\"]\n","        \n","        print(\"Loss: \", loss)\n","        loss.backward()\n","        \n","        if i%accumulate_over==accumulate_over-1:\n","            optimizer.step()\n","            optimizer.zero_grad()\n","    \n","    optimizer.step()"],"execution_count":62,"outputs":[]},{"cell_type":"code","metadata":{"id":"fOIbNiAqfyP-","executionInfo":{"status":"ok","timestamp":1631085874340,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"source":["def evaluate(dataset, metric):\n","    \n","    int_to_labels = {v:k for k, v in ac_dict.items()}\n","    \n","    for tokenized_threads, masked_threads, comp_type_labels, _ in dataset:\n","    \n","        #Remove Device Axis and cast to PyTorch tensor\n","        tokenized_threads = torch.tensor(np.squeeze(tokenized_threads, axis=0),\n","                                        device=device)\n","        masked_threads = torch.tensor(np.squeeze(masked_threads, axis=0),\n","                                     device=device)\n","        comp_type_labels = torch.tensor(np.squeeze(comp_type_labels, axis=0),\n","                                        device=device)\n","        global_attention_mask = torch.squeeze(global_attention_mask, dim=0)\n","        \n","        preds = compute((tokenized_threads,\n","                         torch.where(masked_threads==tokenizer.mask_token_id, 1, 0), \n","                         comp_type_labels,), preds=True)\n","        \n","        lengths = torch.sum(torch.where(tokenized_threads!=tokenizer.pad_token_id, 1, 0), \n","                            axis=-1)\n","        \n","        preds = [ [int_to_labels[pred] for pred in pred[0][:lengths[i]]]\n","                  for i, pred in enumerate(preds)\n","                ]\n","        \n","        refs = [ [int_to_labels[ref] for ref in labels[:lengths[i]]]\n","                 for i, labels in enumerate(comp_type_labels.cpu().tolist())\n","               ]\n","        \n","        metric.add_batch(predictions=preds, \n","                         references=refs,)\n","                         #tokenized_threads=tokenized_threads.cpu().tolist())\n","    \n","    print(metric.compute())"],"execution_count":63,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3iWBULiFf0pq"},"source":["### Final Training"]},{"cell_type":"code","metadata":{"id":"sBHfu8F0f0RS","executionInfo":{"status":"ok","timestamp":1631085874342,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}}},"source":["n_epochs = 35\n"],"execution_count":64,"outputs":[]},{"cell_type":"code","metadata":{"id":"ldxdH0UBf32g","colab":{"base_uri":"https://localhost:8080/","height":459},"executionInfo":{"status":"error","timestamp":1631086071416,"user_tz":-330,"elapsed":78522,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7WujoeIi9pQg7KsDLqvOvz6TK-Yx_MZE9mnJUzw=s64","userId":"18135409234894719745"}},"outputId":"bd5754d8-2d3d-463b-e3c3-69d1041c59ba"},"source":["for epoch in range(n_epochs):\n","    print(f\"------------EPOCH {epoch+1}---------------\")\n","    train_dataset, _, test_dataset = get_datasets()\n","    train(train_dataset)\n","    evaluate(test_dataset, metric)"],"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["------------EPOCH 1---------------\n","<tensorflow.python.data.ops.dataset_ops._NumpyIterator object at 0x7fb5f90d3f90>\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-67-52fbc7af7ecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"------------EPOCH {epoch+1}---------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-62-e0aef3a792a4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     16\u001b[0m         loss = compute((tokenized_threads,\n\u001b[1;32m     17\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_threads\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_token_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                         comp_type_labels,))/data_config[\"batch_size\"]\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-60-4ccb85aaa5e1>\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(batch, preds, cross_entropy)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     logits = linear_layer(transformer_model(input_ids=tokenized_threads,\n\u001b[0;32m---> 27\u001b[0;31m                                             attention_mask=pad_mask,).last_hidden_state)\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m                 \u001b[0mbuffered_token_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m                 \u001b[0mbuffered_token_type_ids_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffered_token_type_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffered_token_type_ids_expanded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (4096) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [8, 4096].  Tensor sizes: [1, 512]"]}]}]}