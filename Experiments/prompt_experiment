{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"prompt_experiment","provenance":[],"authorship_tag":"ABX9TyPgiaeIcN6y2RQC1xEgimMa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"4c738c0e97654e3fad71b3b80df1f22f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_60cbfdfa9f0c40939595cc56be8dd51f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f388e5e2c05141d0b4044d7e22b5de70","IPY_MODEL_79055d051c334dff9b50d410c0e7e5d8","IPY_MODEL_39e363f773b1490ea76005145a3122e9"]}},"60cbfdfa9f0c40939595cc56be8dd51f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f388e5e2c05141d0b4044d7e22b5de70":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_caa11f95d9b0414f812d6c398f756749","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b734ee349a874bf2a113e29e690e9e78"}},"79055d051c334dff9b50d410c0e7e5d8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_941fbef4160446469df0b5e00d1fbfb6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d061e628a6d7488abe3405bcce25b123"}},"39e363f773b1490ea76005145a3122e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_080036f691574c55895d7d958f7182b3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 878k/878k [00:00&lt;00:00, 902kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9df722fcb4b44f418df399213fa4f3c0"}},"caa11f95d9b0414f812d6c398f756749":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b734ee349a874bf2a113e29e690e9e78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"941fbef4160446469df0b5e00d1fbfb6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d061e628a6d7488abe3405bcce25b123":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"080036f691574c55895d7d958f7182b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9df722fcb4b44f418df399213fa4f3c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d33dce7428974613830ba68dd7611f8e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5f906d1faf2c481c929a00943c9c87b0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c1a4052caa0441428a48d4c0c169e4dd","IPY_MODEL_0b58751450ad4414aa5f64b1e5eb958c","IPY_MODEL_18d28ba33a144ca2ad1b860b2e33adb8"]}},"5f906d1faf2c481c929a00943c9c87b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c1a4052caa0441428a48d4c0c169e4dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bfc89467afc645ca974ffe35f702c21f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7c4be4eea10c4850ae54acdf148e4341"}},"0b58751450ad4414aa5f64b1e5eb958c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8df5bfbccb234deaa18aa07a6cc1bcc6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1cfa5124da7c4fb9adff03344ecb2f78"}},"18d28ba33a144ca2ad1b860b2e33adb8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_31b74505aab24e09ad23524775e1c9a3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 446k/446k [00:00&lt;00:00, 693kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_01c856787a78455680857a6182148a10"}},"bfc89467afc645ca974ffe35f702c21f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7c4be4eea10c4850ae54acdf148e4341":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8df5bfbccb234deaa18aa07a6cc1bcc6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1cfa5124da7c4fb9adff03344ecb2f78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"31b74505aab24e09ad23524775e1c9a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"01c856787a78455680857a6182148a10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"228dcd35952b45a5beba1b09af74b0ed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3bd46c77ec824ce481d15a8975111f0e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c0f18c6290bd46f5b39b4b9b654541bd","IPY_MODEL_bbd4833ad50a4ae08136f5c742239487","IPY_MODEL_6acf97f60439447083985cb8fd5a12b7"]}},"3bd46c77ec824ce481d15a8975111f0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c0f18c6290bd46f5b39b4b9b654541bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2a508590120b4697a2036d4a850e17d3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8f4b8f966cac491a85363c81c4b3bbd7"}},"bbd4833ad50a4ae08136f5c742239487":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_eecc5765a86f47db9cc7a083d6d5d7ec","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1355863,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355863,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_905578596d954510863595b6477662b3"}},"6acf97f60439447083985cb8fd5a12b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f70b3e53b14d4d31b49b62d174a5131b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.29M/1.29M [00:00&lt;00:00, 5.57MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_62833c74451748d183298e3c76e7e972"}},"2a508590120b4697a2036d4a850e17d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8f4b8f966cac491a85363c81c4b3bbd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eecc5765a86f47db9cc7a083d6d5d7ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"905578596d954510863595b6477662b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f70b3e53b14d4d31b49b62d174a5131b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"62833c74451748d183298e3c76e7e972":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e0e1134aaedf41ccb75769e4c14fed3f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_38fa30fc2d8d4dadace1a202b7e7a197","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_987bdce16d8249b1961d3fea9ee9a1e0","IPY_MODEL_649d847073a3451ab9058ee70190ce30","IPY_MODEL_2f2f220debf347109cf4d6e9cfc93eca"]}},"38fa30fc2d8d4dadace1a202b7e7a197":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"987bdce16d8249b1961d3fea9ee9a1e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7386c5daa18a4a0cba3a0f6590b747c5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_86a3137d4fcf414f9fd02f951006587e"}},"649d847073a3451ab9058ee70190ce30":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_930947823bc741eaaa9ff0c2e5659637","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":694,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":694,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_11f51ffe29404399b4b9c3004bd30dc6"}},"2f2f220debf347109cf4d6e9cfc93eca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e98e6e7f43404763b1816189ccd2d3d8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 694/694 [00:00&lt;00:00, 15.3kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e46a8074dc7a4ab5a28c23bb4cf7b6bf"}},"7386c5daa18a4a0cba3a0f6590b747c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"86a3137d4fcf414f9fd02f951006587e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"930947823bc741eaaa9ff0c2e5659637":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"11f51ffe29404399b4b9c3004bd30dc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e98e6e7f43404763b1816189ccd2d3d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e46a8074dc7a4ab5a28c23bb4cf7b6bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c89b1ec4edc849aa9e31b5c257aa09e7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0fa0926c3b2341119dc0f0e992c13800","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_99d8318fa0d342c1aa7d9142518c32b1","IPY_MODEL_0144f3d0a01b4f9594267e21ebd2ee0f","IPY_MODEL_f1cc244d8d464f44abf5800493a73a5f"]}},"0fa0926c3b2341119dc0f0e992c13800":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"99d8318fa0d342c1aa7d9142518c32b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_810745d4d4bd4a39b69492d345c35db7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5ce24460792e41bdabea709618c12973"}},"0144f3d0a01b4f9594267e21ebd2ee0f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8955dbedfa1b481ba7551818d2d34ffa","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":597257159,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":597257159,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_10fd79724ca54dd5a30e4ee2008bb6ab"}},"f1cc244d8d464f44abf5800493a73a5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8c972328551d4ae0ba43f3f8f35d6f0b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 570M/570M [00:22&lt;00:00, 28.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b753b941bad2438ab24a9802c7354e86"}},"810745d4d4bd4a39b69492d345c35db7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5ce24460792e41bdabea709618c12973":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8955dbedfa1b481ba7551818d2d34ffa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"10fd79724ca54dd5a30e4ee2008bb6ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8c972328551d4ae0ba43f3f8f35d6f0b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b753b941bad2438ab24a9802c7354e86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"yeBLOK2BrBgh"},"source":["!pip install --upgrade google-cloud-storage"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z3gjmo2Bs1er"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QmThPX25rJYk"},"source":["!pip install transformers\n","!pip install seqeval datasets allennlp\n","!pip install flax\n","!pip install sentencepiece"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YIfyqHCys2ug","executionInfo":{"status":"ok","timestamp":1637753789053,"user_tz":-330,"elapsed":1805,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"}},"outputId":"0b9ef21e-042b-400d-989b-8b573555fc3a"},"source":["\n","!pip install torch"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in ./AM_prompt/lib/python3.6/site-packages (1.9.1)\r\n","Requirement already satisfied: typing-extensions in ./AM_prompt/lib/python3.6/site-packages (from torch) (3.10.0.2)\r\n","Requirement already satisfied: dataclasses in ./AM_prompt/lib/python3.6/site-packages (from torch) (0.8)\n","\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\n","You should consider upgrading via the '/home/tanmoy/AM_jeevesh/AM_prompt/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"ib6lPb3qu7Oh","executionInfo":{"status":"ok","timestamp":1637753961977,"user_tz":-330,"elapsed":5,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"}}},"source":["# Jedi not working\n","%config Completer.use_jedi = False"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"A6qG_k0Fq0Gv","executionInfo":{"status":"error","timestamp":1637753962557,"user_tz":-330,"elapsed":53,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"}},"outputId":"05970d4c-c98a-444c-e61d-6a281a9fc51f"},"source":["import warnings, random\n","from typing import Tuple, List, Union\n","warnings.filterwarnings('ignore')\n","\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","from itertools import chain\n","from transformers import LongformerTokenizer, LongformerModel\n","from sklearn.metrics import precision_recall_fscore_support as prf_metric\n","\n","from arg_mining.datasets.cmv_modes import load_dataset, data_config\n","\n","ac_dict = data_config[\"arg_components\"]\n","rel_type_dict = {rel : i for i, rel in enumerate(data_config[\"adv_relations_map\"].keys())}\n","rel_type_dict.pop(\"None\")\n","\n","user_tokens = [\"[UNU]\"]+[f\"[USER{i}]\" for i in range(data_config[\"max_users\"])]\n","num_mask_pos = 3\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","class precision_recall_fscore():\n","\n","    def __init__(self):\n","        self.preds = []\n","        self.refs = []\n","\n","    def add_batch(self, predictions, references):\n","        self.preds += predictions\n","        self.refs += references\n","\n","    def compute(self):\n","        f1_metrics = {\"precision\" : {}, \"recall\" : {},\n","                      \"f1\": {}, \"support\": {}} \n","        precision, recall, f1, supp = prf_metric(self.refs, self.preds, \n","                                                 labels=list(rel_type_dict.keys()))\n","\n","        for i, k in enumerate(rel_type_dict.keys()):\n","            f1_metrics[\"precision\"][k] = precision[i]\n","            f1_metrics[\"recall\"][k] = recall[i]\n","            f1_metrics[\"f1\"][k] = f1[i]\n","            f1_metrics[\"support\"][k] = supp[i]\n","\n","        for avg in [\"micro\", \"macro\", \"weighted\"]:\n","            precision, recall, f1, supp = prf_metric(self.refs, self.preds,\n","                                                     labels=list(rel_type_dict.keys()), average=avg)\n","            f1_metrics[avg+\"_avg\"] = {}\n","            f1_metrics[avg+\"_avg\"][\"precision\"] = precision \n","            f1_metrics[avg+\"_avg\"][\"recall\"] = recall\n","            f1_metrics[avg+\"_avg\"][\"f1\"] = f1\n","            f1_metrics[avg+\"_avg\"][\"support\"] = supp\n","\n","        self.preds = []\n","        self.refs = []\n","\n","        return f1_metrics\n","\n","metric = precision_recall_fscore()\n","\n","def get_tok_model(tokenizer_version, model_version):\n","    tokenizer = LongformerTokenizer.from_pretrained(tokenizer_version)\n","    transformer_model = LongformerModel.from_pretrained(model_version).to(device)\n","    if tokenizer_version=='allenai/longformer-base-4096':\n","        tokenizer.add_tokens(data_config[\"special_tokens\"])\n","    if model_version=='allenai/longformer-base-4096':\n","        transformer_model.resize_token_embeddings(len(tokenizer))\n","    return tokenizer, transformer_model\n","\n"],"execution_count":2,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-762741653331>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"]}]},{"cell_type":"code","metadata":{"id":"qukib-TmrhcG","executionInfo":{"status":"ok","timestamp":1637750759491,"user_tz":-330,"elapsed":403,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"}}},"source":[""],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"mv1TIwcgkpNT","executionInfo":{"status":"ok","timestamp":1637751679732,"user_tz":-330,"elapsed":380,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"}}},"source":["\"\"\"#### Load in discourse markers\"\"\"\n","flag = 4\n","with open('./Discourse_Markers.txt') as f:\n","    discourse_markers = [dm.strip() for dm in f.readlines()]\n","\n","\"\"\"#### Function to get train, test data (50/50 split currently)\"\"\"\n","\n","def get_datasets(train_sz=100, test_sz=0):\n","    train_dataset, valid_dataset, test_dataset = load_dataset(tokenizer=tokenizer,\n","                                                              train_sz=train_sz,\n","                                                              test_sz=test_sz,\n","                                                              shuffle=True,\n","                                                              mask_tokens=discourse_markers)\n","    return train_dataset, valid_dataset, test_dataset\n","\n","\"\"\"### Define linear layer for a relation type prediction\"\"\"\n","\n","def get_rel_head():\n","    linear_layer = nn.Linear(num_mask_pos*transformer_model.config.hidden_size,\n","                             len(rel_type_dict)).to(device)\n","\n","    return linear_layer\n","\n","\"\"\"### Global Attention Mask Utility for Longformer\"\"\"\n","\n","def get_global_attention_mask(tokenized_threads: np.ndarray) -> np.ndarray:\n","    \"\"\"Returns an attention mask, with 1 where there are [USER{i}] tokens and \n","    0 elsewhere.\n","    \"\"\"\n","    mask = np.zeros_like(tokenized_threads)\n","    return np.array(mask, dtype=bool)\n","\n","def get_spans(comp_type_labels, length):\n","    \n","    def detect_span(start_idx: int, span_t: str):\n","        j = start_idx\n","        while j<length and comp_type_labels[j]==ac_dict[span_t]:\n","            j += 1\n","        end_idx = j\n","        return start_idx, end_idx\n","    \n","    i=0\n","    spans_lis = []\n","    while i<length:\n","        if comp_type_labels[i]==ac_dict[\"O\"]:\n","            _start_idx, end_idx = detect_span(i, \"O\")\n","\n","        elif comp_type_labels[i]==ac_dict[\"B-C\"]:\n","            _start_idx, end_idx = detect_span(i+1, \"I-C\")\n","            spans_lis.append((i, end_idx))\n","            \n","        elif comp_type_labels[i]==ac_dict[\"B-P\"]:\n","            _start_idx, end_idx = detect_span(i+1, \"I-P\")\n","            spans_lis.append((i, end_idx))\n","        \n","        elif (comp_type_labels[i]==ac_dict[\"I-C\"] or\n","              comp_type_labels[i]==ac_dict[\"I-P\"]):\n","            raise AssertionError(\"Span detection not working properly, \\\n","                                  Or intermediate tokens without begin tokens in\",\n","                                 comp_type_labels)\n","        else:\n","            raise ValueError(\"Unknown component type:\", comp_type_labels[i], \n","                             \"Known types are:\", ac_dict)\n","        \n","        i = end_idx\n","    \n","    return spans_lis\n","\n","def get_user_token_positions(tokenized_thread):\n","    user_token_indices = [tokenizer.encode(user_token)[1] for user_token in user_tokens]\n","    user_token_pos = []\n","    for i, elem in enumerate(tokenized_thread):\n","        if elem in user_token_indices:\n","            user_token_pos.append(i)\n","    return user_token_pos\n","\n","def generate_prompts(tokenized_thread, comp_type_labels, refers_to_and_type):\n","\n","    length = np.sum(tokenized_thread!=tokenizer.pad_token_id)\n","    spans_lis = get_spans(comp_type_labels, length)\n","    user_token_pos = get_user_token_positions(tokenized_thread)\n","    for (link_from, link_to, rel_type) in refers_to_and_type:\n","        \n","        if link_to==0:\n","            continue\n","        \n","        from_start_idx, from_end_idx = spans_lis[link_from-1]\n","        to_start_idx, to_end_idx = spans_lis[link_to-1]\n","        \n","        from_user_token_id, to_user_token_id = 0, 0\n","        \n","        for elem in user_token_pos:\n","            if elem<=from_start_idx:\n","                from_user_token_id = tokenized_thread[elem]\n","            if elem<=to_start_idx:\n","                to_user_token_id = tokenized_thread[elem]\n","            if elem>from_start_idx and elem>to_start_idx:\n","                break\n","        \n","        from_seq_length = from_end_idx-from_start_idx\n","        to_seq_length = to_end_idx - to_start_idx\n","        \n","        # part 1\n","        if(flag == 1):\n","            prompt = np.array([tokenizer.mask_token_id]*len(tokenized_thread))\n","        else:\n","            prompt = np.copy(tokenized_thread)\n","\n","        # part 2\n","        if (flag != 2):\n","            prompt[length] = to_user_token_id\n","            prompt[length+1] = tokenizer.encode(\" said\")[1]\n","            \n","            mask_pos = length+2+to_seq_length\n","            \n","            prompt[length+2:mask_pos] = tokenized_thread[to_start_idx:to_end_idx]\n","        else:\n","            mask_pos = length + 2 + to_seq_length\n","            prompt[length:mask_pos] = np.array([tokenizer.mask_token_id]*(mask_pos - length))\n","        \n","        # mid part\n","        prompt[mask_pos:mask_pos+num_mask_pos] = [tokenizer.mask_token_id]*num_mask_pos\n","        \n","\n","        # end part\n","        if (flag != 3):\n","            prompt[mask_pos+num_mask_pos] = from_user_token_id\n","            prompt[mask_pos+num_mask_pos+1] = tokenizer.encode(\" said\")[1]\n","            prompt[mask_pos+num_mask_pos+2:mask_pos+num_mask_pos+2+from_seq_length] = tokenized_thread[from_start_idx:from_end_idx]\n","        else:\n","            prompt[mask_pos + num_mask_pos : mask_pos + num_mask_pos + 2 + from_seq_length] = np.array([tokenizer.mask_token_id]*(2 + from_seq_length))\n","           \n","        yield (prompt, rel_type)\n","\n","def get_prompt_generator(dataset, batch_size, shuffle=True):\n","    prompt_dataset = []\n","    \n","    for (tokenized_threads, _, comp_type_labels, refers_to_and_type) in dataset:\n","        tokenized_threads = tokenized_threads[0]\n","        comp_type_labels = comp_type_labels[0]\n","        refers_to_and_type = refers_to_and_type[0]\n","        for (sample_tokenized_thread, \n","            sample_comp_type_labels, \n","            sample_refers_to_and_type) in zip(tokenized_threads, \n","                                            comp_type_labels, \n","                                            refers_to_and_type):\n","                \n","            prompt_dataset += [elem for elem in generate_prompts(sample_tokenized_thread, \n","                                                                sample_comp_type_labels,\n","                                                                sample_refers_to_and_type)]\n","    if shuffle:\n","        random.shuffle(prompt_dataset)\n","    \n","    def prompt_dataset_gen():\n","        batch_of_prompts = []\n","        rel_type_labels = []\n","        for prompt, rel_type in prompt_dataset:\n","            batch_of_prompts.append(prompt)\n","            rel_type_labels.append(rel_type)\n","            if len(batch_of_prompts)==batch_size:\n","                yield np.array(batch_of_prompts, dtype=np.int32), np.array(rel_type_labels, dtype=np.int32)\n","                batch_of_prompts, rel_type_labels = [], []\n","    \n","    return prompt_dataset_gen\n","\n","\"\"\"### Loss and Prediction Function\"\"\"\n","\n","cross_entropy_layer = nn.CrossEntropyLoss(weight=torch.tensor([0.508, 2.027, 2.402, 2.234, 2.667], \n","                                                              device=device), reduction='sum')\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"_vYkJCWBrmRq","executionInfo":{"status":"ok","timestamp":1637751776631,"user_tz":-330,"elapsed":686,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"}}},"source":["\n","def compute(batch: Tuple[torch.Tensor, torch.Tensor, torch.Tensor],\n","            preds: bool=False,) -> Union[List[torch.Tensor], torch.Tensor]:\n","    \"\"\"\n","    Args:\n","        batch:  A tuple having prompting thread of shape [batch_size, seq_len],\n","                and relation type labels of shape [batch_size], and global attention mask\n","                for longformer of shape [batch_size, seq_len] with 1 for tokens which attend\n","                globally.\n","        \n","        preds:  If True, returns a List(of batch_size size) of relation predictions\n","                for correspoding prompts in the batch.\n","    Returns:\n","        Either the predicted relations(if preds is True), or the loss value \n","        summed over all samples of the batch (if preds is False).\n","    \"\"\"\n","    prompt_threads, rel_type_labels, global_attention_mask = batch\n","    \n","    pad_mask = torch.where(prompt_threads!=tokenizer.pad_token_id, 1, 0)\n","    \n","    hidden_state = transformer_model(input_ids=prompt_threads,\n","                                     attention_mask=pad_mask,\n","                                     global_attention_mask=global_attention_mask).last_hidden_state\n","    \n","    hidden_state = hidden_state[prompt_threads==tokenizer.mask_token_id]\n","    hidden_state = hidden_state.reshape(-1, num_mask_pos, hidden_state.shape[-1])\n","    hidden_state = torch.flatten(hidden_state, start_dim=1)\n","    rel_type_logits = linear_layer(hidden_state)\n","\n","    if preds:\n","        return torch.max(rel_type_logits, dim=-1).indices\n","    \n","    ce_loss = cross_entropy_layer(rel_type_logits, rel_type_labels)\n","\n","    return ce_loss\n","\n","\"\"\"### Training And Evaluation Loops\"\"\"\n","\n","def train(dataset):\n","    accumulate_over = 4\n","    \n","    optimizer.zero_grad()\n","\n","    for i, (prompt_threads, rel_type_labels) in enumerate(\n","                                                    get_prompt_generator(dataset, \n","                                                                         batch_size=data_config[\"batch_size\"])()):\n","        \n","        global_attention_mask = torch.tensor(get_global_attention_mask(prompt_threads),\n","                                             device=device, dtype=torch.int32)\n","        \n","        #Cast to PyTorch tensor\n","        prompt_threads = torch.tensor(prompt_threads, device=device, dtype=torch.long)\n","        rel_type_labels = torch.tensor(rel_type_labels, device=device, dtype=torch.long)\n","        global_attention_mask = torch.squeeze(global_attention_mask, dim=0)\n","        \n","        loss = compute((prompt_threads,\n","                        rel_type_labels,\n","                        global_attention_mask))/data_config[\"batch_size\"]\n","\n","        print(\"Loss:\", loss)\n","        \n","        loss.backward()\n","        \n","        if i%accumulate_over==accumulate_over-1:\n","            optimizer.step()\n","            optimizer.zero_grad()\n","    \n","    optimizer.step()\n","\n","def evaluate(dataset, metric):\n","    \n","    int_to_labels = {v:k for k, v in rel_type_dict.items()}\n","\n","    with torch.no_grad():\n","        for prompt_threads, rel_type_labels in get_prompt_generator(dataset,\n","                                                                    batch_size=data_config[\"batch_size\"])():\n","            print(\"Evaluating\") \n","            global_attention_mask = torch.tensor(get_global_attention_mask(prompt_threads), \n","                                                 device=device)\n","            \n","            #Cast to PyTorch tensor\n","            prompt_threads = torch.tensor(prompt_threads, device=device, dtype=torch.long)\n","            rel_type_labels = torch.tensor(rel_type_labels, device=device, dtype=torch.long)\n","            global_attention_mask = torch.squeeze(global_attention_mask, dim=0)\n","            \n","            preds = compute((prompt_threads,\n","                             rel_type_labels,\n","                             global_attention_mask),\n","                            preds=True)\n","            \n","            preds = [int_to_labels[pred.item()] for pred in preds]\n","            refs =  [int_to_labels[ref.item()] for ref in rel_type_labels]\n","            \n","            metric.add_batch(predictions=preds,\n","                             references=refs,)\n","        \n","    print(\"\\t\\t\\t\\t\", metric.compute())\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":675,"referenced_widgets":["4c738c0e97654e3fad71b3b80df1f22f","60cbfdfa9f0c40939595cc56be8dd51f","f388e5e2c05141d0b4044d7e22b5de70","79055d051c334dff9b50d410c0e7e5d8","39e363f773b1490ea76005145a3122e9","caa11f95d9b0414f812d6c398f756749","b734ee349a874bf2a113e29e690e9e78","941fbef4160446469df0b5e00d1fbfb6","d061e628a6d7488abe3405bcce25b123","080036f691574c55895d7d958f7182b3","9df722fcb4b44f418df399213fa4f3c0","d33dce7428974613830ba68dd7611f8e","5f906d1faf2c481c929a00943c9c87b0","c1a4052caa0441428a48d4c0c169e4dd","0b58751450ad4414aa5f64b1e5eb958c","18d28ba33a144ca2ad1b860b2e33adb8","bfc89467afc645ca974ffe35f702c21f","7c4be4eea10c4850ae54acdf148e4341","8df5bfbccb234deaa18aa07a6cc1bcc6","1cfa5124da7c4fb9adff03344ecb2f78","31b74505aab24e09ad23524775e1c9a3","01c856787a78455680857a6182148a10","228dcd35952b45a5beba1b09af74b0ed","3bd46c77ec824ce481d15a8975111f0e","c0f18c6290bd46f5b39b4b9b654541bd","bbd4833ad50a4ae08136f5c742239487","6acf97f60439447083985cb8fd5a12b7","2a508590120b4697a2036d4a850e17d3","8f4b8f966cac491a85363c81c4b3bbd7","eecc5765a86f47db9cc7a083d6d5d7ec","905578596d954510863595b6477662b3","f70b3e53b14d4d31b49b62d174a5131b","62833c74451748d183298e3c76e7e972","e0e1134aaedf41ccb75769e4c14fed3f","38fa30fc2d8d4dadace1a202b7e7a197","987bdce16d8249b1961d3fea9ee9a1e0","649d847073a3451ab9058ee70190ce30","2f2f220debf347109cf4d6e9cfc93eca","7386c5daa18a4a0cba3a0f6590b747c5","86a3137d4fcf414f9fd02f951006587e","930947823bc741eaaa9ff0c2e5659637","11f51ffe29404399b4b9c3004bd30dc6","e98e6e7f43404763b1816189ccd2d3d8","e46a8074dc7a4ab5a28c23bb4cf7b6bf","c89b1ec4edc849aa9e31b5c257aa09e7","0fa0926c3b2341119dc0f0e992c13800","99d8318fa0d342c1aa7d9142518c32b1","0144f3d0a01b4f9594267e21ebd2ee0f","f1cc244d8d464f44abf5800493a73a5f","810745d4d4bd4a39b69492d345c35db7","5ce24460792e41bdabea709618c12973","8955dbedfa1b481ba7551818d2d34ffa","10fd79724ca54dd5a30e4ee2008bb6ab","8c972328551d4ae0ba43f3f8f35d6f0b","b753b941bad2438ab24a9802c7354e86"]},"id":"OHF48iIzm-Ei","executionInfo":{"status":"error","timestamp":1637751808796,"user_tz":-330,"elapsed":28116,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"}},"outputId":"f3d2dc93-12e5-4701-9696-8e9593253a91"},"source":["\"\"\"### Final Training\"\"\"\n","\n","n_epochs = 30\n","n_runs = 1\n","tokenizer_version, model_version = ('allenai/longformer-base-4096', 'allenai/longformer-base-4096')\n","\n","tokenizer, transformer_model = get_tok_model(tokenizer_version, model_version)\n","\n","\n","linear_layer = get_rel_head()\n","optimizer = optim.Adam(params = chain(transformer_model.parameters(),\n","                          linear_layer.parameters(),),\n","                        lr = 2e-5,)\n","for (tokenizer_version, model_version) in [\n","                                           ('allenai/longformer-base-4096', 'allenai/longformer-base-4096')]:\n","\n","    print(\"Tokenizer:\", tokenizer_version, \"Model:\", model_version)\n","    \n","    for (train_sz, test_sz) in [(50,50)]:\n","    \n","        print(\"\\tTrain size:\", train_sz, \"Test size:\", test_sz)\n","        \n","        for run in range(n_runs):\n","            print(f\"\\n\\n\\t\\t-------------RUN {run+1}-----------\")\n","\n","            train_dataset, _, test_dataset = get_datasets(train_sz, test_sz)\n","            train_dataset = [elem for elem in train_dataset]\n","            test_dataset = [elem for elem in test_dataset]\n","\n","            for epoch in range(n_epochs):\n","                print(f\"\\t\\t\\t------------EPOCH {epoch+1}---------------\")\n","                evaluate(test_dataset, metric)\n","                train(train_dataset)\n"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4c738c0e97654e3fad71b3b80df1f22f","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d33dce7428974613830ba68dd7611f8e","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"228dcd35952b45a5beba1b09af74b0ed","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e0e1134aaedf41ccb75769e4c14fed3f","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/694 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c89b1ec4edc849aa9e31b5c257aa09e7","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/570M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias']\n","- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Tokenizer: allenai/longformer-base-4096 Model: allenai/longformer-base-4096\n","\tTrain size: 50 Test size: 50\n","\n","\n","\t\t-------------RUN 1-----------\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-9a6d39477799>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n\\n\\t\\t-------------RUN {run+1}-----------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0melem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0melem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-bab3c4c457fd>\u001b[0m in \u001b[0;36mget_datasets\u001b[0;34m(train_sz, test_sz)\u001b[0m\n\u001b[1;32m     11\u001b[0m                                                               \u001b[0mtest_sz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_sz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                                               mask_tokens=discourse_markers)\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: load_dataset() got an unexpected keyword argument 'mask_tokens'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":502},"id":"slw8ftk-rpoo","executionInfo":{"status":"error","timestamp":1637750805264,"user_tz":-330,"elapsed":21595,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"}},"outputId":"f9fee361-da15-4e99-c3dd-c05651e9fe2e"},"source":["\n","\"\"\"### Final Training\"\"\"\n","\n","n_epochs = 30\n","n_runs = 1\n","\n","\n","linear_layer = get_rel_head()\n","\n","optimizer = optim.Adam(params = chain(transformer_model.parameters(),\n","                          linear_layer.parameters(),),\n","                        lr = 2e-5,)\n","for (train_sz, test_sz) in [(50,50)]:\n","    print(\"Train size:\", train_sz, \"Test size:\", test_sz)\n","\n","    for (tokenizer_version, model_version) in [('allenai/longformer-base-4096', 'allenai/longformer-base-4096')]:\n","\n","        print(\"\\tTokenizer:\", tokenizer_version, \"Model:\", model_version)\n","        \n","        for run in range(n_runs):\n","            print(f\"\\n\\n\\t\\t-------------RUN {run+1}-----------\")\n","            \n","\n","\n","            train_dataset, _, test_dataset = get_datasets(train_sz, test_sz)\n","            train_dataset = [elem for elem in train_dataset]\n","            test_dataset = [elem for elem in test_dataset]\n","\n","            for epoch in range(n_epochs):\n","                print(f\"\\t\\t\\t------------EPOCH {epoch+1}---------------\")\n","                train(train_dataset)\n","                evaluate(test_dataset, metric)\n","           \n","            # del tokenizer, transformer_model, linear_layer"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Train size: 50 Test size: 50\n","\tTokenizer: allenai/longformer-base-4096 Model: allenai/longformer-base-4096\n","\n","\n","\t\t-------------RUN 1-----------\n"]},{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (759 > 512). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["\t\t\t------------EPOCH 1---------------\n"]},{"output_type":"error","ename":"AssertionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-9b0df60f4671>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\t\\t\\t------------EPOCH {epoch+1}---------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-0f098859ed45>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     48\u001b[0m     for i, (prompt_threads, rel_type_labels) in enumerate(\n\u001b[1;32m     49\u001b[0m                                                     get_prompt_generator(dataset,\n\u001b[0;32m---> 50\u001b[0;31m                                                                          batch_size=2)()):\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         global_attention_mask = torch.tensor(get_global_attention_mask(prompt_threads),\n","\u001b[0;32m<ipython-input-6-553b30020bb9>\u001b[0m in \u001b[0;36mget_prompt_generator\u001b[0;34m(dataset, batch_size, shuffle)\u001b[0m\n\u001b[1;32m    183\u001b[0m             prompt_dataset += [elem for elem in generate_prompts(sample_tokenized_thread,\n\u001b[1;32m    184\u001b[0m                                                                  \u001b[0msample_comp_type_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                                                                  sample_refers_to_and_type)]\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-553b30020bb9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    181\u001b[0m                                                refers_to_and_type):\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             prompt_dataset += [elem for elem in generate_prompts(sample_tokenized_thread,\n\u001b[0m\u001b[1;32m    184\u001b[0m                                                                  \u001b[0msample_comp_type_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                                                                  sample_refers_to_and_type)]\n","\u001b[0;32m<ipython-input-6-553b30020bb9>\u001b[0m in \u001b[0;36mgenerate_prompts\u001b[0;34m(tokenized_thread, comp_type_labels, refers_to_and_type)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 raise AssertionError(\"Please set max_len in load_dataset so that the sequence length:\", length,\n\u001b[1;32m    166\u001b[0m                                     \u001b[0;34m\"doesn't execeed the maximum length:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_max_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                                     \"after adding prompt of length:\", prompt.shape[0]-length)\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: ('Please set max_len in load_dataset so that the sequence length:', 2360, \"doesn't execeed the maximum length:\", 512, 'after adding prompt of length:', 35)"]}]},{"cell_type":"code","metadata":{"id":"MHkhD_sm13aP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jPLh5woV13o5"},"source":["No masking"]},{"cell_type":"code","metadata":{"id":"ea85RSqp1p2u"},"source":["global_flag = 0\n","train_dataset, _, test_dataset = get_datasets(train_sz, test_sz)\n","train_dataset = [elem for elem in train_dataset]\n","test_dataset = [elem for elem in test_dataset]\n","evaluate(test_dataset, metric)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"15YPjqEs154x"},"source":["Sentence masking"]},{"cell_type":"code","metadata":{"id":"IPtpp3S01yl6"},"source":["global_flag = 1\n","train_dataset, _, test_dataset = get_datasets(train_sz, test_sz)\n","train_dataset = [elem for elem in train_dataset]\n","test_dataset = [elem for elem in test_dataset]\n","evaluate(test_dataset, metric)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h7gVqep019cE"},"source":["component 1 masking"]},{"cell_type":"code","metadata":{"id":"0Y3x6jRr1y7w"},"source":["global_flag = 2\n","train_dataset, _, test_dataset = get_datasets(train_sz, test_sz)\n","train_dataset = [elem for elem in train_dataset]\n","test_dataset = [elem for elem in test_dataset]\n","evaluate(test_dataset, metric)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0bgChpoA2ARS"},"source":["component 2 masking"]},{"cell_type":"code","metadata":{"id":"3aASe_Ox1169"},"source":["global_flag = 3\n","train_dataset, _, test_dataset = get_datasets(train_sz, test_sz)\n","train_dataset = [elem for elem in train_dataset]\n","test_dataset = [elem for elem in test_dataset]\n","evaluate(test_dataset, metric)"],"execution_count":null,"outputs":[]}]}