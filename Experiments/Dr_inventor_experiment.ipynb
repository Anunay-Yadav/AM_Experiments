{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Dr_inventor_experiment.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9c22115be3754d80bbc648f678dafd09":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_647820e3310048b4b3d665a6a75b6005","IPY_MODEL_671122ff41d342dbb2771ecf3e494b1c","IPY_MODEL_cfd0cb7ef2ce4340b47176f2eb7b1b35"],"layout":"IPY_MODEL_a9a0013944004dea9002a569e2383b08"}},"647820e3310048b4b3d665a6a75b6005":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e0c3660440e47dd90502b736a051e9e","placeholder":"​","style":"IPY_MODEL_83b0f803343247f99e56eb144a7670d1","value":"Downloading: "}},"671122ff41d342dbb2771ecf3e494b1c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_14c91935cf8247df906ef3fb284971d2","max":2482,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c40951b827b842a1a1b20d2b0de8302c","value":2482}},"cfd0cb7ef2ce4340b47176f2eb7b1b35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a60a3094c224ef99c19fadba9817ebe","placeholder":"​","style":"IPY_MODEL_ce6c18a4cb4248e9a8bbcca271943216","value":" 6.34k/? [00:00&lt;00:00, 152kB/s]"}},"a9a0013944004dea9002a569e2383b08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e0c3660440e47dd90502b736a051e9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83b0f803343247f99e56eb144a7670d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14c91935cf8247df906ef3fb284971d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c40951b827b842a1a1b20d2b0de8302c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5a60a3094c224ef99c19fadba9817ebe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce6c18a4cb4248e9a8bbcca271943216":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3972095409bc407a89347c1569e7dbcd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cc931beebf7b41fd9519c02875dd262b","IPY_MODEL_88e231e3ea0d458ea65dbb4a65e6c2fc","IPY_MODEL_aa25984c7816465fadc49a2481315b86"],"layout":"IPY_MODEL_8f9969b455ec4abcae9fc8c7777e96e6"}},"cc931beebf7b41fd9519c02875dd262b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8befe8370649463f91578f3790a434b6","placeholder":"​","style":"IPY_MODEL_e3400bb18c9e41da8e28e7675504e3f4","value":"Downloading: 100%"}},"88e231e3ea0d458ea65dbb4a65e6c2fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c73fad36e644c8bb316d3e40059f90e","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4839d81b4cc4bca8b1a915fc1a56be6","value":29}},"aa25984c7816465fadc49a2481315b86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9eb391e56f747f7aa65053c27dd10bc","placeholder":"​","style":"IPY_MODEL_b66d9daaee0045918762c8a0a82048c8","value":" 29.0/29.0 [00:00&lt;00:00, 728B/s]"}},"8f9969b455ec4abcae9fc8c7777e96e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8befe8370649463f91578f3790a434b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3400bb18c9e41da8e28e7675504e3f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c73fad36e644c8bb316d3e40059f90e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4839d81b4cc4bca8b1a915fc1a56be6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b9eb391e56f747f7aa65053c27dd10bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b66d9daaee0045918762c8a0a82048c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4e8ac9d1dff4cddb20eafed8c56fc90":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2629f0919174437f93231229f956ef5e","IPY_MODEL_0efbf5fb649d4224b4451c68f130c0cb","IPY_MODEL_8ead96d7b06c429cbfb00c28c3ca0eec"],"layout":"IPY_MODEL_a85847c307b44c0da83844b3e43b8309"}},"2629f0919174437f93231229f956ef5e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b082ababe8244f86a88490c470563677","placeholder":"​","style":"IPY_MODEL_5b7467f3d6e349e3b931e608576dded2","value":"Downloading: 100%"}},"0efbf5fb649d4224b4451c68f130c0cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2c8f59ea30c4bfabe78f9f8725d8558","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a5ddcc86075b48cc84196f7eef6a39b6","value":570}},"8ead96d7b06c429cbfb00c28c3ca0eec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77d932fa25da4c61a85a21b2b6e45b69","placeholder":"​","style":"IPY_MODEL_0884c0ae0e6f40bc9971515db5b4991c","value":" 570/570 [00:00&lt;00:00, 14.5kB/s]"}},"a85847c307b44c0da83844b3e43b8309":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b082ababe8244f86a88490c470563677":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b7467f3d6e349e3b931e608576dded2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2c8f59ea30c4bfabe78f9f8725d8558":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5ddcc86075b48cc84196f7eef6a39b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"77d932fa25da4c61a85a21b2b6e45b69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0884c0ae0e6f40bc9971515db5b4991c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e7e68fc49184b8d82ee5165b4364142":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_69ef115890674742bcd028e7c3056849","IPY_MODEL_5c78157ad49a4458aba7f997675bb3a2","IPY_MODEL_5753325723584257b0a71c70222403e4"],"layout":"IPY_MODEL_985e9605abbf4eb58a73ce740c1db5fa"}},"69ef115890674742bcd028e7c3056849":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b44138d97b448ecad4d0f5dc58e8c2a","placeholder":"​","style":"IPY_MODEL_6e3864bd132c4b0d8ce0cb4f25a040e0","value":"Downloading: 100%"}},"5c78157ad49a4458aba7f997675bb3a2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_045a2a0089294ebcbe7a32fde7cf9748","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d8c27adafa7347fc9fb9f98a90753265","value":213450}},"5753325723584257b0a71c70222403e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f3eda40bede425ebde200ce81f9d875","placeholder":"​","style":"IPY_MODEL_0bb59cd7670f4a09ae9d491887d71ab5","value":" 208k/208k [00:00&lt;00:00, 1.05MB/s]"}},"985e9605abbf4eb58a73ce740c1db5fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b44138d97b448ecad4d0f5dc58e8c2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e3864bd132c4b0d8ce0cb4f25a040e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"045a2a0089294ebcbe7a32fde7cf9748":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8c27adafa7347fc9fb9f98a90753265":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5f3eda40bede425ebde200ce81f9d875":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bb59cd7670f4a09ae9d491887d71ab5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15d8a07f061f49cba2b726075bfe8d14":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cd4184948ed648c1ac62ddbf4eac561f","IPY_MODEL_f2706fa9bb014c6d9024198fd244008d","IPY_MODEL_d91ec999ab874475aef7af7e603f3909"],"layout":"IPY_MODEL_94a6259d08714e6b8925ac482b27fbd5"}},"cd4184948ed648c1ac62ddbf4eac561f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34d5fdaf77dc43f9ada4921fb714f970","placeholder":"​","style":"IPY_MODEL_77468cb0d40042d3ae6da974ad58aec2","value":"Downloading: 100%"}},"f2706fa9bb014c6d9024198fd244008d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7771a4cfdfca49ad812d5b8c0c18bb62","max":435797,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6fcdfb475abb415f93b9cde1fad98d91","value":435797}},"d91ec999ab874475aef7af7e603f3909":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93e8ddfde24b44d598ba3a4920c38558","placeholder":"​","style":"IPY_MODEL_04e51f8bc3fd47f4b558d05cfbff3037","value":" 426k/426k [00:00&lt;00:00, 1.14MB/s]"}},"94a6259d08714e6b8925ac482b27fbd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34d5fdaf77dc43f9ada4921fb714f970":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77468cb0d40042d3ae6da974ad58aec2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7771a4cfdfca49ad812d5b8c0c18bb62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fcdfb475abb415f93b9cde1fad98d91":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"93e8ddfde24b44d598ba3a4920c38558":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04e51f8bc3fd47f4b558d05cfbff3037":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e8efad7d48046abbb357159e73edbd2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f3bc3b13d7c54892889cc945db3d8c0a","IPY_MODEL_f3e96c42dfd743e3bbda00f0210b8965","IPY_MODEL_db3776c740474ae880e48309f92a1787"],"layout":"IPY_MODEL_f445f61661b14285b033cb98b644c717"}},"f3bc3b13d7c54892889cc945db3d8c0a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30760f891f204c8fb58051b57b11e114","placeholder":"​","style":"IPY_MODEL_121f87f2cfd34db9b9da62a9c8aec62b","value":"Downloading: 100%"}},"f3e96c42dfd743e3bbda00f0210b8965":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bee9be5dcf2d40c28fd36b2e4d871780","max":435779157,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a8442b238dd40a5a443e58184295c86","value":435779157}},"db3776c740474ae880e48309f92a1787":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52e494dd32df41b59004d235b364fd74","placeholder":"​","style":"IPY_MODEL_0b0443268738491f8f45ac77643cf4f7","value":" 416M/416M [00:15&lt;00:00, 30.1MB/s]"}},"f445f61661b14285b033cb98b644c717":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30760f891f204c8fb58051b57b11e114":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"121f87f2cfd34db9b9da62a9c8aec62b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bee9be5dcf2d40c28fd36b2e4d871780":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a8442b238dd40a5a443e58184295c86":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"52e494dd32df41b59004d235b364fd74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b0443268738491f8f45ac77643cf4f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2jNi3Z0gh84T","executionInfo":{"elapsed":397,"status":"ok","timestamp":1637189201254,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"},"user_tz":-330},"outputId":"49c3eb35-f4c6-4fa1-8b71-2f5b05417e58"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd drive/MyDrive/Bert_Lime"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Bert_Lime\n"]}]},{"cell_type":"code","metadata":{"id":"qMaHbU8Ch_Ty"},"source":["!pip install --upgrade google-cloud-storage"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OHtw4Ko8iAbS","executionInfo":{"status":"ok","timestamp":1637827879715,"user_tz":-330,"elapsed":144705,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"}},"outputId":"fb1bb667-ad68-412a-b50d-a0dc53849486"},"source":["!pip install transformers\n","!pip install seqeval datasets allennlp\n","!pip install flax\n","!pip install sentencepiece"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 13.5 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 31.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 6.9 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 39.5 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 38.6 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.6 MB/s \n","\u001b[?25hCollecting datasets\n","  Downloading datasets-1.15.1-py3-none-any.whl (290 kB)\n","\u001b[K     |████████████████████████████████| 290 kB 24.1 MB/s \n","\u001b[?25hCollecting allennlp\n","  Downloading allennlp-2.8.0-py3-none-any.whl (738 kB)\n","\u001b[K     |████████████████████████████████| 738 kB 48.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.1)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.0.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2021.11.0-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 52.3 MB/s \n","\u001b[?25hCollecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 37.4 MB/s \n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.1.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.8.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Collecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 49.3 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: torchvision<0.12.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.11.1+cu111)\n","Collecting sqlitedict\n","  Downloading sqlitedict-1.7.0.tar.gz (28 kB)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.6.4)\n","Requirement already satisfied: spacy<3.2,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (2.2.4)\n","Collecting overrides==3.1.0\n","  Downloading overrides-3.1.0.tar.gz (11 kB)\n","Collecting wandb<0.13.0,>=0.10.0\n","  Downloading wandb-0.12.7-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 36.9 MB/s \n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.1.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 47.4 MB/s \n","\u001b[?25hCollecting cached-path<0.4.0,>=0.3.1\n","  Downloading cached_path-0.3.4-py3-none-any.whl (26 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.2.5)\n","Collecting jsonnet>=0.10.0\n","  Downloading jsonnet-0.17.0.tar.gz (259 kB)\n","\u001b[K     |████████████████████████████████| 259 kB 48.8 MB/s \n","\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from allennlp) (8.11.0)\n","Collecting tensorboardX>=1.2\n","  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n","\u001b[K     |████████████████████████████████| 124 kB 47.1 MB/s \n","\u001b[?25hRequirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.99)\n","Collecting fairscale==0.4.0\n","  Downloading fairscale-0.4.0.tar.gz (190 kB)\n","\u001b[K     |████████████████████████████████| 190 kB 55.8 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting filelock\n","  Downloading filelock-3.3.2-py3-none-any.whl (9.7 kB)\n","Collecting base58\n","  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n","Collecting checklist==0.0.11\n","  Downloading checklist-0.0.11.tar.gz (12.1 MB)\n","\u001b[K     |████████████████████████████████| 12.1 MB 11.6 MB/s \n","\u001b[?25hRequirement already satisfied: transformers<4.13,>=4.1 in /usr/local/lib/python3.7/dist-packages (from allennlp) (4.12.5)\n","Requirement already satisfied: torch<1.11.0,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.10.0+cu111)\n","Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.1.0)\n","Collecting munch>=2.5\n","  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n","Requirement already satisfied: jupyter>=1.0 in /usr/local/lib/python3.7/dist-packages (from checklist==0.0.11->allennlp) (1.0.0)\n","Requirement already satisfied: ipywidgets>=7.5 in /usr/local/lib/python3.7/dist-packages (from checklist==0.0.11->allennlp) (7.6.5)\n","Collecting patternfork-nosql\n","  Downloading patternfork_nosql-3.6.tar.gz (22.3 MB)\n","\u001b[K     |████████████████████████████████| 22.3 MB 44.6 MB/s \n","\u001b[?25hCollecting iso-639\n","  Downloading iso-639-0.4.5.tar.gz (167 kB)\n","\u001b[K     |████████████████████████████████| 167 kB 46.6 MB/s \n","\u001b[?25hRequirement already satisfied: google-cloud-storage<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from cached-path<0.4.0,>=0.3.1->allennlp) (1.18.1)\n","Collecting cached-path<0.4.0,>=0.3.1\n","  Downloading cached_path-0.3.3-py3-none-any.whl (26 kB)\n","  Downloading cached_path-0.3.2-py3-none-any.whl (26 kB)\n","Collecting boto3<2.0,>=1.0\n","  Downloading boto3-1.20.13-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 45.1 MB/s \n","\u001b[?25hCollecting botocore<1.24.0,>=1.23.13\n","  Downloading botocore-1.23.13-py3-none-any.whl (8.2 MB)\n","\u001b[K     |████████████████████████████████| 8.2 MB 51.4 MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 7.6 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.13->boto3<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (2.8.2)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 51.1 MB/s \n","\u001b[?25hRequirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (0.4.1)\n","Requirement already satisfied: google-auth>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (1.35.0)\n","Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (1.0.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (0.2.8)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (57.4.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (1.15.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (4.2.4)\n","Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (1.26.3)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (1.53.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (2018.9)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (3.17.3)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (0.2.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (5.1.1)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (3.5.2)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (5.5.0)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (1.0.2)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (4.10.1)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (5.1.3)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist==0.0.11->allennlp) (5.3.5)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist==0.0.11->allennlp) (5.1.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (0.7.5)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (0.8.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (4.4.2)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (4.8.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (2.6.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (1.0.18)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp) (5.2.0)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp) (5.3.1)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp) (5.6.1)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp) (5.2.0)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (2.6.0)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (4.9.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (0.2.5)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2.0->google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (0.4.8)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2,>=2.1.0->allennlp) (1.0.5)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2,>=2.1.0->allennlp) (0.8.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2,>=2.1.0->allennlp) (2.0.6)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2,>=2.1.0->allennlp) (1.0.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2,>=2.1.0->allennlp) (0.4.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2,>=2.1.0->allennlp) (1.0.6)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2,>=2.1.0->allennlp) (1.1.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2,>=2.1.0->allennlp) (3.0.6)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2,>=2.1.0->allennlp) (7.4.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.6.0)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision<0.12.0,>=0.8.1->allennlp) (7.1.2)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<4.13,>=4.1->allennlp) (0.0.46)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.13,>=4.1->allennlp) (0.10.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.13,>=4.1->allennlp) (2019.12.20)\n","Collecting subprocess32>=3.5.3\n","  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 6.6 MB/s \n","\u001b[?25hCollecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (7.1.2)\n","Collecting yaspin>=1.0.0\n","  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (2.3)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n","\u001b[K     |████████████████████████████████| 180 kB 46.5 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (5.4.8)\n","Collecting configparser>=3.8.1\n","  Downloading configparser-5.1.0-py3-none-any.whl (19 kB)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.5.0-py2.py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 55.8 MB/s \n","\u001b[?25hCollecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp) (2.11.3)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp) (1.8.0)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp) (0.12.1)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5->checklist==0.0.11->allennlp) (22.3.0)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter>=1.0->checklist==0.0.11->allennlp) (0.7.0)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 55.7 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.7)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n","\u001b[K     |████████████████████████████████| 192 kB 48.6 MB/s \n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n","\u001b[K     |████████████████████████████████| 160 kB 47.8 MB/s \n","\u001b[?25hCollecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp) (1.5.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter>=1.0->checklist==0.0.11->allennlp) (2.0.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (4.1.0)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (0.5.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (0.7.1)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (0.8.4)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (0.3)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (1.5.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (0.5.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp) (0.16.0)\n","Collecting backports.csv\n","  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp) (4.6.3)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp) (4.2.6)\n","Collecting feedparser\n","  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n","\u001b[K     |████████████████████████████████| 81 kB 9.0 MB/s \n","\u001b[?25hCollecting pdfminer.six\n","  Downloading pdfminer.six-20211012-py3-none-any.whl (5.6 MB)\n","\u001b[K     |████████████████████████████████| 5.6 MB 15.0 MB/s \n","\u001b[?25hCollecting python-docx\n","  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n","\u001b[K     |████████████████████████████████| 5.6 MB 27.0 MB/s \n","\u001b[?25hCollecting cherrypy\n","  Downloading CherryPy-18.6.1-py2.py3-none-any.whl (419 kB)\n","\u001b[K     |████████████████████████████████| 419 kB 37.3 MB/s \n","\u001b[?25hCollecting jaraco.collections\n","  Downloading jaraco.collections-3.4.0-py3-none-any.whl (10 kB)\n","Collecting portend>=2.1.1\n","  Downloading portend-3.1.0-py3-none-any.whl (5.3 kB)\n","Collecting cheroot>=8.2.1\n","  Downloading cheroot-8.5.2-py2.py3-none-any.whl (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 6.1 MB/s \n","\u001b[?25hCollecting zc.lockfile\n","  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n","Collecting jaraco.functools\n","  Downloading jaraco.functools-3.4.0-py3-none-any.whl (6.9 kB)\n","Collecting tempora>=1.8\n","  Downloading tempora-4.1.2-py3-none-any.whl (15 kB)\n","Collecting sgmllib3k\n","  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n","Collecting jaraco.text\n","  Downloading jaraco.text-3.6.0-py3-none-any.whl (8.1 kB)\n","Collecting jaraco.classes\n","  Downloading jaraco.classes-3.2.1-py3-none-any.whl (5.6 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist==0.0.11->allennlp) (5.4.0)\n","Collecting cryptography\n","  Downloading cryptography-36.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n","\u001b[K     |████████████████████████████████| 3.6 MB 24.9 MB/s \n","\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six->patternfork-nosql->checklist==0.0.11->allennlp) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six->patternfork-nosql->checklist==0.0.11->allennlp) (2.21)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (0.7.1)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (1.11.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (1.4.0)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter>=1.0->checklist==0.0.11->allennlp) (1.11.2)\n","Building wheels for collected packages: seqeval, checklist, fairscale, overrides, jsonnet, subprocess32, iso-639, pathtools, patternfork-nosql, python-docx, sgmllib3k, sqlitedict\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=65636c0aeda119d19dd6e5148fbffeaf792b63dbef8845f8b6e1db7f9881c86f\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","  Building wheel for checklist (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for checklist: filename=checklist-0.0.11-py3-none-any.whl size=12165633 sha256=2b50cee6d40f7ceffbe1549d9a9d2dff66cd7096bb740205deca6255e80a6ee5\n","  Stored in directory: /root/.cache/pip/wheels/6a/8a/07/6446879be434879c27671c83443727d74cecf6b630c8a24d03\n","  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairscale: filename=fairscale-0.4.0-py3-none-any.whl size=239949 sha256=ef9dcb8ce4affebaf7b75587b136e156975e0fa23c0b2ed465fd5a0a011f89fe\n","  Stored in directory: /root/.cache/pip/wheels/28/8e/a3/7a2f33ac996114b816d88e55cf1235a1e058f30211e39bd719\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10186 sha256=1dbc6092712e6ca08b7a570c67d98cdd4610c180222137af8f595cae1cb07f28\n","  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n","  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jsonnet: filename=jsonnet-0.17.0-cp37-cp37m-linux_x86_64.whl size=3388676 sha256=12ebba2cbca7ecd5fffea44601134cb5404bbc7f89de0ad720b8608dec565ce7\n","  Stored in directory: /root/.cache/pip/wheels/1c/28/7e/287c6b19f7161bb03c6986a3c46b51d0d7d9a1805346634e3a\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=d9a0b1a32b7f242f39112b2bd646cfdb7ef0acc732847a8649966b8840a51dfb\n","  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n","  Building wheel for iso-639 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for iso-639: filename=iso_639-0.4.5-py3-none-any.whl size=169061 sha256=9d82737b909d32ebde35d8c84f030a4481eaa57d6143ee44678b8befb4a2e2ab\n","  Stored in directory: /root/.cache/pip/wheels/47/60/19/6d020fc92138ed1b113a18271e83ea4b5525fe770cb45b9a2e\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=22bb74fd7d7667a292dbb2141fda6a112badaf8ba4d4614d11ba4daf5bc887a4\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","  Building wheel for patternfork-nosql (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for patternfork-nosql: filename=patternfork_nosql-3.6-py3-none-any.whl size=22332806 sha256=bd85bc0b4affba32f41d6da96e8b977d45e5564a97039a835de25835f6678b34\n","  Stored in directory: /root/.cache/pip/wheels/97/72/8f/5305fe28168f93b658da9ed433b9a1d3ec90594faa0c9aaf4b\n","  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184508 sha256=c2172950b71cf75529f54154e033b721487c3e361f4b717e33b4b394985d66b1\n","  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n","  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6065 sha256=bf5d8d49315a1985dec657e10fe0b97f93724400380806b6062814ec66e3b068\n","  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n","  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-py3-none-any.whl size=14392 sha256=6fd0b610bcd3fa466a8f4e69fc90b520aa1ca81aa26a0091db224fbdf38454c5\n","  Stored in directory: /root/.cache/pip/wheels/af/94/06/18c0e83e9e227da8f3582810b51f319bbfd181e508676a56c8\n","Successfully built seqeval checklist fairscale overrides jsonnet subprocess32 iso-639 pathtools patternfork-nosql python-docx sgmllib3k sqlitedict\n","Installing collected packages: urllib3, jaraco.functools, tempora, multidict, jmespath, jaraco.text, jaraco.classes, frozenlist, zc.lockfile, yarl, smmap, sgmllib3k, portend, jaraco.collections, filelock, cryptography, cheroot, botocore, asynctest, async-timeout, aiosignal, s3transfer, python-docx, pdfminer.six, gitdb, fsspec, feedparser, cherrypy, backports.csv, aiohttp, yaspin, xxhash, subprocess32, shortuuid, sentry-sdk, patternfork-nosql, pathtools, overrides, munch, iso-639, GitPython, docker-pycreds, configparser, boto3, wandb, tensorboardX, sqlitedict, sentencepiece, jsonnet, fairscale, datasets, checklist, cached-path, base58, seqeval, allennlp\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: filelock\n","    Found existing installation: filelock 3.4.0\n","    Uninstalling filelock-3.4.0:\n","      Successfully uninstalled filelock-3.4.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed GitPython-3.1.24 aiohttp-3.8.1 aiosignal-1.2.0 allennlp-2.8.0 async-timeout-4.0.1 asynctest-0.13.0 backports.csv-1.0.7 base58-2.1.1 boto3-1.20.13 botocore-1.23.13 cached-path-0.3.2 checklist-0.0.11 cheroot-8.5.2 cherrypy-18.6.1 configparser-5.1.0 cryptography-36.0.0 datasets-1.15.1 docker-pycreds-0.4.0 fairscale-0.4.0 feedparser-6.0.8 filelock-3.3.2 frozenlist-1.2.0 fsspec-2021.11.0 gitdb-4.0.9 iso-639-0.4.5 jaraco.classes-3.2.1 jaraco.collections-3.4.0 jaraco.functools-3.4.0 jaraco.text-3.6.0 jmespath-0.10.0 jsonnet-0.17.0 multidict-5.2.0 munch-2.5.0 overrides-3.1.0 pathtools-0.1.2 patternfork-nosql-3.6 pdfminer.six-20211012 portend-3.1.0 python-docx-0.8.11 s3transfer-0.5.0 sentencepiece-0.1.96 sentry-sdk-1.5.0 seqeval-1.2.2 sgmllib3k-1.0.0 shortuuid-1.0.8 smmap-5.0.0 sqlitedict-1.7.0 subprocess32-3.5.4 tempora-4.1.2 tensorboardX-2.4.1 urllib3-1.25.11 wandb-0.12.7 xxhash-2.0.2 yarl-1.7.2 yaspin-2.1.0 zc.lockfile-2.0\n","Collecting flax\n","  Downloading flax-0.3.6-py3-none-any.whl (207 kB)\n","\u001b[K     |████████████████████████████████| 207 kB 13.0 MB/s \n","\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax) (1.0.2)\n","Requirement already satisfied: jax>=0.2.21 in /usr/local/lib/python3.7/dist-packages (from flax) (0.2.25)\n","Collecting optax\n","  Downloading optax-0.1.0-py3-none-any.whl (126 kB)\n","\u001b[K     |████████████████████████████████| 126 kB 46.1 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flax) (3.2.2)\n","Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from flax) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.21->flax) (3.10.0.2)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.21->flax) (0.12.0)\n","Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.21->flax) (1.4.1)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.21->flax) (3.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jax>=0.2.21->flax) (1.15.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (3.0.6)\n","Collecting chex>=0.0.4\n","  Downloading chex-0.1.0-py3-none-any.whl (65 kB)\n","\u001b[K     |████████████████████████████████| 65 kB 3.0 MB/s \n","\u001b[?25hRequirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax->flax) (0.1.74+cuda11.cudnn805)\n","Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax) (0.11.2)\n","Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax) (0.1.6)\n","Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax->flax) (2.0)\n","Installing collected packages: chex, optax, flax\n","Successfully installed chex-0.1.0 flax-0.3.6 optax-0.1.0\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y8P27o2aI7Gj","executionInfo":{"status":"ok","timestamp":1637827885647,"user_tz":-330,"elapsed":4245,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"}},"outputId":"42cafe6e-43a8-407f-f5e2-415346739b4d"},"source":["%pip show protobuf"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: protobuf\n","Version: 3.17.3\n","Summary: Protocol Buffers\n","Home-page: https://developers.google.com/protocol-buffers/\n","Author: None\n","Author-email: None\n","License: 3-Clause BSD License\n","Location: /usr/local/lib/python3.7/dist-packages\n","Requires: six\n","Required-by: wandb, tensorflow, tensorflow-metadata, tensorflow-hub, tensorflow-datasets, tensorboardX, tensorboard, googleapis-common-protos, google-cloud-bigquery, google-api-core\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"37vxhFzdI9-U","executionInfo":{"status":"ok","timestamp":1637827896415,"user_tz":-330,"elapsed":485,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"}},"outputId":"4446620b-2dce-4359-ad70-133b4d9f2baf"},"source":["!protoc --version"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["libprotoc 3.0.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bELItH4Eir2t","executionInfo":{"elapsed":12,"status":"ok","timestamp":1637189225641,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"},"user_tz":-330},"outputId":"1c120a7f-4d9b-409f-a95d-5e6e7bb63109"},"source":["%ls"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0m\u001b[01;34marg_mining\u001b[0m/                        Drinventor_linear_layer.pt\n","\u001b[01;34mchange-my-view-modes\u001b[0m/              Drinventor_tokenizer_pre.pkl\n","\u001b[01;34mcompiled_corpus\u001b[0m/                   Drinventor_transformer_layer.pt\n","compiled_corpus.zip                layer_wise_analysis.pkl\n","crf_layer.pkl                      linear_layer.pt\n","cross_entropy_layer.pt             \u001b[01;34mModel\u001b[0m/\n","data_dict.pkl                      \u001b[01;34mnaacl18-multitask_argument_mining\u001b[0m/\n","data_runner.pkl                    \u001b[01;34mtemp\u001b[0m/\n","Discourse_Markers.txt              tokenizer_pre.pkl\n","Drinventor_crf_layer.pkl           transformer_layer.pt\n","Drinventor_cross_entropy_layer.pt  \u001b[01;34mwandb\u001b[0m/\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HO8ge53aqAfc","executionInfo":{"elapsed":6,"status":"ok","timestamp":1637189225642,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"},"user_tz":-330},"outputId":"61eef4a9-b9b3-4333-d5ea-d2046266a719"},"source":["%cd Argument\\ Mining\\ BTP"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[Errno 2] No such file or directory: 'Argument Mining BTP'\n","/content/drive/MyDrive/Bert_Lime\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["9c22115be3754d80bbc648f678dafd09","647820e3310048b4b3d665a6a75b6005","671122ff41d342dbb2771ecf3e494b1c","cfd0cb7ef2ce4340b47176f2eb7b1b35","a9a0013944004dea9002a569e2383b08","6e0c3660440e47dd90502b736a051e9e","83b0f803343247f99e56eb144a7670d1","14c91935cf8247df906ef3fb284971d2","c40951b827b842a1a1b20d2b0de8302c","5a60a3094c224ef99c19fadba9817ebe","ce6c18a4cb4248e9a8bbcca271943216"]},"id":"UMLdlu0hopXy","executionInfo":{"elapsed":33177,"status":"ok","timestamp":1637189258815,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"},"user_tz":-330},"outputId":"41cf4169-6da6-428c-d9d3-c9a26675572c"},"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","from datasets import load_metric\n","metric = load_metric('seqeval')\n","\n","\"\"\"### Define & Load Tokenizer, Model, Dataset\"\"\"\n","import numpy as np\n","\n","import torch\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","\"\"\"#### Or load them from pretrained files...\"\"\"\n","\n","from transformers import LongformerTokenizer, LongformerModel\n","\n","from arg_mining.datasets.DrInventor import load_dataset\n","from arg_mining.datasets.DrInventor import config as data_config\n","\n","import torch.nn as nn\n","\n"],"execution_count":null,"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c22115be3754d80bbc648f678dafd09","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.48k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":249,"referenced_widgets":["3972095409bc407a89347c1569e7dbcd","cc931beebf7b41fd9519c02875dd262b","88e231e3ea0d458ea65dbb4a65e6c2fc","aa25984c7816465fadc49a2481315b86","8f9969b455ec4abcae9fc8c7777e96e6","8befe8370649463f91578f3790a434b6","e3400bb18c9e41da8e28e7675504e3f4","2c73fad36e644c8bb316d3e40059f90e","a4839d81b4cc4bca8b1a915fc1a56be6","b9eb391e56f747f7aa65053c27dd10bc","b66d9daaee0045918762c8a0a82048c8","a4e8ac9d1dff4cddb20eafed8c56fc90","2629f0919174437f93231229f956ef5e","0efbf5fb649d4224b4451c68f130c0cb","8ead96d7b06c429cbfb00c28c3ca0eec","a85847c307b44c0da83844b3e43b8309","b082ababe8244f86a88490c470563677","5b7467f3d6e349e3b931e608576dded2","d2c8f59ea30c4bfabe78f9f8725d8558","a5ddcc86075b48cc84196f7eef6a39b6","77d932fa25da4c61a85a21b2b6e45b69","0884c0ae0e6f40bc9971515db5b4991c","8e7e68fc49184b8d82ee5165b4364142","69ef115890674742bcd028e7c3056849","5c78157ad49a4458aba7f997675bb3a2","5753325723584257b0a71c70222403e4","985e9605abbf4eb58a73ce740c1db5fa","7b44138d97b448ecad4d0f5dc58e8c2a","6e3864bd132c4b0d8ce0cb4f25a040e0","045a2a0089294ebcbe7a32fde7cf9748","d8c27adafa7347fc9fb9f98a90753265","5f3eda40bede425ebde200ce81f9d875","0bb59cd7670f4a09ae9d491887d71ab5","15d8a07f061f49cba2b726075bfe8d14","cd4184948ed648c1ac62ddbf4eac561f","f2706fa9bb014c6d9024198fd244008d","d91ec999ab874475aef7af7e603f3909","94a6259d08714e6b8925ac482b27fbd5","34d5fdaf77dc43f9ada4921fb714f970","77468cb0d40042d3ae6da974ad58aec2","7771a4cfdfca49ad812d5b8c0c18bb62","6fcdfb475abb415f93b9cde1fad98d91","93e8ddfde24b44d598ba3a4920c38558","04e51f8bc3fd47f4b558d05cfbff3037","0e8efad7d48046abbb357159e73edbd2","f3bc3b13d7c54892889cc945db3d8c0a","f3e96c42dfd743e3bbda00f0210b8965","db3776c740474ae880e48309f92a1787","f445f61661b14285b033cb98b644c717","30760f891f204c8fb58051b57b11e114","121f87f2cfd34db9b9da62a9c8aec62b","bee9be5dcf2d40c28fd36b2e4d871780","6a8442b238dd40a5a443e58184295c86","52e494dd32df41b59004d235b364fd74","0b0443268738491f8f45ac77643cf4f7"]},"id":"BNsGtjrDqdaj","executionInfo":{"elapsed":104028,"status":"ok","timestamp":1637189362839,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"},"user_tz":-330},"outputId":"68ffc811-c695-4f2d-d79a-0c69b9279339"},"source":["\n","model_version = 'bert-base-cased'\n","\n","from transformers import AutoTokenizer, AutoModel\n","tokenizer = AutoTokenizer.from_pretrained(model_version,\n","                                          bos_token = \"[CLS]\",\n","                                          eos_token = \"[SEP]\")\n","transformer_model = AutoModel.from_pretrained(model_version,output_hidden_states=True, output_attentions = True)\n","transformer_model = transformer_model.to(device)\n","\n","def resize_token_type_embeddings(transformer_model, new_size):\n","    old_embeddings = transformer_model.embeddings.token_type_embeddings.weight\n","    old_size, hidden_dim = old_embeddings.shape\n","    transformer_model.embeddings.token_type_embeddings = nn.Embedding(new_size, hidden_dim, device=transformer_model.device)\n","    with torch.no_grad():\n","        transformer_model.embeddings.token_type_embeddings.weight[:old_size] = old_embeddings\n","\n","\n","tokenizer.add_tokens(data_config[\"special_tokens\"], special_tokens=True)\n","        \n","transformer_model.resize_token_embeddings(len(tokenizer))\n","\n","from allennlp.modules.conditional_random_field import ConditionalRandomField as crf\n","\n","ac_dict = data_config[\"arg_components\"]\n","\n","allowed_transitions =([(ac_dict[\"B-BC\"], ac_dict[\"I-BC\"]), \n","                       (ac_dict[\"B-OC\"], ac_dict[\"I-OC\"]),\n","                       (ac_dict[\"B-D\"], ac_dict[\"I-D\"]),] + \n","                      \n","                      [(ac_dict[\"I-BC\"], ac_dict[ct]) \n","                        for ct in [\"I-BC\", \"B-BC\", \"B-OC\",\"B-D\", \"O\"]] +\n","                      [(ac_dict[\"I-OC\"], ac_dict[ct]) \n","                        for ct in [\"I-OC\", \"B-BC\", \"B-OC\", \"B-D\", \"O\"]] +\n","                      [(ac_dict[\"I-D\"], ac_dict[ct]) \n","                        for ct in [\"I-D\", \"B-BC\", \"B-OC\", \"B-D\", \"O\"]] +\n","\n","                      [(ac_dict[\"O\"], ac_dict[ct]) \n","                        for ct in [\"O\", \"B-BC\", \"B-OC\", \"B-D\"]])\n","\n","linear_layer = nn.Linear(transformer_model.config.hidden_size,\n","                             len(ac_dict)).to(device)\n","\n","crf_layer = crf(num_tags=len(ac_dict),\n","                constraints=allowed_transitions,\n","                include_start_end_transitions=False).to(device)\n","\n","cross_entropy_layer = nn.CrossEntropyLoss(weight=torch.log(torch.tensor([0.668, 4.531, 2.020, 4.028, 1.388, 4.316, 2.754],\n","                                                                        device=device)), reduction='none')\n"],"execution_count":null,"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3972095409bc407a89347c1569e7dbcd","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4e8ac9d1dff4cddb20eafed8c56fc90","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e7e68fc49184b8d82ee5165b4364142","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15d8a07f061f49cba2b726075bfe8d14","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e8efad7d48046abbb357159e73edbd2","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","metadata":{"id":"cUmuOx9uqlUI"},"source":["\n","\n","\"\"\"#### Function to get train, test data (50/50 split currently)\"\"\"\n","\n","\n","def get_datasets(train_sz=100, test_sz=0):\n","    train_dataset, valid_dataset, test_dataset = load_dataset(tokenizer=tokenizer,\n","                                                              train_sz=train_sz,\n","                                                              test_sz=test_sz,\n","                                                              shuffle=True,\n","                                                              )\n","    return train_dataset, valid_dataset, test_dataset\n","\n","\"\"\"### Define layers for a Linear-Chain-CRF\"\"\"\n","\n","\n","\n","def get_crf_head():\n","    linear_layer = nn.Linear(transformer_model.config.hidden_size,\n","                             len(ac_dict)).to(device)\n","\n","    crf_layer = crf(num_tags=len(ac_dict),\n","                    constraints=allowed_transitions,\n","                    include_start_end_transitions=False).to(device)\n","\n","    return linear_layer, crf_layer\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"rlnwEoxjqiWc","executionInfo":{"elapsed":22,"status":"ok","timestamp":1637189362849,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"},"user_tz":-330},"outputId":"c50a624b-e8a3-4515-936d-9c3fc9c807d3"},"source":["\n","\"\"\"### Loss and Prediction Function\"\"\"\n","\n","from typing import Tuple, List\n","\n","def compute(batch: Tuple[torch.Tensor, torch.Tensor],\n","            preds: bool=False, cross_entropy: bool=True):\n","    \"\"\"\n","    Args:\n","        batch:  A tuple having tokenized thread of shape [batch_size, seq_len],\n","                component type labels of shape [batch_size, seq_len], and a global\n","                attention mask for Longformer, of the same shape.\n","        \n","        preds:  If True, returns a List(of batch_size size) of Tuples of form \n","                (tag_sequence, viterbi_score) where the tag_sequence is the \n","                viterbi-decoded sequence, for the corresponding sample in the batch.\n","        \n","        cross_entropy:  This argument will only be used if preds=False, i.e., if \n","                        loss is being calculated. If True, then cross entropy loss\n","                        will also be added to the output loss.\n","    \n","    Returns:\n","        Either the predicted sequences with their scores for each element in the batch\n","        (if preds is True), or the loss value summed over all elements of the batch\n","        (if preds is False).\n","    \"\"\"\n","    tokenized_sub_parts, comp_type_labels = batch\n","    tokenized_sub_parts = tokenized_sub_parts[:,:512]\n","    comp_type_labels = comp_type_labels[:, :512]\n","    pad_mask = torch.where(tokenized_sub_parts!=tokenizer.pad_token_id, 1, 0)\n","\n","    global_attention_mask = torch.where(torch.logical_or(tokenized_sub_parts==tokenizer.sep_token_id,\n","                                                         tokenized_sub_parts==tokenizer.bos_token_id), 1, 0)\n","\n","    logits = linear_layer(transformer_model(input_ids=tokenized_sub_parts,\n","                                            attention_mask=pad_mask,\n","                                            ).last_hidden_state)\n","    \n","    if preds:\n","        return crf_layer.viterbi_tags(logits, pad_mask)\n","    \n","    log_likelihood = crf_layer(logits, comp_type_labels, pad_mask)\n","    \n","    if cross_entropy:\n","        logits = logits.reshape(-1, logits.shape[-1])\n","        \n","        pad_mask, comp_type_labels = pad_mask.reshape(-1), comp_type_labels.reshape(-1)\n","        \n","        ce_loss = torch.sum(pad_mask*cross_entropy_layer(logits, comp_type_labels))\n","        \n","        return ce_loss - log_likelihood\n","\n","    return -log_likelihood\n","\n","\"\"\"### Define optimizer\"\"\"\n","\n","from itertools import chain\n","\n","import torch.optim as optim\n","\n","\"\"\"### Training And Evaluation Loops\"\"\"\n","\n","def train(dataset):\n","    accumulate_over = 4\n","    \n","    optimizer.zero_grad()\n","\n","    for i, (tokenized_sub_parts, comp_type_labels, _) in enumerate(dataset):\n","        \n","        #Cast to PyTorch tensor\n","        tokenized_sub_parts = torch.tensor(tokenized_sub_parts, device=device)\n","        comp_type_labels = torch.tensor(comp_type_labels, device=device, dtype=torch.long)\n","        \n","        loss = compute((tokenized_sub_parts,\n","                        comp_type_labels,))/batch_size\n","\n","        print(\"Loss:\", loss)\n","        \n","        loss.backward()\n","        \n","        if i%accumulate_over==accumulate_over-1:\n","            optimizer.step()\n","            optimizer.zero_grad()\n","    \n","    optimizer.step()\n","\n","\n","\n","def evaluate(dataset, metric):\n","    \n","    int_to_labels = {v:k for k, v in ac_dict.items()}\n","\n","    with torch.no_grad():\n","        for tokenized_sub_parts, comp_type_labels, _ in dataset:\n","            print(\"Evaluating\") \n","    \n","            #Cast to PyTorch tensor\n","            tokenized_sub_parts = torch.tensor(tokenized_sub_parts, device=device)\n","            comp_type_labels = torch.tensor(comp_type_labels, device=device, dtype=torch.long)\n","            \n","\n","            tokenized_sub_parts = tokenized_sub_parts[:, :512]\n","            comp_type_labels = comp_type_labels[:, :512]\n","\n","            preds = compute((tokenized_sub_parts,\n","                             comp_type_labels,),\n","                            preds=True)\n","            \n","            lengths = torch.sum(torch.where(tokenized_sub_parts!=tokenizer.pad_token_id, 1, 0), \n","                                axis=-1)\n","            \n","            preds = [ [int_to_labels[pred] for pred in pred[0][:lengths[i]]]\n","                      for i, pred in enumerate(preds)\n","                    ]\n","            \n","            refs = [ [int_to_labels[ref] for ref in labels[:lengths[i]]]\n","                     for i, labels in enumerate(comp_type_labels.cpu().tolist())\n","                   ]\n","            \n","            metric.add_batch(predictions=preds, \n","                             references=refs,)\n","                             #tokenized_threads=tokenized_threads.cpu().tolist())\n","        \n","    print(\"\\t\\t\\t\\t\", metric.compute())\n","\n","\"\"\"### Final Training\"\"\"\n","\n","\n","        "],"execution_count":null,"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'### Final Training'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8qvHx5o0cEoX","executionInfo":{"elapsed":339,"status":"ok","timestamp":1636826598164,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"},"user_tz":-330},"outputId":"ef1c9ecf-6de9-4859-c968-565c05507b82"},"source":["print(ac_dict)\n","import random"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["FrozenDict({\n","    O: 0,\n","    B-BC: 1,\n","    I-BC: 2,\n","    B-OC: 3,\n","    I-OC: 4,\n","    B-D: 5,\n","    I-D: 6,\n","})\n"]}]},{"cell_type":"code","metadata":{"id":"0p_1YeF5bil0"},"source":["def get_masked_data_lists(dataset,\n","                          left: bool=True) -> Tuple[List[List[int]], List[List[int]]]:\n","    \"\"\"\n","    Args:\n","        dataset:    A python generator that yields tuples of np.array's\n","                    consisting of tokenized_threads, masked_threads and component\n","                    type labels\n","        left:       If true, left side of components are masked. Otherwise right\n","                    side is masked.\n","    Returns:\n","        A tuple of two lists consisting of samples from entire dataset:\n","            final_threads:  A list of lists of int. Where each internal list corresponds\n","                            to a thread masked on one side.\n","            final_labels:   A list of lists of int. Where each internal list corresponds\n","                            to a masked component type labels.\n","    NOTE:\n","        A left masked sample consists of a tokenized thread whose all tokens before\n","        the beginning of some argumentative component are [MASK] and the corresponding\n","        component type labels are \"other\".\n","    \"\"\"\n","    final_threads, final_labels = [], []\n","    if not left:\n","        for (tokenized_threads, comp_type_labels, _) in dataset:\n","            for (tokenized_thread, comp_type_label) in zip(tokenized_threads, comp_type_labels):\n","                # tokenized_thread = tokenized_thread.tolist()\n","                # comp_type_label = comp_type_label.tolist()\n","                left_masked_thread = []\n","                comp_types_for_left_masked_thread = []\n","                for i, (_token, label) in enumerate(zip(tokenized_thread, comp_type_label)):\n","                    if (label == data_config[\"arg_components\"][\"B-OC\"] or \n","                        label == data_config[\"arg_components\"][\"B-D\"] or \n","                        label == data_config[\"arg_components\"][\"B-BC\"]):\n","                        final_threads.append(left_masked_thread+tokenized_thread[i:])\n","                        final_labels.append(comp_types_for_left_masked_thread+comp_type_label[i:])\n","                    left_masked_thread.append(tokenizer.mask_token_id)\n","                    comp_types_for_left_masked_thread.append(0)\n","    else:\n","        for (tokenized_threads, comp_type_labels, _) in dataset:\n","            for (tokenized_thread, comp_type_label) in zip(tokenized_threads, comp_type_labels):\n","                tokenized_thread = tokenized_thread[::-1]\n","                comp_type_label = comp_type_label[::-1]\n","                right_masked_thread = []\n","                comp_types_for_right_masked_thread = []\n","                flag = 0\n","                for i, (_token, label) in enumerate(zip(tokenized_thread, comp_type_label)):\n","                    if ((label == data_config[\"arg_components\"][\"I-BC\"] or \n","                        label == data_config[\"arg_components\"][\"I-OC\"] or\n","                         label == data_config[\"arg_components\"][\"I-D\"] )) and flag:\n","                        final_threads.append(right_masked_thread+tokenized_thread[i:])\n","                        final_labels.append(comp_types_for_right_masked_thread+comp_type_label[i:])\n","                        final_threads[-1] = final_threads[-1][::-1]\n","                        final_labels[-1] = final_labels[-1][::-1]\n","                    if(label != data_config[\"arg_components\"][\"I-BC\"] and\n","                        label != data_config[\"arg_components\"][\"I-OC\"] and\n","                       label != data_config[\"arg_components\"][\"I-D\"]):\n","                        flag = 1\n","                    else:\n","                        flag = 0\n","                    right_masked_thread.append(tokenizer.mask_token_id)\n","                    comp_types_for_right_masked_thread.append(0)\n","#         print((final_threads, final_labels))\n","        \n","    return final_threads, final_labels\n","from typing import Generator\n","def get_masked_dataset(dataset,\n","                       left:bool = True,\n","                       shuffle:bool = True,\n","                       batch_size: int = 10) -> Generator[Tuple[np.ndarray, np.ndarray], None, None]:\n","    \"\"\"\n","    Args:\n","        dataset:    Same as in get_masked_data_lists()\n","        left:       Same as in get_masked_data_lists()\n","        shuffle:    Whether to shuffle around the elements corresponding to masking\n","                    of various threads. If True, batch will consist of random left/right\n","                    masked samples from different tokenized_threads, rather than same one.\n","        batch_size: Number of elements to put in a batch. \n","    \n","    Yields:\n","        A batch consisting of a tuple of np.array's corresponding to left/right masked\n","        tokenized_threads, and comp_type_labels.\n","    \"\"\"\n","    masked_threads, labels_for_masked_threads = get_masked_data_lists(dataset, left)\n","    samples =[(elem1, elem2) for (elem1, elem2) in zip(masked_threads, labels_for_masked_threads)]\n","    if shuffle:\n","        random.shuffle(samples)\n","    # print(masked_threads)\n","    batch_threads = []\n","    batch_labels = []\n","    lengths = []\n","    for sample in samples:\n","#         print(sample)\n","        batch_threads.append(sample[0])\n","        batch_labels.append(sample[1])\n","        lengths.append(len(sample[0]))\n","        if len(batch_threads)==batch_size:\n","            max_len = max(lengths)\n","            for thread, label in zip(batch_threads, batch_labels):\n","                thread += [tokenizer.pad_token_id]*(max_len-len(thread))\n","                label += [0]*(max_len-len(thread))\n","            yield np.array(batch_threads), np.array(batch_labels)\n","            batch_threads, batch_labels, lengths = [], [], []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RfmoMc_LdWe1"},"source":["def evaluate_left_right(dataset, metric, left):\n","    \n","    int_to_labels = {v:k for k, v in ac_dict.items()}\n","    print('ENTER')\n","    \n","    with torch.no_grad():\n","        print(\"Enter 2\")\n","        for tokenized_threads, comp_type_labels in get_masked_dataset(dataset, left):\n","            #Cast to PyTorch tensor\n","            # print(tokenized_threads)\n","            tokenized_threads = torch.tensor(tokenized_threads, device=device)\n","            tokenized_threads = tokenized_threads[:, :512]\n","            comp_type_labels = comp_type_labels[:][:512]\n","            max_size = max([len(i1) for i1 in comp_type_labels])\n","            # print(max_size)\n","            new_comp = []\n","            for l in range(comp_type_labels.shape[0]):\n","              new_comp.append(list(comp_type_labels[l]) + [0]*(max_size - len(comp_type_labels[l])))\n","            comp_type_labels = np.array(new_comp)\n","            comp_type_labels = torch.tensor(comp_type_labels, device=device)\n","            \n","            preds = compute_left_right((tokenized_threads,\n","                            torch.where(tokenized_threads==tokenizer.mask_token_id, 1, 0),\n","                            comp_type_labels,), preds=True)\n","            total_pred = []\n","            total_ref = []\n","              \n","            if not left:\n","              for i in range(tokenized_threads.shape[0]):\n","                temp = []\n","                temp_ref = []\n","                flag = False;\n","                for j in range(tokenized_threads.shape[1]):\n","                  if(tokenized_threads[i, j] != tokenizer.pad_token_id and flag):\n","                    temp.append(preds[i][0][j])\n","                    temp_ref.append(int(comp_type_labels[i][j].cpu().numpy()))\n","                  if(tokenized_threads[i, j] != tokenizer.mask_token_id):\n","                    flag = True\n","                total_pred.append(temp)\n","                total_ref.append(temp_ref);\n","            else:\n","              for i in range(tokenized_threads.shape[0]):\n","                temp = []\n","                temp_ref = []\n","                flag = False;\n","                for j in range(tokenized_threads.shape[1] - 1, -1, -1):\n","                  if(tokenized_threads[i, j] != tokenizer.pad_token_id and flag):\n","                    temp.append(preds[i][0][j])\n","                    temp_ref.append(int(comp_type_labels[i][j].cpu().numpy()))\n","                  if(tokenized_threads[i, j] != tokenizer.mask_token_id):\n","                    flag = True\n","                total_pred.append(temp[::-1])\n","                total_ref.append(temp_ref[::-1]);\n","            lengths = torch.sum(torch.where(tokenized_threads!=tokenizer.pad_token_id, 1, 0), \n","                                  axis=-1)\n","            preds = [ [int_to_labels[pr] for pr in pred]\n","                    for i, pred in enumerate(total_pred)\n","                    ]\n","            \n","            refs = [ [int_to_labels[ref] for ref in labels]\n","                    for i, labels in enumerate(total_ref)\n","                ]\n","            metric.add_batch(predictions=preds, \n","                            references=refs,)\n","                            #tokenized_threads=tokenized_threads.cpu().tolist())\n","        \n","    print(metric.compute())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PZ-uAqnifJyU"},"source":["def compute_left_right(batch: Tuple[torch.Tensor, torch.Tensor, torch.Tensor],\n","            preds: bool=False, cross_entropy: bool=True):\n","    \"\"\"\n","    Args:\n","        batch:  A tuple having tokenized thread of shape [batch_size, seq_len],\n","                component type labels of shape [batch_size, seq_len], and a global\n","                attention mask for Longformer, of the same shape.\n","        \n","        preds:  If True, returns a List(of batch_size size) of Tuples of form \n","                (tag_sequence, viterbi_score) where the tag_sequence is the \n","                viterbi-decoded sequence, for the corresponding sample in the batch.\n","        \n","        cross_entropy:  This argument will only be used if preds=False, i.e., if \n","                        loss is being calculated. If True, then cross entropy loss\n","                        will also be added to the output loss.\n","    \n","    Returns:\n","        Either the predicted sequences with their scores for each element in the batch\n","        (if preds is True), or the loss value summed over all elements of the batch\n","        (if preds is False).\n","    \"\"\"\n","    tokenized_threads, token_type_ids, comp_type_labels = batch\n","    tokenized_threads = tokenized_threads[:, :512]\n","    comp_type_labels = comp_type_labels[:, :512]\n","    pad_mask = torch.where(tokenized_threads!=tokenizer.pad_token_id, 1, 0)\n","    \n","    logits = linear_layer(transformer_model(input_ids=tokenized_threads,\n","                                            attention_mask=pad_mask,).last_hidden_state)\n","    # print(logits.shape)\n","    if preds:\n","        return crf_layer.viterbi_tags(logits, pad_mask)\n","    \n","    log_likelihood = crf_layer(logits, comp_type_labels, pad_mask)\n","    \n","    if cross_entropy:\n","        logits = logits.reshape(-1, logits.shape[-1])\n","        \n","        pad_mask, comp_type_labels = pad_mask.reshape(-1), comp_type_labels.reshape(-1)\n","        \n","        ce_loss = torch.sum(pad_mask*cross_entropy_layer(logits, comp_type_labels))\n","        \n","        return ce_loss - log_likelihood\n","\n","    return -log_likelihood"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o0UMa2Qpemix","executionInfo":{"elapsed":870813,"status":"ok","timestamp":1636827984865,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"},"user_tz":-330},"outputId":"8f4fbb93-8b8b-42f7-8322-13b13faea98c"},"source":["n_epochs = 1\n","n_runs = 1\n","print(\"Right mask\")\n","batch_size = 2\n","for (train_sz, test_sz) in [(50,50)]:\n","\n","    print(\"\\tTrain size:\", train_sz, \"Test size:\", test_sz)\n","    \n","    for run in range(n_runs):\n","        print(f\"\\n\\n\\t\\t-------------RUN {run+1}-----------\")\n","        \n","        optimizer = optim.Adam(params = chain(transformer_model.parameters(),\n","                                  linear_layer.parameters(),\n","                                  crf_layer.parameters()),\n","                                lr = 2e-5,)\n","\n","        train_dataset, _, test_dataset = get_datasets(train_sz, test_sz)\n","        train_dataset = [elem for elem in train_dataset]\n","        test_dataset = [elem for elem in test_dataset]\n","        print(\"Train dataset size:\", len(train_dataset))\n","        for epoch in range(n_epochs):\n","            print(f\"\\t\\t\\t------------EPOCH {epoch+1}---------------\")\n","            # train(train_dataset)\n","            evaluate_left_right(test_dataset, metric, True)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Right mask\n","\tTrain size: 50 Test size: 50\n","\n","\n","\t\t-------------RUN 1-----------\n","Train dataset size: 68\n","\t\t\t------------EPOCH 1---------------\n","ENTER\n","Enter 2\n","{'BC': {'precision': 0.00024656121816184873, 'recall': 0.0017149984409105083, 'f1': 0.0004311386633394956, 'number': 19242}, 'D': {'precision': 0.0007138395645578656, 'recall': 0.002010757552908058, 'f1': 0.0010536297545042672, 'number': 19893}, 'OC': {'precision': 0.0011899365367180417, 'recall': 0.002347024308466052, 'f1': 0.0015792145287736648, 'number': 17895}, 'overall_precision': 0.0005107206935142913, 'overall_recall': 0.0020164825530422583, 'overall_f1': 0.000815019028922545, 'overall_accuracy': 0.12535140511533802}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cgsbETi4rFlz","executionInfo":{"elapsed":4388237,"status":"ok","timestamp":1636816094196,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"},"user_tz":-330},"outputId":"c7640e7f-42e3-4868-dc6c-bd9da839cc39"},"source":["n_epochs = 35\n","n_runs = 1\n","batch_size = 2\n","for (train_sz, test_sz) in [(50,50)]:\n","\n","    print(\"\\tTrain size:\", train_sz, \"Test size:\", test_sz)\n","    \n","    for run in range(n_runs):\n","        print(f\"\\n\\n\\t\\t-------------RUN {run+1}-----------\")\n","        \n","        optimizer = optim.Adam(params = chain(transformer_model.parameters(),\n","                                  linear_layer.parameters(),\n","                                  crf_layer.parameters()),\n","                                lr = 2e-5,)\n","\n","        train_dataset, _, test_dataset = get_datasets(train_sz, test_sz)\n","        train_dataset = [elem for elem in train_dataset]\n","        test_dataset = [elem for elem in test_dataset]\n","        print(\"Train dataset size:\", len(train_dataset))\n","        for epoch in range(n_epochs):\n","            print(f\"\\t\\t\\t------------EPOCH {epoch+1}---------------\")\n","            train(train_dataset)\n","            evaluate(test_dataset, metric)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["\tTrain size: 50 Test size: 50\n","\n","\n","\t\t-------------RUN 1-----------\n","Train dataset size: 69\n","\t\t\t------------EPOCH 1---------------\n","Loss: tensor(1519.9774, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1033.5620, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1042.8639, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1084.4423, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1764.4027, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1129.1053, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1054.9170, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1435.5516, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1333.8762, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1343.3154, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(652.1956, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(418.6808, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1468.4607, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1025.2673, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1150.3818, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1432.2003, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1113.4138, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1031.3336, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1309.1375, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(922.5122, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(955.5203, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1512.5258, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(919.6810, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1080.9247, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(843.4762, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1018.8962, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1245.2122, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1003.5810, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(827.9813, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1621.6187, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1367.3560, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(981.7322, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1026.3334, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(779.7072, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(911.8662, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1837.9017, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1770.3837, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1064.1417, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(994.7732, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(992.9614, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1472.0835, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(723.1440, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(957.9485, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1283.4985, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1384.6038, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1109.3420, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1222.2701, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1011.9136, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(936.7891, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(945.7617, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(873.8096, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1310.0028, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(843.0237, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1021.5659, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1339.4734, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(817.7583, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1180.1748, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1029.5664, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1784.4092, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(945.1429, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(724.6010, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(854.7819, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1327.4412, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1618.3394, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1062.4062, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(533.4256, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1563.1476, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1410.7246, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1391.5540, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.23071324599708878, 'recall': 0.2596232596232596, 'f1': 0.24431599229287093, 'number': 1221}, 'D': {'precision': 0.35374149659863946, 'recall': 0.14092140921409213, 'f1': 0.20155038759689922, 'number': 1476}, 'OC': {'precision': 0.16000974184120798, 'recall': 0.37244897959183676, 'f1': 0.2238500851788756, 'number': 1764}, 'overall_precision': 0.19479235332893868, 'overall_recall': 0.2649630127774042, 'overall_f1': 0.22452274669959163, 'overall_accuracy': 0.5485486232201635}\n","\t\t\t------------EPOCH 2---------------\n","Loss: tensor(811.3809, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(792.4825, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(744.7541, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(826.7102, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1486.0085, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(973.3899, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(893.4140, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1067.8320, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1024.2887, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1233.6279, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(693.3323, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(384.8103, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1313.2380, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(928.2148, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1037.1561, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1269.1302, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(994.8839, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(864.1789, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1017.3226, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(790.4573, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(796.3746, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1438.0339, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(898.5922, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(961.2993, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(708.6121, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(947.1274, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1101.9160, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(757.0654, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(717.9305, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1330.4734, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1271.4905, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(968.6219, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(805.5735, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(687.5257, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(730.9064, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1460.8999, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1469.9753, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(924.3289, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(877.1182, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(873.3177, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1247.6471, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(619.5809, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(847.7656, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(973.0317, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1262.3722, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(943.6666, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(966.1387, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(802.7054, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(697.2936, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(595.0507, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(759.2153, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1167.6278, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(776.4964, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(972.2625, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1200.8008, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(824.3857, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(997.8270, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(959.7516, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1678.6299, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(871.1899, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(666.8925, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(764.6579, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1143.9260, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1415.1980, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(980.9932, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(481.9179, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1156.9003, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1063.4780, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1231.6277, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.2385195339273475, 'recall': 0.28501228501228504, 'f1': 0.2597014925373135, 'number': 1221}, 'D': {'precision': 0.4588744588744589, 'recall': 0.21544715447154472, 'f1': 0.29322268326417705, 'number': 1476}, 'OC': {'precision': 0.18364881192106322, 'recall': 0.2585034013605442, 'f1': 0.21473981634094652, 'number': 1764}, 'overall_precision': 0.24207119741100325, 'overall_recall': 0.25151311365164764, 'overall_f1': 0.24670184696569922, 'overall_accuracy': 0.6745894836959055}\n","\t\t\t------------EPOCH 3---------------\n","Loss: tensor(596.7586, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(726.8237, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(640.1885, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(725.7216, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1325.6375, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(788.9053, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(805.2045, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(878.6846, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(983.1246, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1104.5535, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(488.3768, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(207.2675, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1055.7974, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(843.7069, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(900.3112, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1054.7059, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(897.4138, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(763.1729, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(941.1451, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(715.2135, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(752.5755, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1442.7957, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(857.2892, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(892.3426, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(637.1071, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(832.3537, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(910.8876, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(575.6621, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(690.5079, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1077.1980, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1043.0182, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(769.3962, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(616.2122, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(615.5123, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(590.6124, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(984.7664, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1275.7825, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(806.4694, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(818.7429, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(783.6411, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1015.6895, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(535.1227, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(730.1820, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(849.5784, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1103.3722, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(870.7278, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(737.6866, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(718.8554, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(780.3573, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(523.7726, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(635.7397, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1075.0811, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(634.3412, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(770.6239, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1084.9399, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(750.3991, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(849.5946, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(893.4826, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1468.1184, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(756.9060, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(600.4731, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(667.8456, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(922.9584, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1274.5087, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(893.6818, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(421.2476, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(929.2147, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(805.4696, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(917.8050, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.2599880739415623, 'recall': 0.3570843570843571, 'f1': 0.3008971704623878, 'number': 1221}, 'D': {'precision': 0.4133083411433927, 'recall': 0.29878048780487804, 'f1': 0.3468344475029493, 'number': 1476}, 'OC': {'precision': 0.2353191489361702, 'recall': 0.3134920634920635, 'f1': 0.2688381137578998, 'number': 1764}, 'overall_precision': 0.2807224185316058, 'overall_recall': 0.3205559291638646, 'overall_f1': 0.2993197278911564, 'overall_accuracy': 0.6892291338362411}\n","\t\t\t------------EPOCH 4---------------\n","Loss: tensor(478.5290, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(591.2008, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(527.1683, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(600.9904, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1181.1335, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(700.8073, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(734.3402, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(712.7316, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(879.4930, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(963.9733, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(431.0815, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(118.0969, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(896.7999, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(789.7208, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(819.1476, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(997.1747, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(807.7234, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(683.0730, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(829.6014, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(599.2960, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(666.8914, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1117.9875, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(684.6005, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(745.6476, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(543.3997, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(701.6533, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(724.2011, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(436.3107, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(614.2108, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(915.6235, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(903.7627, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(674.4891, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(503.0106, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(578.8387, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(513.0936, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(699.4102, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1041.0078, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(713.1068, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(756.3825, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(704.4960, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(824.5948, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(497.0226, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(769.8602, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(802.4789, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(875.0230, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(724.0294, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(676.0970, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(560.7803, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(654.3339, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(431.1925, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(596.3741, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(973.1659, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(601.5004, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(635.3404, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1042.7078, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(643.2753, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(668.1823, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(758.8990, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1288.2682, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(647.3405, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(567.5759, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(569.8254, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(756.8790, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1020.6342, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(798.3398, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(292.5656, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(725.5345, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(661.1699, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(851.6516, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.1835164835164835, 'recall': 0.4103194103194103, 'f1': 0.2536066818526955, 'number': 1221}, 'D': {'precision': 0.369155617585485, 'recall': 0.3584010840108401, 'f1': 0.36369886558954967, 'number': 1476}, 'OC': {'precision': 0.21247311827956988, 'recall': 0.2800453514739229, 'f1': 0.2416238689166055, 'number': 1764}, 'overall_precision': 0.23489519112207152, 'overall_recall': 0.34162743779421656, 'overall_f1': 0.2783815873595762, 'overall_accuracy': 0.6086924088285482}\n","\t\t\t------------EPOCH 5---------------\n","Loss: tensor(429.7913, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(527.5107, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(518.7512, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(550.4250, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1167.6794, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(769.3090, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(722.7000, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(649.4741, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(756.5209, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(922.6082, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(441.2365, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(119.7433, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(798.8228, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(654.5801, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(720.8014, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(806.5364, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(715.9913, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(607.0088, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(815.5726, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(570.0328, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(616.8733, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(985.8550, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(698.4685, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(729.3057, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(503.3478, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(633.6168, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(662.6949, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(446.0824, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(472.5969, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(922.3892, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(922.1882, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(635.9417, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(420.1868, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(482.5355, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(429.7309, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(678.5105, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(932.8054, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(643.4627, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(665.2530, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(632.0033, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(741.3580, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(515.6427, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(791.1703, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(843.7124, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(806.7044, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(643.1271, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(851.6141, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(578.1541, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(481.8352, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(414.0010, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(568.8127, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(768.3027, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(545.8590, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(631.8163, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(919.8887, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(610.4119, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(789.0702, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(733.5109, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1197.7234, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(620.5742, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(594.8297, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(554.3168, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(885.7736, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1152.5796, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(774.1896, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(234.6678, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(592.2372, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(522.4670, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(753.8855, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.24456521739130435, 'recall': 0.40540540540540543, 'f1': 0.3050847457627119, 'number': 1221}, 'D': {'precision': 0.45038167938931295, 'recall': 0.3597560975609756, 'f1': 0.39999999999999997, 'number': 1476}, 'OC': {'precision': 0.25769059295586266, 'recall': 0.3276643990929705, 'f1': 0.28849513351634637, 'number': 1764}, 'overall_precision': 0.2945280940139552, 'overall_recall': 0.35956063662855864, 'overall_f1': 0.32381144645200366, 'overall_accuracy': 0.6827858228509087}\n","\t\t\t------------EPOCH 6---------------\n","Loss: tensor(396.7635, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(411.9295, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(395.3907, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(498.2345, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(904.7250, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(564.8297, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(610.5873, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(552.4266, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(641.2823, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(712.1732, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(376.8231, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(154.5197, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(755.3010, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(562.7449, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(701.0988, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(696.8323, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(670.8771, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(492.1004, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(680.8261, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(515.5472, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(546.3494, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(926.1433, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(440.1709, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(611.5623, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(421.4168, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(564.1135, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(581.2182, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(310.5195, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(421.3584, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(881.6711, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(794.9718, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(641.3774, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(409.0374, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(397.5147, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(481.0746, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(849.6399, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(862.5987, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(574.3817, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(635.6323, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(521.9999, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(579.2506, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(323.6757, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(524.8077, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(557.5774, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(685.3409, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(527.5473, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(675.2877, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(473.3036, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(416.7983, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(304.7026, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(543.0524, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(751.4960, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(468.5007, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(578.8514, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(783.1610, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(668.8587, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(569.7521, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(635.3676, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1007.1863, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(523.2213, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(439.1415, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(407.4536, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(653.3879, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(853.3046, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(699.1186, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(172.6183, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(527.8586, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(412.3420, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(732.8825, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.2665615141955836, 'recall': 0.4152334152334152, 'f1': 0.3246878001921229, 'number': 1221}, 'D': {'precision': 0.5362318840579711, 'recall': 0.3258807588075881, 'f1': 0.405394016013485, 'number': 1476}, 'OC': {'precision': 0.26495726495726496, 'recall': 0.15816326530612246, 'f1': 0.19808306709265175, 'number': 1764}, 'overall_precision': 0.328920041536864, 'overall_recall': 0.2840170365388926, 'overall_f1': 0.30482376999879707, 'overall_accuracy': 0.6907024234681984}\n","\t\t\t------------EPOCH 7---------------\n","Loss: tensor(305.2615, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(516.9494, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(479.8668, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(479.9071, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(890.5701, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(471.8336, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(718.9512, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(527.1210, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(826.1966, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(681.8300, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(358.3432, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(74.6854, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(612.2898, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(452.1143, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(618.4335, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(557.4110, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(652.3976, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(486.2411, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(620.8535, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(488.9200, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(586.5787, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1076.8262, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(507.7481, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(729.5823, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(429.4595, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(545.5641, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(599.3311, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(283.1677, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(555.2694, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(688.0059, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(564.0789, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(553.6978, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(313.1983, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(412.2591, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(357.3152, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(524.3655, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(795.8447, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(525.0485, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(558.5258, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(532.2538, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(625.2441, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(301.8495, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(523.6989, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(538.6464, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(981.0839, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(557.9131, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(710.1280, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(524.8253, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(371.2881, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(293.3335, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(656.4575, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(606.4109, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(503.3669, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(603.6341, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(717.1993, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(505.8216, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(606.2006, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(570.0342, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(973.2941, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(564.5493, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(410.1336, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(452.8619, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(586.8671, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(833.2346, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(642.5561, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(150.0970, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(479.8689, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(370.7450, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(600.5703, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.21125644074514466, 'recall': 0.43652743652743653, 'f1': 0.2847222222222222, 'number': 1221}, 'D': {'precision': 0.5872442839951865, 'recall': 0.33062330623306235, 'f1': 0.42306025140875597, 'number': 1476}, 'OC': {'precision': 0.28613352898019073, 'recall': 0.22108843537414966, 'f1': 0.2494403581707707, 'number': 1764}, 'overall_precision': 0.2991308034767861, 'overall_recall': 0.31629679444070835, 'overall_f1': 0.3074743952930922, 'overall_accuracy': 0.6672043863002713}\n","\t\t\t------------EPOCH 8---------------\n","Loss: tensor(285.8735, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(315.3255, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(396.9555, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(418.4206, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1086.4655, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(530.9418, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(618.0486, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(615.1334, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(674.1149, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(693.4142, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(322.6404, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(52.6771, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(650.2930, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(494.4312, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(671.1079, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(679.1589, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(605.2346, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(385.6581, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(707.2704, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(499.7487, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(552.2363, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(668.2911, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(272.9136, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(622.4267, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(333.9810, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(552.1024, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(514.3992, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(240.6521, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(391.1187, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(636.3514, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(508.6352, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(495.4452, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(292.2536, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(368.7233, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(350.1710, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(536.3021, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(694.1930, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(473.9062, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(488.4368, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(428.5999, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(467.0071, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(318.0428, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(508.7007, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(493.9929, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(655.0502, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(469.8487, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(698.1083, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(434.5195, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(294.1065, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(258.6515, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(494.6074, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(611.7297, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(489.1584, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(599.5123, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(525.2403, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(496.1780, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(508.0581, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(499.3424, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(885.3229, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(629.6871, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(372.0549, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(548.0249, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(771.4199, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1048.8733, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(703.2003, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(111.0778, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(776.1300, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(884.1337, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(797.4463, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.3469551282051282, 'recall': 0.3546273546273546, 'f1': 0.3507492912110166, 'number': 1221}, 'D': {'precision': 0.5752314814814815, 'recall': 0.3367208672086721, 'f1': 0.4247863247863248, 'number': 1476}, 'OC': {'precision': 0.34973005398920215, 'recall': 0.33049886621315194, 'f1': 0.33984261148353245, 'number': 1764}, 'overall_precision': 0.40037046837787776, 'overall_recall': 0.33916162295449453, 'overall_f1': 0.3672330097087379, 'overall_accuracy': 0.7108529228014883}\n","\t\t\t------------EPOCH 9---------------\n","Loss: tensor(280.4153, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(398.6542, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(303.3125, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(472.1891, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(683.6470, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(320.4689, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(512.5453, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(420.3604, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(558.5841, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(480.6437, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(248.7039, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(47.4216, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(614.8960, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(449.2204, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(652.7103, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(509.7166, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(677.1387, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(449.9339, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(666.7612, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(575.0175, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(607.1165, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1208.5250, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(440.4531, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(650.7521, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(482.5319, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(702.4626, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(825.4169, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(365.8200, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(394.6009, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(647.9983, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(555.5549, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(559.1183, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(345.7570, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(421.6226, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(458.6862, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(530.8190, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(697.9639, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(580.8101, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(405.6569, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(604.6683, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(478.7422, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(269.4930, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(359.7397, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(542.3383, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(635.8837, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(436.9337, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(528.0153, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(540.8024, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(320.5026, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(299.0594, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(477.6521, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(556.6539, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(449.2697, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(662.7086, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(510.2975, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(516.8768, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(566.2388, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(627.0664, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(855.9183, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(755.3433, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(473.3615, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(647.3292, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(809.6208, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1007.1693, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(784.8726, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(246.8612, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(880.4178, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(944.3345, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(904.2090, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.39402173913043476, 'recall': 0.2375102375102375, 'f1': 0.2963719979560552, 'number': 1221}, 'D': {'precision': 0.5133267522211253, 'recall': 0.3523035230352303, 'f1': 0.4178384893531539, 'number': 1476}, 'OC': {'precision': 0.20372960372960372, 'recall': 0.4954648526077097, 'f1': 0.2887347208457218, 'number': 1764}, 'overall_precision': 0.2788541149196887, 'overall_recall': 0.3774938354629007, 'overall_f1': 0.3207619047619048, 'overall_accuracy': 0.574452411812426}\n","\t\t\t------------EPOCH 10---------------\n","Loss: tensor(857.0804, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(623.6841, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(418.2648, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(569.9106, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(860.6876, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(425.6992, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(522.4072, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(515.0573, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(482.6490, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(584.4354, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(272.3543, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(164.8905, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(568.0670, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(371.9099, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(531.3006, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(557.8255, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(571.9824, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(390.4724, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(453.7096, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(293.5451, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(412.0090, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(579.5151, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(245.6742, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(477.2966, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(353.6609, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(426.3939, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(440.7014, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(225.4225, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(416.9498, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(607.0353, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(480.2441, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(574.1489, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(419.5853, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(688.5496, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(365.0487, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(584.3464, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(546.6985, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(838.8952, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(775.0258, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(494.7811, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(427.1371, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(295.2309, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(360.2919, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(509.3393, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(609.8377, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(569.0515, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(422.8267, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(646.0284, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(712.9891, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(447.9985, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(455.5103, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(723.3185, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(408.5525, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(474.7773, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(576.1625, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(371.8527, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(571.8956, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(408.4938, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(735.8133, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(431.4746, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(303.8593, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(330.4305, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(452.5598, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(714.8033, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(521.4344, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(134.7898, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(428.9887, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(364.8033, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(547.4252, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.4171374764595104, 'recall': 0.3628173628173628, 'f1': 0.3880858519491897, 'number': 1221}, 'D': {'precision': 0.5191605839416058, 'recall': 0.38550135501355015, 'f1': 0.44245723172628304, 'number': 1476}, 'OC': {'precision': 0.25403001667593106, 'recall': 0.518140589569161, 'f1': 0.34091756807161505, 'number': 1764}, 'overall_precision': 0.3346073662265462, 'overall_recall': 0.4317417619367855, 'overall_f1': 0.37701869433297447, 'overall_accuracy': 0.6403588112977071}\n","\t\t\t------------EPOCH 11---------------\n","Loss: tensor(312.6446, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(255.9232, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(291.9700, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(369.4963, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(661.4016, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(329.6935, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(461.6471, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(446.7324, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(457.9142, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(570.7742, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(286.1613, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(90.9645, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(644.0538, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(426.9322, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(572.0177, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(587.6014, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(611.3257, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(475.7209, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(561.5153, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(291.5178, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(372.8657, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(602.2373, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(379.0646, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(426.6440, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(259.6295, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(384.5302, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(382.4354, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(174.9057, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(256.8878, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(524.6871, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(389.8459, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(433.6058, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(201.6743, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(288.9322, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(260.9040, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(389.5854, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(450.2027, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(383.1277, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(301.4042, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(329.2249, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(325.1740, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(206.8808, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(273.7639, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(370.4950, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(429.3493, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(299.3230, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(475.3885, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(311.2312, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(234.8319, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(230.2798, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(351.8807, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(473.0352, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(361.1783, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(493.8546, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(454.4709, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(293.7611, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(459.7305, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(306.3391, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(626.1307, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(409.7651, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(281.9638, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(282.0613, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(394.3833, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(679.2040, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(448.1054, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(119.8688, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(364.6189, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(260.7704, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(492.9694, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.3547224224945926, 'recall': 0.40294840294840295, 'f1': 0.3773006134969325, 'number': 1221}, 'D': {'precision': 0.4824335904027421, 'recall': 0.3814363143631436, 'f1': 0.42603102534998105, 'number': 1476}, 'OC': {'precision': 0.2925559604372723, 'recall': 0.31859410430839, 'f1': 0.3050203527815469, 'number': 1764}, 'overall_precision': 0.36134078212290505, 'overall_recall': 0.3624747814391392, 'overall_f1': 0.36190689346463745, 'overall_accuracy': 0.7149930531596468}\n","\t\t\t------------EPOCH 12---------------\n","Loss: tensor(224.2084, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(255.9640, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(270.5917, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(272.7885, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(530.3833, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(211.7249, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(476.3883, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(276.5193, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(473.6976, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(464.6984, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(209.7818, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(22.7349, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(484.2226, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(275.2093, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(450.7838, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(324.8373, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(344.7673, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(279.3535, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(310.8915, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(227.6075, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(341.8743, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(435.0560, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(191.3656, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(393.7826, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(199.3525, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(343.5703, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(319.2463, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(130.9254, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(310.8419, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(486.1561, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(276.0826, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(311.6975, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(154.5316, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(289.1091, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(252.2415, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(309.0750, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(447.5858, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(281.7718, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(300.4088, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(344.5781, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(299.7570, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(209.6994, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(262.5313, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(318.6103, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(395.1656, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(266.7400, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(311.6136, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(252.2269, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(168.8623, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(168.0270, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(275.1703, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(385.2263, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(327.5252, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(347.3961, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(341.6096, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(249.7256, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(371.3379, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(247.9104, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(504.2754, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(298.3014, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(221.5155, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(252.5710, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(342.5488, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(517.0353, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(442.8755, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(63.0387, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(314.1638, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(213.9561, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(374.6711, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.4324561403508772, 'recall': 0.4037674037674038, 'f1': 0.4176196526895383, 'number': 1221}, 'D': {'precision': 0.4987146529562982, 'recall': 0.3943089430894309, 'f1': 0.4404086265607264, 'number': 1476}, 'OC': {'precision': 0.28793774319066145, 'recall': 0.3356009070294785, 'f1': 0.3099476439790576, 'number': 1764}, 'overall_precision': 0.38207655283062114, 'overall_recall': 0.373683030710603, 'overall_f1': 0.37783318223028106, 'overall_accuracy': 0.7101442518392809}\n","\t\t\t------------EPOCH 13---------------\n","Loss: tensor(193.3249, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(143.0193, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(202.4402, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(239.1686, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(415.1043, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(152.3513, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(328.5635, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(250.4734, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(307.6267, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(253.2732, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(121.3042, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(12.6649, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(377.0424, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(227.3288, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(342.6665, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(313.9038, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(305.1744, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(266.0140, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(351.2795, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(253.1198, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(325.7134, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(401.9119, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(162.8803, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(381.0534, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(175.5140, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(282.3499, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(285.0743, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(108.9585, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(185.8549, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(393.7434, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(252.4092, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(262.1661, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(166.8716, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(218.3763, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(210.3570, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(254.6082, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(359.8283, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(234.4245, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(204.1545, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(260.3205, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(285.2934, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(230.2750, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(248.5523, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(306.0187, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(391.1080, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(272.2282, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(421.8369, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(256.8514, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(198.7022, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(186.4016, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(347.7641, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(464.2943, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(333.6286, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(495.9339, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(344.7823, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(298.3089, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(343.9254, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(218.0584, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(456.6806, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(327.5423, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(162.1917, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(236.8370, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(307.0273, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(464.2630, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(354.3841, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(47.3526, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(267.3541, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(159.9485, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(323.5485, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.41186891054030117, 'recall': 0.3808353808353808, 'f1': 0.39574468085106385, 'number': 1221}, 'D': {'precision': 0.5697674418604651, 'recall': 0.3319783197831978, 'f1': 0.4195205479452055, 'number': 1476}, 'OC': {'precision': 0.3390452876376989, 'recall': 0.31405895691609975, 'f1': 0.3260741612713361, 'number': 1764}, 'overall_precision': 0.4165056582942313, 'overall_recall': 0.3382649630127774, 'overall_f1': 0.37333003463631875, 'overall_accuracy': 0.7134265173484516}\n","\t\t\t------------EPOCH 14---------------\n","Loss: tensor(174.0844, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(125.1987, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(191.5983, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(205.7954, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(472.4422, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(162.9882, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(365.7367, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(251.8235, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(399.7801, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(340.5831, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(135.4409, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(5.4773, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(374.4287, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(251.9760, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(365.7455, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(306.2235, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(254.8047, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(251.5916, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(339.1968, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(226.0602, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(244.9001, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(327.7555, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(124.3915, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(258.9126, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(146.2007, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(255.9445, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(248.8556, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(97.0040, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(165.9944, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(348.9932, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(212.2090, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(219.4134, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(123.6805, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(204.3183, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(192.2731, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(219.6620, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(321.6486, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(210.9168, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(158.3518, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(229.0703, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(244.1198, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(180.1944, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(225.5613, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(273.4107, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(339.3740, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(244.8392, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(249.2838, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(231.9030, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(146.6081, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(151.7149, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(307.3104, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(411.1541, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(317.6011, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(455.1627, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(329.2838, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(311.1578, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(357.1172, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(273.6449, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(488.8074, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(319.3300, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(190.8913, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(249.5314, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(316.5379, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(531.9849, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(373.5732, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(75.8461, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(276.8915, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(160.7635, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(303.8344, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.37303370786516854, 'recall': 0.40786240786240785, 'f1': 0.38967136150234744, 'number': 1221}, 'D': {'precision': 0.5835266821345708, 'recall': 0.3407859078590786, 'f1': 0.43028229255774164, 'number': 1476}, 'OC': {'precision': 0.2742749054224464, 'recall': 0.2465986394557823, 'f1': 0.25970149253731345, 'number': 1764}, 'overall_precision': 0.3795929156753899, 'overall_recall': 0.32190091907644025, 'overall_f1': 0.34837457544881123, 'overall_accuracy': 0.6869819009166099}\n","\t\t\t------------EPOCH 15---------------\n","Loss: tensor(159.6174, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(91.8820, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(179.4606, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(190.4946, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(410.9892, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(104.7909, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(272.3524, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(308.7401, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(277.1752, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(193.9506, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(91.4096, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(4.5793, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(285.3250, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(179.0600, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(277.1902, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(258.8348, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(253.4785, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(260.3826, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(289.2056, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(249.7914, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(377.7748, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(426.9948, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(144.0268, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(382.1526, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(217.6481, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(486.8217, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(488.6124, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(167.8977, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(163.7102, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(402.7342, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(266.6543, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(267.2119, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(113.1685, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(197.9529, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(189.8434, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(205.8988, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(277.5583, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(198.1472, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(122.9618, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(205.3557, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(217.7328, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(160.4395, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(185.6377, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(343.6259, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(322.0232, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(233.0859, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(374.1261, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(213.0750, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(159.4596, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(239.1051, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(342.5793, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(411.7759, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(447.2936, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(510.1769, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(354.5914, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(335.3807, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(369.0887, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(345.4130, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(494.5519, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(416.2989, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(287.8095, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(362.6275, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(464.6937, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(542.2925, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(486.9781, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(200.8270, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(271.7292, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(209.8178, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(418.6218, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.35766423357664234, 'recall': 0.44144144144144143, 'f1': 0.3951612903225806, 'number': 1221}, 'D': {'precision': 0.45026575550493547, 'recall': 0.40176151761517614, 'f1': 0.4246330110991765, 'number': 1476}, 'OC': {'precision': 0.2732200939645826, 'recall': 0.42857142857142855, 'f1': 0.33370116971970865, 'number': 1764}, 'overall_precision': 0.33768556608835626, 'overall_recall': 0.423223492490473, 'overall_f1': 0.3756466374850776, 'overall_accuracy': 0.6825154089311191}\n","\t\t\t------------EPOCH 16---------------\n","Loss: tensor(211.0718, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(114.1106, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(250.8919, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(212.0718, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(408.2050, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(137.9492, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(312.9855, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(275.8352, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(279.3860, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(206.4598, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(86.6499, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(28.8806, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(288.5605, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(173.1051, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(265.2965, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(238.5979, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(246.8694, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(241.8796, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(312.6476, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(268.2067, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(370.2657, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(379.8969, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(146.6385, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(302.2728, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(293.5801, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(560.2812, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(387.1281, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(234.7142, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(288.9603, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(517.4354, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(304.2167, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(417.3753, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(139.6465, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(288.3388, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(211.8912, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(269.2201, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(309.4042, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(235.7849, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(151.3345, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(248.7342, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(214.6644, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(150.5110, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(157.7304, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(280.2454, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(274.7266, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(198.6321, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(184.0639, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(206.0587, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(123.5564, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(135.8210, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(235.0400, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(338.5427, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(299.3765, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(393.9614, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(298.0579, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(222.0190, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(303.5141, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(266.8172, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(485.2255, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(356.9751, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(272.9515, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(298.7610, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(313.0544, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(540.8363, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(593.6184, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(264.7924, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(342.9540, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(277.8876, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(657.9387, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.32578077158603796, 'recall': 0.4357084357084357, 'f1': 0.37281009110021024, 'number': 1221}, 'D': {'precision': 0.33575677461996034, 'recall': 0.34417344173441733, 'f1': 0.3399130143860823, 'number': 1476}, 'OC': {'precision': 0.23491879350348027, 'recall': 0.45918367346938777, 'f1': 0.3108211818879509, 'number': 1764}, 'overall_precision': 0.2805580831058538, 'overall_recall': 0.4147052230441605, 'overall_f1': 0.33469018543645407, 'overall_accuracy': 0.5907984670328134}\n","\t\t\t------------EPOCH 17---------------\n","Loss: tensor(226.7393, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(209.5465, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(350.5803, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(275.5707, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(555.8516, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(312.8618, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(496.4543, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(361.6896, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(326.2442, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(344.0065, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(342.0559, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(228.2017, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(508.7095, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(327.8949, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(479.0279, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(373.7882, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(340.4700, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(273.4339, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(274.5150, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(199.2567, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(272.1999, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(329.9273, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(116.9055, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(271.0114, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(152.0685, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(291.5414, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(265.7527, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(103.6345, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(201.3745, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(408.5897, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(273.8817, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(271.8560, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(164.0178, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(380.4525, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(272.4573, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(291.0599, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(583.3353, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(490.7569, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(354.5356, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(484.5895, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(264.9875, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(271.8762, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(229.4562, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(403.8187, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(417.5120, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(497.8275, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(241.5859, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(541.8746, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(330.8719, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(226.8903, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(269.3898, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(504.5478, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(325.3840, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(279.6768, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(348.5459, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(210.5944, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(282.0268, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(182.4346, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(452.3576, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(237.6794, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(165.5294, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(204.5670, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(274.5363, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(418.5788, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(397.9532, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(104.3125, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(258.8383, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(174.3741, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(472.3058, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.2790190735694823, 'recall': 0.41932841932841936, 'f1': 0.33507853403141363, 'number': 1221}, 'D': {'precision': 0.4697095435684647, 'recall': 0.38346883468834686, 'f1': 0.42223051100335696, 'number': 1476}, 'OC': {'precision': 0.22940655447298494, 'recall': 0.44047619047619047, 'f1': 0.3016889924286546, 'number': 1764}, 'overall_precision': 0.2886261086043255, 'overall_recall': 0.4158260479713069, 'overall_f1': 0.34074210139603234, 'overall_accuracy': 0.5737157669964473}\n","\t\t\t------------EPOCH 18---------------\n","Loss: tensor(188.3065, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(174.5534, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(370.7872, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(203.0398, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(538.4292, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(404.2176, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(548.2708, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(387.0874, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(333.6442, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(490.5822, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(490.2255, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(205.1829, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(600.4363, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(477.2457, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(590.1140, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(387.9962, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(445.8076, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(334.8697, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(379.2376, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(362.2933, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(383.7897, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(382.5627, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(362.9070, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(578.9548, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(167.4339, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(330.4142, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(299.9429, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(94.4901, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(264.1667, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(370.3318, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(281.9026, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(228.5007, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(152.4376, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(260.5899, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(218.2153, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(275.6250, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(365.8419, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(347.0596, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(221.6521, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(344.5482, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(306.1492, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(222.0626, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(216.3437, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(287.5081, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(381.6097, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(256.9916, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(220.1243, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(294.2740, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(216.6571, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(171.5455, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(236.8977, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(327.8715, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(288.2545, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(282.1804, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(321.3234, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(197.5497, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(297.1091, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(190.0062, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(418.4294, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(286.1427, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(154.2567, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(229.9454, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(323.2832, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(515.1464, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(336.7097, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(45.1517, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(234.5764, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(126.3194, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(350.1166, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.37064910630291625, 'recall': 0.3226863226863227, 'f1': 0.3450087565674256, 'number': 1221}, 'D': {'precision': 0.570267131242741, 'recall': 0.3326558265582656, 'f1': 0.4201968335472829, 'number': 1476}, 'OC': {'precision': 0.25037707390648567, 'recall': 0.47052154195011336, 'f1': 0.3268359913368773, 'number': 1764}, 'overall_precision': 0.32735254819622067, 'overall_recall': 0.38444295001120826, 'overall_f1': 0.35360824742268043, 'overall_accuracy': 0.6536930149287133}\n","\t\t\t------------EPOCH 19---------------\n","Loss: tensor(153.0875, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(107.0664, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(218.4058, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(260.7686, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(464.2103, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(148.6665, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(281.3444, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(278.3536, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(325.2077, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(254.0177, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(135.8640, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(84.0696, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(340.9887, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(238.7843, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(305.1094, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(315.1075, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(289.3386, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(244.3153, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(224.0540, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(166.4850, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(256.1765, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(315.2517, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(120.1180, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(230.8684, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(223.4014, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(293.2582, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(261.8610, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(119.0920, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(148.6958, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(354.2299, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(253.1865, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(206.9156, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(177.5540, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(222.9976, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(183.8552, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(244.3997, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(239.0332, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(199.3943, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(107.0215, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(191.8446, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(261.3177, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(135.9007, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(150.0372, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(234.7210, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(319.8915, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(201.8924, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(250.6510, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(285.6645, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(171.5830, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(174.1262, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(227.0907, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(365.7179, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(290.9783, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(254.9951, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(316.2570, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(180.7920, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(343.6177, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(179.2667, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(415.8850, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(294.1293, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(139.8748, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(207.4521, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(337.2957, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(465.1144, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(281.1004, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(47.2439, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(251.8544, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(145.5707, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(319.3382, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.37333333333333335, 'recall': 0.38984438984438985, 'f1': 0.3814102564102564, 'number': 1221}, 'D': {'precision': 0.5060869565217392, 'recall': 0.3943089430894309, 'f1': 0.44325971058644326, 'number': 1476}, 'OC': {'precision': 0.2962962962962963, 'recall': 0.4444444444444444, 'f1': 0.3555555555555555, 'number': 1764}, 'overall_precision': 0.36324196410964305, 'overall_recall': 0.4129119031607263, 'overall_f1': 0.3864876206462442, 'overall_accuracy': 0.7081394589856681}\n","\t\t\t------------EPOCH 20---------------\n","Loss: tensor(156.9240, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(65.6608, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(154.0637, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(152.6547, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(301.5449, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(74.1223, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(262.0707, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(180.9300, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(219.8784, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(158.5858, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(83.9643, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(25.6680, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(225.6330, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(154.9801, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(217.4292, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(223.1372, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(225.5909, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(212.3798, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(176.7124, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(128.9089, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(228.6343, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(259.8363, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(97.5675, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(165.9334, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(117.0675, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(271.0463, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(218.2455, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(67.1105, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(140.0369, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(314.1538, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(194.4256, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(162.8357, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(89.0069, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(184.1655, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(152.2018, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(165.0288, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(229.5600, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(195.0078, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(77.3544, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(193.2634, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(208.1170, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(118.1788, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(122.2879, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(211.2997, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(248.1259, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(140.5495, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(145.1347, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(152.5371, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(90.9758, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(99.4702, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(169.5210, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(238.7515, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(236.3030, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(193.9572, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(219.4569, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(131.8053, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(205.8112, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(101.9536, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(301.2973, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(191.6082, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(76.8406, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(144.7501, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(215.6067, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(331.8447, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(235.9563, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(20.7035, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(178.2023, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(90.1885, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(226.1628, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.33436341161928307, 'recall': 0.4430794430794431, 'f1': 0.381120112715745, 'number': 1221}, 'D': {'precision': 0.44592592592592595, 'recall': 0.4078590785907859, 'f1': 0.4260438782731776, 'number': 1476}, 'OC': {'precision': 0.26812941613982894, 'recall': 0.4087301587301587, 'f1': 0.3238266337300696, 'number': 1764}, 'overall_precision': 0.32950327028460313, 'overall_recall': 0.41784353284017034, 'overall_f1': 0.36845226329314096, 'overall_accuracy': 0.7084285221413053}\n","\t\t\t------------EPOCH 21---------------\n","Loss: tensor(105.1233, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(59.1448, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(138.6830, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(120.9309, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(307.1424, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(55.7698, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(218.0407, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(158.7047, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(194.9568, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(148.3403, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(58.0654, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(13.1974, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(222.6287, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(132.6168, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(202.2240, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(219.5272, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(154.6796, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(190.1738, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(172.7667, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(103.7797, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(193.4117, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(206.0715, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(61.6740, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(140.7309, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(95.0445, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(204.9191, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(156.1358, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(57.0389, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(94.2897, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(242.8784, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(149.3538, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(121.4734, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(77.0634, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(145.2215, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(131.2890, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(108.7847, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(187.0545, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(157.1610, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(54.2196, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(153.5776, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(181.1423, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(89.1932, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(109.3676, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(188.3572, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(215.4820, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(141.9497, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(138.4316, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(134.5298, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(91.1032, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(95.2908, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(163.9304, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(235.5511, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(220.0330, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(162.3382, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(203.4957, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(122.9163, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(196.2733, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(84.2133, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(270.4517, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(178.7660, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(67.4203, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(132.4648, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(191.2023, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(292.0242, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(225.6797, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(12.9523, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(163.5892, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(78.4547, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(197.7890, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.3635693215339233, 'recall': 0.4037674037674038, 'f1': 0.3826154443150951, 'number': 1221}, 'D': {'precision': 0.5055045871559632, 'recall': 0.37330623306233063, 'f1': 0.4294621979734996, 'number': 1476}, 'OC': {'precision': 0.24871959026888604, 'recall': 0.44047619047619047, 'f1': 0.3179214402618658, 'number': 1764}, 'overall_precision': 0.3269299820466786, 'overall_recall': 0.4082044384667115, 'overall_f1': 0.36307446914564856, 'overall_accuracy': 0.7023022481653814}\n","\t\t\t------------EPOCH 22---------------\n","Loss: tensor(83.6191, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(35.9224, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(121.2466, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(91.0025, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(263.4063, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(43.0234, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(190.0138, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(135.7817, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(165.7188, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(125.9083, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(49.8450, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(9.2683, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(185.5289, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(115.3833, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(167.5699, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(185.2798, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(136.2994, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(178.2602, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(158.2738, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(99.8637, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(191.9746, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(191.8601, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(60.5805, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(127.7360, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(83.4177, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(195.7472, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(145.5933, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(53.3498, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(88.6724, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(226.7892, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(132.5208, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(108.4501, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(60.4365, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(135.9923, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(121.1639, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(92.5793, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(168.7558, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(105.1062, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(44.6880, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(121.6692, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(159.7860, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(79.3559, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(87.7607, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(161.3069, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(192.9167, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(108.0150, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(111.9798, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(122.4610, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(66.5955, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(75.7123, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(135.9149, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(198.7714, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(214.5113, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(144.4474, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(198.2765, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(102.3482, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(174.6713, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(74.0183, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(261.0879, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(170.9979, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(57.1739, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(109.0933, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(180.0722, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(288.2603, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(227.7254, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(9.6775, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(160.8661, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(72.8485, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(178.2913, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.4009546539379475, 'recall': 0.41277641277641275, 'f1': 0.4067796610169491, 'number': 1221}, 'D': {'precision': 0.5602988260405549, 'recall': 0.3556910569105691, 'f1': 0.43514297554910897, 'number': 1476}, 'OC': {'precision': 0.30674603174603177, 'recall': 0.43820861678004536, 'f1': 0.36087768440709617, 'number': 1764}, 'overall_precision': 0.38226559185405173, 'overall_recall': 0.40394530374355525, 'overall_f1': 0.3928065395095367, 'overall_accuracy': 0.7152261686077414}\n","\t\t\t------------EPOCH 23---------------\n","Loss: tensor(79.0528, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(29.8734, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(112.0723, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(83.9269, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(244.0872, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(26.1244, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(164.5923, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(114.9228, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(159.6782, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(100.9109, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(42.0222, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(3.8194, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(166.7153, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(101.9561, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(168.9815, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(174.9657, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(120.2399, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(167.0478, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(137.3266, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(89.7247, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(166.6926, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(173.5320, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(53.9546, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(108.7379, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(75.1498, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(190.0290, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(150.4934, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(56.9238, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(77.5965, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(230.5693, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(120.1440, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(106.3424, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(54.8123, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(124.7915, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(116.4384, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(81.8167, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(160.2360, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(92.8010, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(39.5529, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(109.9836, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(146.4882, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(69.5956, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(81.2287, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(143.4026, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(173.5781, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(104.3825, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(104.5111, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(116.1499, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(60.0090, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(62.3592, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(128.9858, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(189.5803, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(204.5044, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(128.1650, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(163.8131, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(103.5921, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(159.1742, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(62.1343, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(220.1598, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(169.2242, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(47.4695, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(99.0706, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(177.1827, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(256.6581, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(205.7440, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(9.3287, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(148.5122, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(72.0661, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(178.6009, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.43, 'recall': 0.4226044226044226, 'f1': 0.42627013630731103, 'number': 1221}, 'D': {'precision': 0.5076096687555953, 'recall': 0.38414634146341464, 'f1': 0.4373312765136907, 'number': 1476}, 'OC': {'precision': 0.3423809523809524, 'recall': 0.4075963718820862, 'f1': 0.37215320910973093, 'number': 1764}, 'overall_precision': 0.40796920987095314, 'overall_recall': 0.40394530374355525, 'overall_f1': 0.4059472854246452, 'overall_accuracy': 0.718172747871656}\n","\t\t\t------------EPOCH 24---------------\n","Loss: tensor(78.8535, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(28.0068, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(116.0214, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(79.5792, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(248.4502, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(21.2363, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(206.4874, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(114.4004, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(156.3142, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(92.6581, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(39.1219, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(2.7023, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(160.7980, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(82.6306, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(142.6051, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(195.4642, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(105.4908, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(156.0182, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(120.4111, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(76.8342, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(144.7947, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(147.2499, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(46.3586, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(94.3692, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(61.2905, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(166.3066, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(111.5942, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(42.6887, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(62.3980, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(211.4653, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(105.2880, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(95.0853, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(47.3663, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(124.3362, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(111.7629, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(77.0428, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(161.3763, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(97.1203, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(41.0623, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(111.2337, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(165.3580, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(69.8376, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(84.1510, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(163.7557, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(182.3326, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(117.4236, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(124.8874, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(110.0851, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(55.9921, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(58.0326, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(126.9414, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(189.8373, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(196.2503, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(135.2183, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(182.7744, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(89.7338, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(151.9335, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(55.1081, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(226.5888, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(148.2009, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(38.3887, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(75.2684, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(157.0460, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(247.0913, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(202.3451, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(7.1410, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(139.2051, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(63.7144, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(163.6902, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.44165946413137425, 'recall': 0.41850941850941853, 'f1': 0.4297729184188394, 'number': 1221}, 'D': {'precision': 0.4683648315529992, 'recall': 0.3861788617886179, 'f1': 0.42331971778685484, 'number': 1476}, 'OC': {'precision': 0.340129749768304, 'recall': 0.41609977324263037, 'f1': 0.3742988271290158, 'number': 1764}, 'overall_precision': 0.40048543689320387, 'overall_recall': 0.40685944855413586, 'overall_f1': 0.4036472812187257, 'overall_accuracy': 0.708521768320543}\n","\t\t\t------------EPOCH 25---------------\n","Loss: tensor(66.6902, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(27.5803, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(111.5085, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(80.1103, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(249.9698, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(23.3793, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(181.3814, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(119.8308, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(160.2518, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(109.1455, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(36.5019, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(4.2973, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(174.9067, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(100.4046, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(153.7379, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(185.9727, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(123.2325, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(165.7771, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(130.8914, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(79.3391, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(157.1886, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(160.6253, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(46.9311, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(98.1021, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(61.4702, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(166.7913, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(133.7013, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(41.4329, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(61.2057, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(194.9904, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(92.0494, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(95.6905, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(50.1696, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(115.2942, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(102.0975, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(67.3135, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(151.2892, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(76.5687, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(31.7663, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(95.8520, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(136.3206, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(60.6331, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(80.9487, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(144.7478, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(162.4321, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(112.6081, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(109.2006, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(117.7141, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(59.9821, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(55.2956, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(123.6030, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(192.6196, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(196.3019, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(124.1503, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(168.7027, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(93.0769, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(168.6031, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(57.0912, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(231.8713, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(160.5646, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(36.9498, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(83.2200, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(173.9648, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(245.3055, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(203.0971, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(6.3142, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(137.9340, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(75.8302, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(151.8515, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.3979183346677342, 'recall': 0.407043407043407, 'f1': 0.40242914979757083, 'number': 1221}, 'D': {'precision': 0.5227934044616876, 'recall': 0.36517615176151763, 'f1': 0.4299960111687276, 'number': 1476}, 'OC': {'precision': 0.2998483699772555, 'recall': 0.44841269841269843, 'f1': 0.3593820990458882, 'number': 1764}, 'overall_precision': 0.3714924766165108, 'overall_recall': 0.40954942837928715, 'overall_f1': 0.389593773323382, 'overall_accuracy': 0.7081114851318967}\n","\t\t\t------------EPOCH 26---------------\n","Loss: tensor(59.5850, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(20.0415, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(98.4983, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(67.2161, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(213.0768, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(15.8290, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(146.6297, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(92.3868, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(128.4638, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(82.2549, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(34.1936, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(2.6898, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(144.0019, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(78.9902, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(127.3323, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(163.8197, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(105.1515, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(153.2113, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(117.7038, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(73.1331, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(142.3839, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(144.8515, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(50.7400, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(100.0274, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(55.4188, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(162.1209, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(119.8082, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(38.0481, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(62.0131, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(184.1183, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(103.3068, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(87.9048, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(50.5761, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(113.1096, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(97.8362, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(70.3372, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(136.0710, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(81.3390, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(31.2120, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(99.9752, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(126.1675, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(67.8168, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(68.4932, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(142.1467, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(157.5116, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(95.1869, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(102.4306, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(97.1687, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(49.8794, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(49.3955, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(106.7761, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(173.2639, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(188.6420, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(117.0119, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(161.1653, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(90.6019, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(132.4032, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(37.7820, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(206.4698, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(138.0161, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(31.2798, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(55.5473, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(138.5527, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(220.8757, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(197.0918, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(4.7794, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(126.6297, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(65.0109, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(141.4444, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.3642433234421365, 'recall': 0.4021294021294021, 'f1': 0.38224990268586995, 'number': 1221}, 'D': {'precision': 0.5858823529411765, 'recall': 0.33739837398373984, 'f1': 0.42820292347377475, 'number': 1476}, 'OC': {'precision': 0.2800294767870302, 'recall': 0.4308390022675737, 'f1': 0.3394372487717731, 'number': 1764}, 'overall_precision': 0.3560667752442997, 'overall_recall': 0.39206455951580366, 'overall_f1': 0.37319961591806255, 'overall_accuracy': 0.720000372984717}\n","\t\t\t------------EPOCH 27---------------\n","Loss: tensor(58.1316, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(28.6829, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(106.3296, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(73.8994, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(235.8413, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(23.8884, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(146.0721, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(98.7740, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(146.4204, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(91.4549, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(36.3691, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1.3280, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(154.4442, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(86.3418, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(140.4117, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(162.1388, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(93.9091, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(144.9086, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(113.0341, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(71.7087, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(130.1083, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(135.0178, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(39.1478, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(81.2746, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(55.2954, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(151.3211, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(117.7426, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(32.4121, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(49.2516, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(180.3023, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(80.2444, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(82.8874, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(39.6065, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(107.0474, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(94.7366, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(59.8369, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(131.7034, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(68.7500, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(25.5700, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(83.9912, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(120.2774, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(60.8243, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(69.4059, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(115.1358, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(147.3671, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(89.2560, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(116.0556, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(98.4082, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(50.8544, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(48.2220, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(115.2282, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(166.1550, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(178.0874, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(103.2009, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(135.0382, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(91.5957, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(126.1989, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(40.3845, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(178.7890, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(145.7483, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(33.2486, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(64.6073, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(147.0804, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(220.1202, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(191.2963, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(5.1472, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(131.3219, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(56.2571, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(159.6893, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.412609736632083, 'recall': 0.42342342342342343, 'f1': 0.417946645109135, 'number': 1221}, 'D': {'precision': 0.479285134037368, 'recall': 0.3997289972899729, 'f1': 0.43590690801625415, 'number': 1476}, 'OC': {'precision': 0.3261936635430611, 'recall': 0.4143990929705215, 'f1': 0.3650436953807741, 'number': 1764}, 'overall_precision': 0.388994708994709, 'overall_recall': 0.4120152432190092, 'overall_f1': 0.4001741780971043, 'overall_accuracy': 0.7210913532817993}\n","\t\t\t------------EPOCH 28---------------\n","Loss: tensor(50.4387, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(16.9466, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(98.9954, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(63.1097, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(214.5685, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(8.5895, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(143.6986, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(77.7230, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(105.8052, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(71.2309, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(28.7756, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1.4280, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(128.4489, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(63.5242, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(98.3397, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(144.6195, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(79.9647, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(131.3863, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(100.5166, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(62.8567, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(117.0541, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(122.5434, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(36.3885, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(67.8555, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(45.7647, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(137.5372, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(81.8901, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(29.4153, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(46.5583, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(158.7384, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(84.3619, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(68.8400, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(36.6898, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(96.6392, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(83.8375, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(55.4073, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(127.2850, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(65.1529, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(25.6179, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(85.1952, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(107.0456, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(53.0088, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(61.8701, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(121.2544, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(143.2113, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(89.0380, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(101.7134, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(85.5282, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(46.6323, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(42.9107, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(100.0005, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(153.4647, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(169.1910, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(98.6103, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(146.1017, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(65.4699, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(123.2035, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(32.6720, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(185.6061, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(124.7536, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(27.2713, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(45.8929, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(128.0951, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(205.2493, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(168.0350, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(3.5688, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(110.2544, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(58.6310, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(123.6665, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.3881918819188192, 'recall': 0.4307944307944308, 'f1': 0.4083850931677019, 'number': 1221}, 'D': {'precision': 0.47983539094650207, 'recall': 0.39498644986449866, 'f1': 0.4332961724266073, 'number': 1476}, 'OC': {'precision': 0.30059642147117294, 'recall': 0.42857142857142855, 'f1': 0.3533535872867492, 'number': 1764}, 'overall_precision': 0.3667649950835792, 'overall_recall': 0.41806769782559966, 'overall_f1': 0.3907395767860884, 'overall_accuracy': 0.7155991533246925}\n","\t\t\t------------EPOCH 29---------------\n","Loss: tensor(44.5288, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(15.0558, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(84.5218, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(55.8461, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(178.9130, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(8.6509, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(115.8029, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(67.3243, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(103.7385, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(72.3231, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(28.3498, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1.7925, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(121.0553, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(65.1071, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(100.0956, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(133.0395, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(94.6177, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(137.0515, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(98.7147, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(62.5252, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(123.6879, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(121.5644, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(32.5138, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(69.2802, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(49.1647, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(151.1533, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(100.3323, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(30.1724, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(41.2616, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(152.2634, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(105.4434, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(75.9636, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(38.2294, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(99.3930, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(86.3789, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(60.2785, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(122.1152, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(54.9106, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(19.3305, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(70.8170, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(103.9579, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(46.7279, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(63.8745, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(100.1564, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(137.3232, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(72.6934, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(85.5197, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(97.3291, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(51.1589, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(43.0447, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(98.8928, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(132.5008, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(158.8832, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(80.1720, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(117.2436, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(56.7386, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(111.4854, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(26.7466, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(156.2804, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(127.8275, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(24.4177, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(48.1639, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(145.6664, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(190.8031, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(188.6226, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(2.8016, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(109.9849, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(58.8513, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(139.2608, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.41116751269035534, 'recall': 0.39803439803439805, 'f1': 0.4044943820224719, 'number': 1221}, 'D': {'precision': 0.5733186328555678, 'recall': 0.3523035230352303, 'f1': 0.4364246747796894, 'number': 1476}, 'OC': {'precision': 0.29541145240803945, 'recall': 0.44160997732426305, 'f1': 0.35401045216996135, 'number': 1764}, 'overall_precision': 0.3776978417266187, 'overall_recall': 0.4001344989912576, 'overall_f1': 0.3885925764667465, 'overall_accuracy': 0.7058176291226467}\n","\t\t\t------------EPOCH 30---------------\n","Loss: tensor(45.5147, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(12.6069, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(88.6756, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(57.2119, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(205.9481, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(7.2661, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(128.0910, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(70.7791, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(103.4990, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(70.1172, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(32.0468, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1.3088, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(129.7357, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(63.7841, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(92.5389, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(126.7162, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(78.5780, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(115.4639, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(87.5683, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(56.1719, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(110.3042, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(108.6960, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(30.7034, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(60.4384, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(38.9219, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(128.5884, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(78.2235, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(26.6898, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(38.5632, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(136.5546, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(72.4693, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(59.2922, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(33.6026, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(88.7895, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(75.3031, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(50.2217, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(118.7176, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(56.2540, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(17.6943, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(71.7484, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(99.6617, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(45.7748, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(53.8507, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(110.0142, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(118.3262, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(86.1371, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(95.2119, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(84.7666, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(44.0366, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(45.4719, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(94.3531, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(147.3147, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(172.4841, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(97.9969, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(142.5276, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(62.1476, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(131.7088, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(29.9672, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(181.8607, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(127.3505, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(25.1635, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(38.1851, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(120.8366, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(179.2442, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(180.6231, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(2.5900, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(102.1606, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(55.6944, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(125.1348, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.40188383045525905, 'recall': 0.41932841932841936, 'f1': 0.41042084168336673, 'number': 1221}, 'D': {'precision': 0.5815279361459521, 'recall': 0.34552845528455284, 'f1': 0.4334891627709307, 'number': 1476}, 'OC': {'precision': 0.3229074889867841, 'recall': 0.4155328798185941, 'f1': 0.3634110064452157, 'number': 1764}, 'overall_precision': 0.3969690115358516, 'overall_recall': 0.3934095494283793, 'overall_f1': 0.3951812654807476, 'overall_accuracy': 0.7190399373385675}\n","\t\t\t------------EPOCH 31---------------\n","Loss: tensor(37.3335, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(11.2904, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(87.8477, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(48.3161, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(172.2283, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(6.4841, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(107.4995, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(55.4521, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(104.9878, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(68.5325, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(23.0979, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(0.9060, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(104.3499, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(55.9639, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(84.7185, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(147.5415, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(74.4247, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(117.0636, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(86.7075, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(53.7796, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(110.0213, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(109.5911, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(31.0255, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(56.5520, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(41.0908, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(155.0789, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(94.6958, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(26.1632, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(38.8017, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(152.0053, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(79.7863, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(68.8244, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(30.9272, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(89.0103, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(79.7432, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(52.1814, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(110.6286, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(50.7663, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(16.5087, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(65.2348, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(105.7597, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(51.2569, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(65.9073, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(107.4425, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(121.7989, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(72.2991, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(107.2869, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(88.3192, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(43.8939, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(38.3012, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(98.7469, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(129.0017, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(150.5780, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(76.4643, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(108.2937, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(57.1821, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(101.9170, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(22.5127, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(136.8435, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(113.2781, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(22.3019, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(38.6689, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(108.3374, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(159.7969, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(177.7344, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(2.5509, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(100.6647, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(52.1260, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(117.9633, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.4090909090909091, 'recall': 0.40540540540540543, 'f1': 0.4072398190045249, 'number': 1221}, 'D': {'precision': 0.48713550600343053, 'recall': 0.38482384823848237, 'f1': 0.42997728993186984, 'number': 1476}, 'OC': {'precision': 0.32673702726473175, 'recall': 0.4212018140589569, 'f1': 0.36800396235760274, 'number': 1764}, 'overall_precision': 0.38838709677419353, 'overall_recall': 0.40484196368527237, 'overall_f1': 0.3964438590714521, 'overall_accuracy': 0.7255391960314426}\n","\t\t\t------------EPOCH 32---------------\n","Loss: tensor(40.7657, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(10.6769, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(81.9536, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(49.0538, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(161.2186, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(4.9036, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(109.7046, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(64.4482, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(92.8878, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(59.8825, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(25.1846, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(0.7792, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(114.4286, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(53.2139, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(77.9470, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(114.8224, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(72.4018, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(108.9203, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(84.7684, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(56.1436, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(101.4117, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(105.0588, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(29.7794, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(64.6953, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(37.3962, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(122.7228, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(74.5714, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(22.4071, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(41.7326, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(145.0323, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(66.9446, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(59.8274, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(33.6034, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(74.5615, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(77.1320, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(50.5970, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(116.7454, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(43.7579, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(12.8079, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(61.5220, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(93.6486, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(39.2728, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(46.8087, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(85.8614, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(98.4431, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(73.6337, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(98.1079, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(66.5645, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(39.4644, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(35.0010, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(88.1798, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(117.0843, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(137.1559, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(77.1684, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(102.7238, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(50.6552, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(95.0728, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(25.5145, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(135.3377, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(104.3609, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(21.9862, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(37.2623, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(105.1088, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(160.7098, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(169.9432, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(2.1982, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(97.4798, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(47.1745, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(120.1160, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.36607828089025324, 'recall': 0.3906633906633907, 'f1': 0.3779714738510301, 'number': 1221}, 'D': {'precision': 0.521, 'recall': 0.3529810298102981, 'f1': 0.4208400646203554, 'number': 1476}, 'OC': {'precision': 0.25789120214909333, 'recall': 0.43537414965986393, 'f1': 0.3239139603542808, 'number': 1764}, 'overall_precision': 0.3344063624313577, 'overall_recall': 0.3958753642681013, 'overall_f1': 0.3625538903715869, 'overall_accuracy': 0.7185177587348358}\n","\t\t\t------------EPOCH 33---------------\n","Loss: tensor(41.7013, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(8.7464, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(72.5535, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(47.0733, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(153.7875, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(4.5589, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(105.5610, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(63.4754, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(83.3130, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(59.8308, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(22.5054, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(0.7934, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(94.2832, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(53.7127, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(77.4025, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(130.6066, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(66.3207, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(127.3005, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(86.0457, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(63.3910, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(94.1074, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(103.2920, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(24.5832, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(39.6332, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(42.0407, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(117.8231, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(66.3972, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(24.5520, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(34.3958, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(121.0382, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(56.8271, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(51.9538, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(43.0427, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(69.3342, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(65.1122, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(43.8898, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(94.2684, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(42.0660, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(12.9184, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(50.8213, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(91.9718, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(41.1105, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(47.8953, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(85.1261, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(101.6698, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(67.0185, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(78.3312, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(81.9547, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(42.0891, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(41.8923, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(88.8079, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(118.8552, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(148.2128, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(77.8807, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(110.3857, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(44.2887, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(101.8461, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(20.9119, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(138.8546, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(110.1555, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(17.6412, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(29.0256, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(99.1299, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(163.4388, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(174.8198, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1.8684, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(100.2244, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(51.6415, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(120.9480, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.3659722222222222, 'recall': 0.43161343161343163, 'f1': 0.39609169485155954, 'number': 1221}, 'D': {'precision': 0.5457380457380457, 'recall': 0.3556910569105691, 'f1': 0.4306808859721083, 'number': 1476}, 'OC': {'precision': 0.2970257234726688, 'recall': 0.4189342403628118, 'f1': 0.34760112888052686, 'number': 1764}, 'overall_precision': 0.36625766871165644, 'overall_recall': 0.4014794889038332, 'overall_f1': 0.38306063522617906, 'overall_accuracy': 0.7136689574144699}\n","\t\t\t------------EPOCH 34---------------\n","Loss: tensor(38.3550, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(7.1398, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(76.8071, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(40.7865, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(159.4233, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(4.2342, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(89.5196, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(49.1723, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(88.8210, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(48.6188, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(22.6341, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(0.8007, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(92.1977, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(46.4009, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(66.6424, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(101.2027, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(62.6614, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(133.6350, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(90.2927, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(45.7815, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(90.4825, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(100.5644, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(26.1613, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(50.7209, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(37.6541, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(114.7618, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(63.9137, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(30.2135, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(34.7432, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(138.2723, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(56.9255, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(51.0705, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(38.6378, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(70.2993, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(55.7666, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(45.0885, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(127.6113, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(31.8055, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(13.4850, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(54.6568, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(119.8556, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(38.9069, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(42.8526, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(76.3367, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(150.1345, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(56.1982, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(86.6423, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(63.2005, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(37.8566, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(30.8626, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(99.8232, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(106.5173, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(152.7320, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(68.9585, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(89.0457, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(42.7981, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(93.1224, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(20.4748, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(135.5527, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(104.6918, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(16.7479, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(27.1026, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(108.9585, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(145.1505, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(159.3442, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1.8266, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(86.3164, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(46.8255, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(119.5174, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.40737704918032785, 'recall': 0.407043407043407, 'f1': 0.4072101597705858, 'number': 1221}, 'D': {'precision': 0.5290068829891839, 'recall': 0.36449864498644985, 'f1': 0.4316085038106699, 'number': 1476}, 'OC': {'precision': 0.3203501094091904, 'recall': 0.41496598639455784, 'f1': 0.3615707582119042, 'number': 1764}, 'overall_precision': 0.3907563025210084, 'overall_recall': 0.3960995292535306, 'overall_f1': 0.39340977401758875, 'overall_accuracy': 0.7092117900469028}\n","\t\t\t------------EPOCH 35---------------\n","Loss: tensor(46.0506, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(7.4027, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(72.0806, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(40.9548, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(161.9625, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(4.7839, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(96.4616, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(50.3563, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(89.9870, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(60.5204, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(19.3918, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(0.8417, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(111.0318, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(45.6611, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(69.7645, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(133.2218, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(72.9853, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(128.9180, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(81.0956, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(47.8069, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(98.0228, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(111.1331, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(23.6443, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(43.2590, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(43.5862, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(111.3798, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(58.5501, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(26.1472, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(31.6873, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(125.1792, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(61.5842, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(44.7789, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(34.4552, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(66.0375, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(48.5422, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(39.9472, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(95.2663, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(29.8136, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(13.6517, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(48.4674, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(114.8211, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(37.1633, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(47.0301, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(88.6044, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(113.0619, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(61.1569, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(87.0059, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(78.3445, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(41.8048, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(56.5101, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(101.6965, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(130.8169, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(137.7436, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(84.2082, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(117.4370, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(56.9447, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(103.7632, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(21.1094, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(142.4208, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(109.4270, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(16.5630, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(23.2378, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(91.4931, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(136.6175, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(142.5006, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(1.5866, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(88.8544, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(43.3316, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss: tensor(111.6406, device='cuda:0', grad_fn=<DivBackward0>)\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","Evaluating\n","\t\t\t\t {'BC': {'precision': 0.4131578947368421, 'recall': 0.3857493857493858, 'f1': 0.3989834815756036, 'number': 1221}, 'D': {'precision': 0.49910714285714286, 'recall': 0.3787262872628726, 'f1': 0.4306625577812018, 'number': 1476}, 'OC': {'precision': 0.3130504403522818, 'recall': 0.4433106575963719, 'f1': 0.36696386672923503, 'number': 1764}, 'overall_precision': 0.38083228247162676, 'overall_recall': 0.406186953597848, 'overall_f1': 0.3931012040351448, 'overall_accuracy': 0.7163264735227474}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8grYONVWc5S3","executionInfo":{"elapsed":914322,"status":"ok","timestamp":1636828905749,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"},"user_tz":-330},"outputId":"53ba9007-1d5e-4d00-e006-f03a0066b68d"},"source":["n_epochs = 1\n","n_runs = 1\n","print(\"Right mask\")\n","batch_size = 2\n","for (train_sz, test_sz) in [(50,50)]:\n","\n","    print(\"\\tTrain size:\", train_sz, \"Test size:\", test_sz)\n","    \n","    for run in range(n_runs):\n","        print(f\"\\n\\n\\t\\t-------------RUN {run+1}-----------\")\n","        \n","        optimizer = optim.Adam(params = chain(transformer_model.parameters(),\n","                                  linear_layer.parameters(),\n","                                  crf_layer.parameters()),\n","                                lr = 2e-5,)\n","\n","        train_dataset, _, test_dataset = get_datasets(train_sz, test_sz)\n","        train_dataset = [elem for elem in train_dataset]\n","        test_dataset = [elem for elem in test_dataset]\n","        print(\"Train dataset size:\", len(train_dataset))\n","        for epoch in range(n_epochs):\n","            print(f\"\\t\\t\\t------------EPOCH {epoch+1}---------------\")\n","            # train(train_dataset)\n","            evaluate_left_right(test_dataset, metric, True)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Right mask\n","\tTrain size: 50 Test size: 50\n","\n","\n","\t\t-------------RUN 1-----------\n","Train dataset size: 67\n","\t\t\t------------EPOCH 1---------------\n","ENTER\n","Enter 2\n","{'BC': {'precision': 0.5226174496644296, 'recall': 0.38940841126168924, 'f1': 0.44628478092672724, 'number': 19997}, 'D': {'precision': 0.6185405316163117, 'recall': 0.35745634958496325, 'f1': 0.45307776030959007, 'number': 20962}, 'OC': {'precision': 0.3983568494373995, 'recall': 0.576271186440678, 'f1': 0.4710752529199316, 'number': 19352}, 'overall_precision': 0.4805031903870276, 'overall_recall': 0.43826167697434965, 'overall_f1': 0.4584113770378078, 'overall_accuracy': 0.7505135809785721}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rs_GOUiTdzei","executionInfo":{"elapsed":908229,"status":"ok","timestamp":1636829813969,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"},"user_tz":-330},"outputId":"3a675ac9-30d4-49e0-c6af-cead35ff8b40"},"source":["n_epochs = 1\n","n_runs = 1\n","print(\"Left mask\")\n","batch_size = 2\n","for (train_sz, test_sz) in [(50,50)]:\n","\n","    print(\"\\tTrain size:\", train_sz, \"Test size:\", test_sz)\n","    \n","    for run in range(n_runs):\n","        print(f\"\\n\\n\\t\\t-------------RUN {run+1}-----------\")\n","        \n","        optimizer = optim.Adam(params = chain(transformer_model.parameters(),\n","                                  linear_layer.parameters(),\n","                                  crf_layer.parameters()),\n","                                lr = 2e-5,)\n","\n","        train_dataset, _, test_dataset = get_datasets(train_sz, test_sz)\n","        train_dataset = [elem for elem in train_dataset]\n","        test_dataset = [elem for elem in test_dataset]\n","        print(\"Train dataset size:\", len(train_dataset))\n","        for epoch in range(n_epochs):\n","            print(f\"\\t\\t\\t------------EPOCH {epoch+1}---------------\")\n","            # train(train_dataset)\n","            evaluate_left_right(test_dataset, metric, False)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Left mask\n","\tTrain size: 50 Test size: 50\n","\n","\n","\t\t-------------RUN 1-----------\n","Train dataset size: 69\n","\t\t\t------------EPOCH 1---------------\n","ENTER\n","Enter 2\n","{'BC': {'precision': 0.5438948595105529, 'recall': 0.48976855360578325, 'f1': 0.5154145832694255, 'number': 17153}, 'D': {'precision': 0.6238167938931297, 'recall': 0.4457778747545276, 'f1': 0.5199796385848816, 'number': 18332}, 'OC': {'precision': 0.44596226154748353, 'recall': 0.5845277388434236, 'f1': 0.5059288537549406, 'number': 22117}, 'overall_precision': 0.5127487616233597, 'overall_recall': 0.5121523558209784, 'overall_f1': 0.5124503851932914, 'overall_accuracy': 0.7785750798896716}\n"]}]},{"cell_type":"code","metadata":{"id":"vBhSFB3JrQbs"},"source":["linear_path = \"Drinventor_linear_layer.pt\"\n","cross_path = \"Drinventor_cross_entropy_layer.pt\"\n","crf_path = \"Drinventor_crf_layer.pkl\"\n","tokenizer_path = \"Drinventor_tokenizer_pre.pkl\"\n","transformer_path = \"Drinventor_transformer_layer.pt\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"67mxAyx_rR4q"},"source":["import pickle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fWX6PVNNrR9C"},"source":["# torch.save(linear_layer.state_dict(), linear_path)\n","# torch.save(cross_entropy_layer.state_dict(), cross_path)\n","# torch.save(transformer_model.state_dict(), transformer_path)\n","# with open(crf_path, \"wb\") as f:\n","#   pickle.dump(crf_layer, f)\n","# with open(tokenizer_path, \"wb\") as f:\n","#   pickle.dump(tokenizer, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5C4a1k1HTk2i"},"source":["linear_layer.load_state_dict(torch.load(linear_path, map_location=device))\n","cross_entropy_layer.load_state_dict(torch.load(cross_path, map_location=device))\n","transformer_model.load_state_dict(torch.load(transformer_path , map_location=device))\n","with open(crf_path, \"rb\") as f:\n","  crf_layer = pickle.load(f)\n","with open(tokenizer_path, \"rb\") as f:\n","  tokenizer = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A4shbk55FpE0"},"source":["from tqdm import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k-VtvWvyFlOc"},"source":["actual_layer = [[] for i in range(13)]\n","def layer_wise_compute(batch: Tuple[torch.Tensor, torch.Tensor, torch.Tensor],\n","            preds: bool=False, cross_entropy: bool=True):\n","    \"\"\"\n","    Args:\n","        batch:  A tuple having tokenized thread of shape [batch_size, seq_len],\n","                component type labels of shape [batch_size, seq_len], and a global\n","                attention mask for Longformer, of the same shape.\n","        \n","        preds:  If True, returns a List(of batch_size size) of Tuples of form \n","                (tag_sequence, viterbi_score) where the tag_sequence is the \n","                viterbi-decoded sequence, for the corresponding sample in the batch.\n","        \n","        cross_entropy:  This argument will only be used if preds=False, i.e., if \n","                        loss is being calculated. If True, then cross entropy loss\n","                        will also be added to the output loss.\n","    \n","    Returns:\n","        Either the predicted sequences with their scores for each element in the batch\n","        (if preds is True), or the loss value summed over all elements of the batch\n","        (if preds is False).\n","    \"\"\"\n","    tokenized_threads, token_type_ids, comp_type_labels = batch\n","    \n","    pad_mask = torch.where(tokenized_threads!=tokenizer.pad_token_id, 1, 0)\n","\n","    logit_all = transformer_model(input_ids=tokenized_threads,\n","                                                attention_mask=pad_mask,).hidden_states\n","\n","    for i in tqdm(range(12)):\n","        \n","        logits = linear_layer(logit_all[i])\n","        tags = crf_layer.viterbi_tags(logits, pad_mask)\n","        for row in range(len(tags)):\n","          for col in range(len(tags[row][0])):\n","            if(tokenizer.pad_token_id == tokenized_threads[row][col] or tokenizer.mask_token_id == tokenized_threads[row][col]):\n","              continue\n","            actual_layer[i].append((tags[row][0][col], logits[row][col].cpu().numpy(), comp_type_labels[row][col].cpu().numpy()))\n","\n","def layer_wise_evaluate(dataset, metric):\n","    \n","    int_to_labels = {v:k for k, v in ac_dict.items()}\n","    print('ENTER')\n","    \n","    with torch.no_grad():\n","        for tokenized_threads, comp_type_labels, _ in dataset:\n","            # print(comp_type_labels)\n","            #Cast to PyTorch tensor\n","            tokenized_threads = torch.tensor(tokenized_threads, device=device)\n","            # masked_threads = torch.tensor(masked_threads, device=device)\n","            comp_type_labels = torch.tensor(comp_type_labels, device=device)\n","            tokenized_threads = tokenized_threads[:, :512]\n","            comp_type_labels = comp_type_labels[:, :512]\n","            # print(tokenized_threads)\n","            # print(comp_type_labels.shape)\n","            # print(comp_type_labels)\n","            preds = layer_wise_compute((tokenized_threads,\n","                            torch.where(tokenized_threads==tokenizer.mask_token_id, 1, 0), \n","                            comp_type_labels,), preds=True)\n","            \n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"64_hNMTqF1_0"},"source":["distance_starting_distribution = []\n","distance_ending_distribution = []\n","\n","def extract_starting_ind(tags_seq, ac_dict):\n","  ret_ind = []\n","  for i in range(len(tags_seq)):\n","    label = tags_seq[i]\n","    if(label == data_config[\"arg_components\"][\"B-OC\"] or \n","                        label == data_config[\"arg_components\"][\"B-D\"] or \n","                        label == data_config[\"arg_components\"][\"B-BC\"]):\n","      ret_ind.append(i)\n","  return ret_ind\n","\n","def extract_ending_ind(tags_seq, ac_dict):\n","  ret_ind = []\n","  for i in range(1, len(tags_seq)):\n","    label = tags_seq[i-1]\n","    if(label != data_config[\"arg_components\"][\"I-BC\"] and\n","                        label != data_config[\"arg_components\"][\"I-OC\"] and\n","                       label != data_config[\"arg_components\"][\"I-D\"]) and tags_seq[i] != tags_seq[i-1]:\n","      ret_ind.append(i)\n","  label = tags_seq[len(tags_seq)-1]\n","  if(label == data_config[\"arg_components\"][\"I-BC\"] and\n","                        label == data_config[\"arg_components\"][\"I-OC\"] and\n","                       label == data_config[\"arg_components\"][\"I-D\"]):\n","    ret_ind.append(len(tags_seq) - 1)\n","  return ret_ind\n","\n","def get_val(ind, X):\n","  if(ind >= len(X) or ind < 0):\n","    return 1000000\n","  return X[ind]\n","def find_closest(val, X):\n","  ans = 100000000\n","  for i in X:\n","    ans = min(ans, abs(val - i))\n","  return ans\n","def match(X, X_dash):\n","  ret_dist = []\n","  left_ind = 0\n","  for i in range(len(X)):\n","    closest_dist = find_closest(X[i], X_dash)\n","    ret_dist.append(closest_dist)\n","  return ret_dist\n","def check(X, X_origin):\n","  if(len(X) == 0):\n","    return\n","def distance_compute(batch: Tuple[torch.Tensor, torch.Tensor, torch.Tensor],\n","            preds: bool=False, cross_entropy: bool=True):\n","\n","    tokenized_threads, token_type_ids, comp_type_labels = batch\n","    \n","    pad_mask = torch.where(tokenized_threads!=tokenizer.pad_token_id, 1, 0)\n","\n","    logit_all = transformer_model(input_ids=tokenized_threads,\n","                                                attention_mask=pad_mask,).last_hidden_state\n","\n","    logits = linear_layer(logit_all)\n","    tags = crf_layer.viterbi_tags(logits, pad_mask)\n","    for row in range(len(tags)):\n","\n","      true_lab = comp_type_labels[row][:].cpu().numpy()\n","      pred_lab = tags[row][0][:]\n","\n","      X = extract_starting_ind(true_lab, ac_dict)\n","      X_dash = extract_starting_ind(pred_lab, ac_dict)\n","      Y = extract_ending_ind(true_lab, ac_dict)\n","      Y_dash = extract_ending_ind(pred_lab, ac_dict)\n","      \n","      check(X, true_lab)\n","      check(X_dash, pred_lab)\n","      check(Y, true_lab)\n","      check(Y_dash, pred_lab)\n","\n","      ret_start = match(X, X_dash)\n","      ret_end = match(Y, Y_dash)\n","\n","      distance_starting_distribution.extend(ret_start)\n","      distance_ending_distribution.extend(ret_end)\n","\n","def distance_evaluate(dataset, metric):\n","    \n","    int_to_labels = {v:k for k, v in ac_dict.items()}\n","    print('ENTER')\n","    \n","    with torch.no_grad():\n","        for tokenized_threads, comp_type_labels, _ in dataset:\n","            # print(comp_type_labels)\n","            #Cast to PyTorch tensor\n","            tokenized_threads = torch.tensor(tokenized_threads, device=device)\n","            # masked_threads = torch.tensor(masked_threads, device=device)\n","            comp_type_labels = torch.tensor(comp_type_labels, device=device)\n","            # print(tokenized_threads)\n","            tokenized_threads = tokenized_threads[:, :512]\n","            comp_type_labels = comp_type_labels[:, :512]\n","            # print(comp_type_labels.shape)\n","            # print(comp_type_labels)\n","            preds = distance_compute((tokenized_threads,\n","                            torch.where(tokenized_threads==tokenizer.mask_token_id, 1, 0), \n","                            comp_type_labels,), preds=True)\n","            "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XffidEn0khBP"},"source":["n_epochs = 1\n","for epoch in range(n_epochs):\n","    print(f\"------------EPOCH {epoch+1}---------------\")\n","    train_dataset, _, test_dataset = get_datasets()\n","    # train(train_dataset)\n","    # evaluate(test_dataset, metric)\n","    layer_wise_evaluate(train_dataset, metric)\n","    # layer_wise_evaluate(test_dataset, metric)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"FAPIAQJqFxHg","outputId":"b4f24127-b128-473a-8ed7-d656f75f7bc3"},"source":["n_epochs = 1\n","for epoch in range(n_epochs):\n","    print(f\"------------EPOCH {epoch+1}---------------\")\n","    train_dataset, _, test_dataset = get_datasets()\n","    # train(train_dataset)\n","    # evaluate(test_dataset, metric)\n","    distance_evaluate(train_dataset, metric)\n","    # distance_evaluate(test_dataset, metric)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["------------EPOCH 1---------------\n","ENTER\n"]}]},{"cell_type":"code","metadata":{"id":"ybfSFKTHOwvU"},"source":["import pandas as pd\n","\n","print(len(distance_starting_distribution)*25/100, len(distance_ending_distribution)*25/100)\n","print(len(distance_starting_distribution)*50/100, len(distance_ending_distribution)*50/100)\n","print(len(distance_starting_distribution)*75/100, len(distance_ending_distribution)*75/100)\n","print(len(distance_starting_distribution), len(distance_ending_distribution))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NlQXh3kIOyzg"},"source":["pd.DataFrame([i for i in distance_starting_distribution if i < 1000]).describe()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fp94uJOYO1v-"},"source":["pd.DataFrame([i for i in distance_ending_distribution if i < 1000]).describe()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"US0-DSj-O8HZ","executionInfo":{"elapsed":354,"status":"ok","timestamp":1637192243813,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"},"user_tz":-330},"outputId":"1ae6ed4a-da8b-4953-addb-c1b4b47c3c21"},"source":["threshold = 2\n","start_ind = sum([i > threshold for i in distance_starting_distribution])\n","end_ind = sum([i > threshold for i in distance_ending_distribution])\n","print(start_ind, end_ind)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["1274 2290\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ESerLh1lQY2e","executionInfo":{"elapsed":6,"status":"ok","timestamp":1637192185938,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"},"user_tz":-330},"outputId":"0760e627-7c7d-42a5-c7bb-c4682d84011e"},"source":["print(ac_dict)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["FrozenDict({\n","    O: 0,\n","    B-BC: 1,\n","    I-BC: 2,\n","    B-OC: 3,\n","    I-OC: 4,\n","    B-D: 5,\n","    I-D: 6,\n","})\n"]}]},{"cell_type":"code","metadata":{"id":"U5O0FHvuPUaA"},"source":["data_layer = []\n","data_class_wise_layer = {}\n","\n","class_names = ['O', 'B-BC', 'I-BC', 'B-OC', 'I-OC', 'B-D', 'I-D']\n","for j in class_names:\n","  data_class_wise_layer[j] = []\n","for i in range(len(actual_layer)):\n","  count = 0\n","  for j in actual_layer[i]:\n","    count += (j[0] == j[2])\n","  data_layer.append((count, len(actual_layer[i])))\n","  for key in range(len(class_names)):\n","    cnt = 0\n","    den = 0\n","    for j in actual_layer[i]:\n","      cnt += (j[0] == j[2] and j[2] == key)\n","      den += (j[2] == key)\n","    # print(cnt, den)\n","    data_class_wise_layer[class_names[key]].append((cnt, den))\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"02U7DHA1PX1S"},"source":["import matplotlib.pyplot as plt\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sDfwMuVcPavB"},"source":["def plot2(img1_bar, img2_bar, img3_bar, img4_bar, img5_bar, img6_bar, img7_bar, img8_bar):\n","  fig, arr = plt.subplots(2, 7)\n","  fig.set_figheight(30)\n","  fig.set_figwidth(30)\n","  img1 = arr[0][0]\n","  arr[0][1].set_visible(False)\n","  arr[0][2].set_visible(False)\n","  arr[0][3].set_visible(False)\n","  arr[0][4].set_visible(False)\n","  img2, img3, img4, img5, img6, img7, img8 = arr[1][0], arr[1][1], arr[1][2], arr[1][3], arr[1][4], arr[1][5], arr[1][6]\n","  img1.set_title(\" Total \")\n","  img1.set_xlabel(\"layer number\")\n","  img1.set_ylabel(\"Correct predictions\")\n","  img2.set_title(\" O Class \")\n","  img2.set_xlabel(\"layer number\")\n","  img2.set_ylabel(\"Correct predictions\")\n","  img3.set_title(\" B-BC class\")\n","  img3.set_xlabel(\"layer number\")\n","  img3.set_ylabel(\"Correct predictions\")\n","  img4.set_title(\" I-BC class\")\n","  img4.set_xlabel(\"layer number\")\n","  img4.set_ylabel(\"Correct predictions\")\n","  img5.set_title(\" B-OC class\")\n","  img5.set_xlabel(\"layer number\")\n","  img5.set_ylabel(\"Correct predictions\")\n","  img6.set_title(\" I-OC class\")\n","  img6.set_xlabel(\"layer number\")\n","  img6.set_ylabel(\"Correct predictions\")\n","  img7.set_title(\" B-D class\")\n","  img7.set_xlabel(\"layer number\")\n","  img7.set_ylabel(\"Correct predictions\")\n","  img8.set_title(\" I-D class\")\n","  img8.set_xlabel(\"layer number\")\n","  img8.set_ylabel(\"Correct predictions\")\n","\n","  img1.bar(list(range(13)),[i[0]/(i[1] + (i[1] == 0)) for i in img1_bar])\n","  img2.bar(list(range(13)),[i[0]/(i[1] + (i[1] == 0)) for i in img2_bar])\n","  img3.bar(list(range(13)),[i[0]/(i[1] + (i[1] == 0)) for i in img3_bar])\n","  img4.bar(list(range(13)),[i[0]/(i[1] + (i[1] == 0)) for i in img4_bar])\n","  img5.bar(list(range(13)),[i[0]/(i[1] + (i[1] == 0)) for i in img5_bar])\n","  img6.bar(list(range(13)),[i[0]/(i[1] + (i[1] == 0)) for i in img6_bar])\n","  img7.bar(list(range(13)),[i[0]/(i[1] + (i[1] == 0)) for i in img7_bar])\n","  img8.bar(list(range(13)),[i[0]/(i[1] + (i[1] == 0)) for i in img8_bar])\n","  plt.show()\n","  plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"SXBVGT8JPdIw","executionInfo":{"elapsed":2773,"status":"ok","timestamp":1637192736542,"user":{"displayName":"Anunay Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwwpkT-fB7xFD2pOYIajY3v4O-5ZcrswGNcQBQWA=s64","userId":"13986630515992640352"},"user_tz":-330},"outputId":"b22bd2b8-f446-4be7-a74d-21d539b74cf1"},"source":["plot2(data_layer, data_class_wise_layer['O'], data_class_wise_layer['B-BC'], data_class_wise_layer['I-BC'], data_class_wise_layer['B-OC'], data_class_wise_layer['I-OC'], data_class_wise_layer['B-D'], data_class_wise_layer['I-D'])"],"execution_count":null,"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 2160x2160 with 14 Axes>"]},"metadata":{},"output_type":"display_data"}]}]}